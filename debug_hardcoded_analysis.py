#!/usr/bin/env python3
"""
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚°ã®è©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ»åˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½œæˆã—ãŸãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã‚’æ´»ç”¨ã—ã¦ï¼š
1. ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®å…·ä½“çš„ãªç™ºç”Ÿç®‡æ‰€ã‚’ç‰¹å®š
2. å•é¡Œã®ã‚ã‚‹æˆ¦ç•¥ãƒ»éŠ˜æŸ„ãƒ»æ™‚é–“è¶³ã®çµ„ã¿åˆã‚ã›ã‚’æŠ½å‡º
3. ç™ºç”Ÿãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åˆ†æã—ã¦ãƒã‚°ã®æ ¹æœ¬åŸå› ã‚’è¿½è·¡
"""

import sys
import os
import pandas as pd
import numpy as np
import pickle
import gzip
import json
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Tuple, Any, Optional
from collections import defaultdict, Counter

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

class HardcodedValueBugDetector:
    """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚°ã®è©³ç´°æ¤œçŸ¥ãƒ»åˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.compressed_dir = Path("large_scale_analysis/compressed")
        self.known_hardcoded_values = [
            100.0, 105.0, 97.62, 100.00, 105.00, 97.620,
            0.04705, 0.050814, 0.044810,  # GMTæ¤œå‡ºå€¤
            102.0, 95.0, 98.0, 103.0,     # è¿½åŠ ã®ç–‘ã‚ã—ã„å€¤
            1000.0, 1000.00,               # 1000ç³»ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤
            840.0, 880.0, 620.0            # æ–°ãŸã«æ¤œå‡ºã•ã‚ŒãŸç–‘ã‚ã—ã„å€¤
        ]
        self.tolerance = 0.0001
        
        # åˆ†æçµæœã‚’ä¿å­˜
        self.analysis_results = {
            'hardcoded_violations': [],
            'static_pricing_strategies': [],
            'price_inconsistencies': [],
            'summary_stats': {}
        }
    
    def run_comprehensive_analysis(self) -> Dict[str, Any]:
        """åŒ…æ‹¬çš„ãªãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤åˆ†æã‚’å®Ÿè¡Œ"""
        print("ğŸ” ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚°ã®åŒ…æ‹¬çš„åˆ†æé–‹å§‹")
        print("=" * 60)
        
        if not self.compressed_dir.exists():
            print("âŒ compressed ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“")
            return self.analysis_results
        
        # 1. å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³ã—ã¦åŸºæœ¬çµ±è¨ˆã‚’åé›†
        print("\nğŸ“Š ã‚¹ãƒ†ãƒƒãƒ—1: åŸºæœ¬çµ±è¨ˆæƒ…å ±ã®åé›†")
        basic_stats = self._collect_basic_statistics()
        self.analysis_results['summary_stats']['basic'] = basic_stats
        
        # 2. ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®è©³ç´°æ¤œçŸ¥
        print("\nğŸ¯ ã‚¹ãƒ†ãƒƒãƒ—2: ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®è©³ç´°æ¤œçŸ¥")
        hardcoded_violations = self._detect_hardcoded_values_detailed()
        self.analysis_results['hardcoded_violations'] = hardcoded_violations
        
        # 3. é™çš„ä¾¡æ ¼è¨­å®šæˆ¦ç•¥ã®åˆ†æ
        print("\nâš™ï¸ ã‚¹ãƒ†ãƒƒãƒ—3: é™çš„ä¾¡æ ¼è¨­å®šæˆ¦ç•¥ã®åˆ†æ")
        static_strategies = self._analyze_static_pricing_detailed()
        self.analysis_results['static_pricing_strategies'] = static_strategies
        
        # 4. ä¾¡æ ¼ä¸€è²«æ€§ã®åˆ†æ
        print("\nğŸ”„ ã‚¹ãƒ†ãƒƒãƒ—4: ä¾¡æ ¼ä¸€è²«æ€§ã®åˆ†æ")
        inconsistencies = self._analyze_price_inconsistencies()
        self.analysis_results['price_inconsistencies'] = inconsistencies
        
        # 5. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã¨æ ¹æœ¬åŸå› ã®æ¨å®š
        print("\nğŸ§  ã‚¹ãƒ†ãƒƒãƒ—5: ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã¨æ ¹æœ¬åŸå› æ¨å®š")
        pattern_analysis = self._analyze_patterns_and_root_causes()
        self.analysis_results['pattern_analysis'] = pattern_analysis
        
        # 6. çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_detailed_report()
        
        return self.analysis_results
    
    def _collect_basic_statistics(self) -> Dict[str, Any]:
        """åŸºæœ¬çµ±è¨ˆæƒ…å ±ã‚’åé›†"""
        stats = {
            'total_files': 0,
            'symbols': set(),
            'timeframes': set(),
            'strategies': set(),
            'symbol_timeframe_combinations': set(),
            'total_trades': 0,
            'files_by_symbol': defaultdict(int),
            'files_by_timeframe': defaultdict(int),
            'files_by_strategy': defaultdict(int)
        }
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            stats['total_files'] += 1
            
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡º
            parts = file_path.stem.replace('.pkl', '').split('_')
            if len(parts) >= 3:
                symbol = parts[0]
                timeframe = parts[1]
                strategy = '_'.join(parts[2:])
                
                stats['symbols'].add(symbol)
                stats['timeframes'].add(timeframe)
                stats['strategies'].add(strategy)
                stats['symbol_timeframe_combinations'].add(f"{symbol}_{timeframe}")
                
                stats['files_by_symbol'][symbol] += 1
                stats['files_by_timeframe'][timeframe] += 1
                stats['files_by_strategy'][strategy] += 1
                
                # ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°ã‚’é›†è¨ˆ
                try:
                    with gzip.open(file_path, 'rb') as f:
                        trades_data = pickle.load(f)
                    
                    if isinstance(trades_data, list):
                        df = pd.DataFrame(trades_data)
                    elif isinstance(trades_data, dict):
                        df = pd.DataFrame(trades_data)
                    else:
                        df = trades_data
                    
                    if not df.empty:
                        stats['total_trades'] += len(df)
                
                except Exception as e:
                    print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")
        
        # setã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ï¼ˆJSONå¯¾å¿œï¼‰
        stats['symbols'] = sorted(list(stats['symbols']))
        stats['timeframes'] = sorted(list(stats['timeframes']))
        stats['strategies'] = sorted(list(stats['strategies']))
        stats['symbol_timeframe_combinations'] = sorted(list(stats['symbol_timeframe_combinations']))
        
        print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {stats['total_files']}")
        print(f"ğŸ·ï¸ éŠ˜æŸ„æ•°: {len(stats['symbols'])}")
        print(f"â° æ™‚é–“è¶³: {len(stats['timeframes'])}")
        print(f"ğŸ“ˆ æˆ¦ç•¥æ•°: {len(stats['strategies'])}")
        print(f"ğŸ’° ç·ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°: {stats['total_trades']}")
        
        return stats
    
    def _detect_hardcoded_values_detailed(self) -> List[Dict]:
        """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®è©³ç´°æ¤œçŸ¥"""
        violations = []
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
                price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price']
                for col in price_columns:
                    if col in df.columns:
                        values = pd.to_numeric(df[col], errors='coerce').dropna()
                        
                        if len(values) > 0:
                            # å„ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’ãƒã‚§ãƒƒã‚¯
                            for hardcoded_val in self.known_hardcoded_values:
                                matching_count = sum(abs(val - hardcoded_val) < self.tolerance for val in values)
                                
                                if matching_count > 0:
                                    violation_percentage = matching_count / len(values) * 100
                                    
                                    violation = {
                                        'file_path': str(file_path),
                                        'symbol': symbol,
                                        'timeframe': timeframe,
                                        'strategy': strategy,
                                        'column': col,
                                        'hardcoded_value': hardcoded_val,
                                        'matching_count': matching_count,
                                        'total_count': len(values),
                                        'percentage': violation_percentage,
                                        'severity': 'HIGH' if violation_percentage > 50 else 'MEDIUM',
                                        'sample_values': values.head(10).tolist(),
                                        'unique_values': sorted(values.unique().tolist()),
                                        'mean_value': float(values.mean()),
                                        'std_value': float(values.std()),
                                        'cv': float(values.std() / values.mean()) if values.mean() > 0 else 0.0
                                    }
                                    violations.append(violation)
            
            except Exception as e:
                print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼ {file_path.name}: {e}")
        
        # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
        violations.sort(key=lambda x: (x['severity'], -x['percentage']))
        
        print(f"ğŸš¨ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤é•å: {len(violations)}ä»¶")
        
        # ä¸Šä½10ä»¶ã‚’è¡¨ç¤º
        for i, violation in enumerate(violations[:10]):
            print(f"  {i+1}. {violation['symbol']}_{violation['timeframe']}_{violation['strategy']}")
            print(f"     {violation['column']}: {violation['hardcoded_value']} ({violation['percentage']:.1f}%)")
        
        return violations
    
    def _analyze_static_pricing_detailed(self) -> List[Dict]:
        """é™çš„ä¾¡æ ¼è¨­å®šã®è©³ç´°åˆ†æ"""
        static_strategies = []
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã®å¤‰å‹•ã‚’åˆ†æ
                if 'entry_price' in df.columns:
                    entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                    
                    if len(entry_prices) > 5:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«
                        unique_count = len(entry_prices.unique())
                        cv = entry_prices.std() / entry_prices.mean() if entry_prices.mean() > 0 else 0
                        
                        # é™çš„ä¾¡æ ¼è¨­å®šã®åˆ¤å®š
                        is_static = (unique_count <= 3 or cv < 0.001)
                        
                        analysis = {
                            'file_path': str(file_path),
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'strategy': strategy,
                            'unique_prices': unique_count,
                            'coefficient_of_variation': float(cv),
                            'total_trades': len(entry_prices),
                            'mean_price': float(entry_prices.mean()),
                            'std_price': float(entry_prices.std()),
                            'price_range': float(entry_prices.max() - entry_prices.min()),
                            'is_static': is_static,
                            'unique_values': sorted(entry_prices.unique().tolist())[:20],  # æœ€å¤§20ä»¶
                            'severity': 'HIGH' if unique_count == 1 else 'MEDIUM' if unique_count <= 3 else 'LOW'
                        }
                        
                        if is_static:
                            static_strategies.append(analysis)
            
            except Exception as e:
                continue
        
        # æ·±åˆ»åº¦ã§ã‚½ãƒ¼ãƒˆ
        static_strategies.sort(key=lambda x: (x['severity'], x['unique_prices']))
        
        print(f"âš™ï¸ é™çš„ä¾¡æ ¼è¨­å®šæˆ¦ç•¥: {len(static_strategies)}ä»¶")
        
        # çµ±è¨ˆè¡¨ç¤º
        severity_counts = Counter(s['severity'] for s in static_strategies)
        print(f"   HIGH: {severity_counts['HIGH']}ä»¶")
        print(f"   MEDIUM: {severity_counts['MEDIUM']}ä»¶")
        print(f"   LOW: {severity_counts['LOW']}ä»¶")
        
        return static_strategies
    
    def _analyze_price_inconsistencies(self) -> List[Dict]:
        """ä¾¡æ ¼ä¸€è²«æ€§ã®åˆ†æ"""
        inconsistencies = []
        
        # éŠ˜æŸ„ãƒ»æ™‚é–“è¶³ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        symbol_timeframe_groups = defaultdict(list)
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            parts = file_path.stem.replace('.pkl', '').split('_')
            if len(parts) >= 3:
                symbol = parts[0]
                timeframe = parts[1]
                strategy = '_'.join(parts[2:])
                
                key = f"{symbol}_{timeframe}"
                symbol_timeframe_groups[key].append({
                    'strategy': strategy,
                    'file_path': file_path
                })
        
        # å„ã‚°ãƒ«ãƒ¼ãƒ—ã§ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        for key, strategies in symbol_timeframe_groups.items():
            if len(strategies) > 1:
                symbol, timeframe = key.split('_', 1)
                
                strategy_prices = {}
                strategy_details = {}
                
                for strategy_info in strategies:
                    try:
                        with gzip.open(strategy_info['file_path'], 'rb') as f:
                            trades_data = pickle.load(f)
                        
                        if isinstance(trades_data, list):
                            df = pd.DataFrame(trades_data)
                        elif isinstance(trades_data, dict):
                            df = pd.DataFrame(trades_data)
                        else:
                            df = trades_data
                        
                        if df.empty or 'entry_price' not in df.columns:
                            continue
                        
                        entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                        if len(entry_prices) > 0:
                            mean_price = entry_prices.mean()
                            strategy_prices[strategy_info['strategy']] = mean_price
                            strategy_details[strategy_info['strategy']] = {
                                'mean': float(mean_price),
                                'std': float(entry_prices.std()),
                                'count': len(entry_prices),
                                'unique_count': len(entry_prices.unique()),
                                'sample_values': entry_prices.head(5).tolist()
                            }
                    
                    except Exception:
                        continue
                
                # æˆ¦ç•¥é–“ã®ä¾¡æ ¼å·®ã‚’ãƒã‚§ãƒƒã‚¯
                if len(strategy_prices) > 1:
                    prices = list(strategy_prices.values())
                    price_range = max(prices) - min(prices)
                    avg_price = np.mean(prices)
                    
                    # å¹³å‡ä¾¡æ ¼ã®10%ä»¥ä¸Šã®å·®ã¯ä¸€è²«æ€§ã®å•é¡Œ
                    if price_range > avg_price * 0.1:
                        inconsistency = {
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'strategy_count': len(strategy_prices),
                            'price_range': float(price_range),
                            'avg_price': float(avg_price),
                            'deviation_percentage': float(price_range / avg_price * 100),
                            'strategy_prices': {k: float(v) for k, v in strategy_prices.items()},
                            'strategy_details': strategy_details,
                            'severity': 'HIGH' if price_range > avg_price * 0.5 else 'MEDIUM'
                        }
                        inconsistencies.append(inconsistency)
        
        inconsistencies.sort(key=lambda x: -x['deviation_percentage'])
        
        print(f"ğŸ”„ ä¾¡æ ¼ä¸€è²«æ€§ã®å•é¡Œ: {len(inconsistencies)}ä»¶")
        
        return inconsistencies
    
    def _analyze_patterns_and_root_causes(self) -> Dict[str, Any]:
        """ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æã¨æ ¹æœ¬åŸå› ã®æ¨å®š"""
        patterns = {
            'most_affected_symbols': {},
            'most_affected_timeframes': {},
            'most_affected_strategies': {},
            'hardcoded_value_frequency': {},
            'probable_root_causes': []
        }
        
        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤é•åã®åˆ†æ
        symbol_counts = Counter()
        timeframe_counts = Counter()
        strategy_counts = Counter()
        value_counts = Counter()
        
        for violation in self.analysis_results['hardcoded_violations']:
            symbol_counts[violation['symbol']] += 1
            timeframe_counts[violation['timeframe']] += 1
            strategy_counts[violation['strategy']] += 1
            value_counts[violation['hardcoded_value']] += 1
        
        patterns['most_affected_symbols'] = dict(symbol_counts.most_common(10))
        patterns['most_affected_timeframes'] = dict(timeframe_counts.most_common())
        patterns['most_affected_strategies'] = dict(strategy_counts.most_common(10))
        patterns['hardcoded_value_frequency'] = dict(value_counts.most_common())
        
        # æ ¹æœ¬åŸå› ã®æ¨å®š
        root_causes = []
        
        # 1. 100.0ç³»ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®åˆ†æ
        if 100.0 in value_counts and value_counts[100.0] > 50:
            root_causes.append({
                'type': 'DEFAULT_PLACEHOLDER_VALUES',
                'description': '100.0ãŒãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã¨ã—ã¦å¤§é‡ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹',
                'affected_count': value_counts[100.0],
                'likely_source': 'scalable_analysis_system.py, high_leverage_bot_orchestrator.py'
            })
        
        # 2. 1000.0ç³»ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®åˆ†æ
        if 1000.0 in value_counts and value_counts[1000.0] > 50:
            root_causes.append({
                'type': 'FALLBACK_MECHANISM_VALUES',
                'description': '1000.0ãŒãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å€¤ã¨ã—ã¦ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹',
                'affected_count': value_counts[1000.0],
                'likely_source': 'TestHighLeverageBotOrchestrator, fallback mechanisms'
            })
        
        # 3. é™çš„ä¾¡æ ¼è¨­å®šã®åˆ†æ
        static_high_severity = sum(1 for s in self.analysis_results['static_pricing_strategies'] if s['severity'] == 'HIGH')
        if static_high_severity > 100:
            root_causes.append({
                'type': 'STATIC_PRICING_GENERATION',
                'description': 'ä¾¡æ ¼ç”Ÿæˆãƒ­ã‚¸ãƒƒã‚¯ãŒé™çš„å€¤ã‚’å‡ºåŠ›ã—ã¦ã„ã‚‹',
                'affected_count': static_high_severity,
                'likely_source': 'ML prediction models, price calculation logic'
            })
        
        patterns['probable_root_causes'] = root_causes
        
        print(f"ğŸ§  æ ¹æœ¬åŸå› å€™è£œ: {len(root_causes)}ä»¶")
        for cause in root_causes:
            print(f"   {cause['type']}: {cause['description']}")
        
        return patterns
    
    def _generate_detailed_report(self):
        """è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = f"hardcoded_bug_analysis_{timestamp}.json"
        
        # JSONå¯¾å¿œã®ãŸã‚ã«numpyå‹ã¨ä»–ã®å‹ã‚’å¤‰æ›
        def convert_numpy_types(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, np.bool_):
                return bool(obj)
            elif isinstance(obj, bool):
                return obj
            elif isinstance(obj, dict):
                return {k: convert_numpy_types(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert_numpy_types(v) for v in obj]
            elif hasattr(obj, '__dict__'):
                return str(obj)
            return obj
        
        converted_results = convert_numpy_types(self.analysis_results)
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(converted_results, f, indent=2, ensure_ascii=False)
        
        print(f"\nğŸ“„ è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_file}")
        
        # ã‚µãƒãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤º
        print("\n" + "=" * 60)
        print("ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
        print("=" * 60)
        
        print(f"ğŸš¨ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤é•å: {len(self.analysis_results['hardcoded_violations'])}ä»¶")
        print(f"âš™ï¸ é™çš„ä¾¡æ ¼è¨­å®š: {len(self.analysis_results['static_pricing_strategies'])}ä»¶")
        print(f"ğŸ”„ ä¾¡æ ¼ä¸€è²«æ€§å•é¡Œ: {len(self.analysis_results['price_inconsistencies'])}ä»¶")
        
        if 'pattern_analysis' in self.analysis_results:
            patterns = self.analysis_results['pattern_analysis']
            print(f"\nğŸ¯ æœ€ã‚‚å½±éŸ¿ã‚’å—ã‘ãŸéŠ˜æŸ„:")
            for symbol, count in list(patterns['most_affected_symbols'].items())[:5]:
                print(f"   {symbol}: {count}ä»¶")
            
            print(f"\nâ° æœ€ã‚‚å½±éŸ¿ã‚’å—ã‘ãŸæ™‚é–“è¶³:")
            for timeframe, count in list(patterns['most_affected_timeframes'].items())[:5]:
                print(f"   {timeframe}: {count}ä»¶")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚°è©³ç´°ãƒ‡ãƒãƒƒã‚°ãƒ»åˆ†æ")
    print("=" * 60)
    
    detector = HardcodedValueBugDetector()
    results = detector.run_comprehensive_analysis()
    
    print("\nâœ… åˆ†æå®Œäº†ï¼è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆã‚’ã”ç¢ºèªãã ã•ã„ã€‚")
    
    return results

if __name__ == '__main__':
    main()