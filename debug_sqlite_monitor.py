#!/usr/bin/env python3
"""
SQLiteè©³ç´°ç›£è¦–ãƒ„ãƒ¼ãƒ«
ãƒ­ãƒƒã‚¯ç«¶åˆã€ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã€WALãƒ¢ãƒ¼ãƒ‰ã®åˆ†æ
"""

import sqlite3
import time
import os
import threading
import logging
import subprocess
from datetime import datetime
from pathlib import Path
import json

logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SQLiteDetailedMonitor:
    def __init__(self):
        self.db_path = Path(__file__).parent / "large_scale_analysis" / "analysis.db"
        self.monitoring_data = []
        self.lock_events = []
        self.transaction_timings = []
        self.connection_pool = []
        
    def enable_sqlite_logging(self):
        """SQLiteã®è©³ç´°ãƒ­ã‚°ã‚’æœ‰åŠ¹åŒ–"""
        logger.info("ğŸ”§ SQLiteè©³ç´°ãƒ­ã‚°è¨­å®š")
        
        # SQLiteã®ãƒ‡ãƒãƒƒã‚°ãƒ“ãƒ«ãƒ‰ã§ãªã„å ´åˆã®ä»£æ›¿ç›£è¦–æ–¹æ³•
        try:
            # WALãƒ¢ãƒ¼ãƒ‰ã®ç¢ºèª
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("PRAGMA journal_mode")
                journal_mode = cursor.fetchone()[0]
                
                cursor.execute("PRAGMA synchronous")
                synchronous = cursor.fetchone()[0]
                
                cursor.execute("PRAGMA cache_size")
                cache_size = cursor.fetchone()[0]
                
                cursor.execute("PRAGMA temp_store")
                temp_store = cursor.fetchone()[0]
                
                logger.info(f"ğŸ“Š SQLiteè¨­å®š:")
                logger.info(f"  journal_mode: {journal_mode}")
                logger.info(f"  synchronous: {synchronous}")
                logger.info(f"  cache_size: {cache_size}")
                logger.info(f"  temp_store: {temp_store}")
                
                # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–ã®ææ¡ˆ
                if journal_mode != 'WAL':
                    logger.warning("âš ï¸ WALãƒ¢ãƒ¼ãƒ‰æœªä½¿ç”¨ - ä¸¦è¡Œå‡¦ç†æ€§èƒ½ãŒåˆ¶é™ã•ã‚Œã‚‹å¯èƒ½æ€§")
                
                return {
                    'journal_mode': journal_mode,
                    'synchronous': synchronous,
                    'cache_size': cache_size,
                    'temp_store': temp_store
                }
                
        except Exception as e:
            logger.error(f"âŒ SQLiteè¨­å®šå–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def optimize_sqlite_settings(self):
        """SQLiteã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–"""
        logger.info("âš¡ SQLiteè¨­å®šæœ€é©åŒ–")
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                
                # WALãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´ï¼ˆä¸¦è¡Œèª­ã¿å–ã‚Šå‘ä¸Šï¼‰
                cursor.execute("PRAGMA journal_mode=WAL")
                logger.info("  âœ… WALãƒ¢ãƒ¼ãƒ‰æœ‰åŠ¹åŒ–")
                
                # åŒæœŸè¨­å®šã®æœ€é©åŒ–
                cursor.execute("PRAGMA synchronous=NORMAL")
                logger.info("  âœ… åŒæœŸãƒ¢ãƒ¼ãƒ‰æœ€é©åŒ–")
                
                # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºå¢—åŠ 
                cursor.execute("PRAGMA cache_size=10000")
                logger.info("  âœ… ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚µã‚¤ã‚ºå¢—åŠ ")
                
                # ä¸€æ™‚ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’ãƒ¡ãƒ¢ãƒªã«
                cursor.execute("PRAGMA temp_store=MEMORY")
                logger.info("  âœ… ä¸€æ™‚ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ãƒ¡ãƒ¢ãƒªåŒ–")
                
                # æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š
                conn.execute("PRAGMA busy_timeout=30000")  # 30ç§’
                logger.info("  âœ… ãƒ“ã‚¸ãƒ¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®š")
                
                conn.commit()
                
        except Exception as e:
            logger.error(f"âŒ SQLiteæœ€é©åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def monitor_database_locks(self, duration_seconds=60):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯çŠ¶æ³ã®ç›£è¦–"""
        logger.info(f"ğŸ”’ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ­ãƒƒã‚¯ç›£è¦–é–‹å§‹ ({duration_seconds}ç§’)")
        
        def lock_monitor():
            start_time = time.time()
            connection_attempts = 0
            successful_connections = 0
            lock_timeouts = 0
            
            while time.time() - start_time < duration_seconds:
                try:
                    connection_attempts += 1
                    lock_start = time.time()
                    
                    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆä»˜ãDBæ¥ç¶šãƒ†ã‚¹ãƒˆ
                    with sqlite3.connect(self.db_path, timeout=1.0) as conn:
                        conn.execute("PRAGMA busy_timeout=1000")  # 1ç§’
                        cursor = conn.cursor()
                        
                        # è»½ã„ã‚¯ã‚¨ãƒªã§ãƒ­ãƒƒã‚¯çŠ¶æ³ãƒ†ã‚¹ãƒˆ
                        cursor.execute("SELECT COUNT(*) FROM analyses WHERE task_status='pending'")
                        result = cursor.fetchone()
                        
                        successful_connections += 1
                        lock_end = time.time()
                        lock_duration = lock_end - lock_start
                        
                        self.monitoring_data.append({
                            'timestamp': lock_end,
                            'operation': 'connection_test',
                            'duration': lock_duration,
                            'success': True,
                            'pending_tasks': result[0] if result else 0
                        })
                        
                        if lock_duration > 0.1:
                            logger.warning(f"âš ï¸ é•·æ™‚é–“æ¥ç¶š: {lock_duration:.3f}ç§’")
                
                except sqlite3.OperationalError as e:
                    lock_end = time.time()
                    lock_duration = lock_end - lock_start
                    
                    if "database is locked" in str(e) or "busy" in str(e):
                        lock_timeouts += 1
                        logger.error(f"ğŸ”´ ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ #{lock_timeouts}: {lock_duration:.3f}ç§’")
                        
                        self.lock_events.append({
                            'timestamp': lock_end,
                            'error': str(e),
                            'duration': lock_duration,
                            'type': 'lock_timeout'
                        })
                    else:
                        logger.error(f"âŒ DBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
                
                except Exception as e:
                    logger.error(f"âŒ ç›£è¦–ã‚¨ãƒ©ãƒ¼: {e}")
                
                time.sleep(0.2)  # 200msé–“éš”
            
            # ç›£è¦–çµæœã‚µãƒãƒªãƒ¼
            success_rate = (successful_connections / connection_attempts * 100) if connection_attempts > 0 else 0
            logger.info(f"ğŸ“Š ãƒ­ãƒƒã‚¯ç›£è¦–å®Œäº†:")
            logger.info(f"  æ¥ç¶šè©¦è¡Œ: {connection_attempts}å›")
            logger.info(f"  æˆåŠŸ: {successful_connections}å› ({success_rate:.1f}%)")
            logger.info(f"  ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {lock_timeouts}å›")
        
        monitor_thread = threading.Thread(target=lock_monitor, daemon=True)
        monitor_thread.start()
        return monitor_thread
    
    def test_concurrent_transactions(self, num_workers=30):
        """ä¸¦è¡Œãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã®ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ"""
        logger.info(f"ğŸ”¥ ä¸¦è¡Œãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆé–‹å§‹: {num_workers}ãƒ¯ãƒ¼ã‚«ãƒ¼")
        
        test_symbol = f"STRESS_TEST_{int(time.time())}"
        
        def transaction_worker(worker_id):
            worker_start = time.time()
            transaction_success = False
            
            try:
                # å®Ÿéš›ã®å‡¦ç†ã¨åŒã˜é‡ã„ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³
                with sqlite3.connect(self.db_path, timeout=10.0) as conn:
                    conn.execute("PRAGMA busy_timeout=10000")  # 10ç§’
                    cursor = conn.cursor()
                    
                    # BEGIN TRANSACTION
                    trans_start = time.time()
                    
                    # INSERT
                    cursor.execute('''
                        INSERT INTO analyses 
                        (symbol, timeframe, config, task_status, execution_id, status)
                        VALUES (?, ?, ?, 'pending', ?, 'running')
                    ''', (test_symbol, '1h', f'Worker_{worker_id}', f'stress_test_{worker_id}'))
                    
                    # å‡¦ç†æ™‚é–“ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
                    time.sleep(0.01)  # 10mså‡¦ç†æ™‚é–“
                    
                    # UPDATE
                    cursor.execute('''
                        UPDATE analyses SET
                            task_status = 'completed', total_return = ?, sharpe_ratio = ?,
                            status = 'no_signal', error_message = ?
                        WHERE symbol = ? AND timeframe = ? AND config = ?
                    ''', (0.0, 0.0, 'Stress test', test_symbol, '1h', f'Worker_{worker_id}'))
                    
                    # COMMIT
                    conn.commit()
                    trans_end = time.time()
                    
                    transaction_success = True
                    trans_duration = trans_end - trans_start
                    
                    self.transaction_timings.append({
                        'worker_id': worker_id,
                        'duration': trans_duration,
                        'success': True,
                        'start_time': trans_start,
                        'end_time': trans_end
                    })
                    
                    logger.debug(f"âœ… Worker {worker_id}: ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æˆåŠŸ ({trans_duration:.3f}ç§’)")
            
            except sqlite3.OperationalError as e:
                worker_end = time.time()
                worker_duration = worker_end - worker_start
                
                logger.error(f"ğŸ”´ Worker {worker_id}: DBç«¶åˆã‚¨ãƒ©ãƒ¼ ({worker_duration:.3f}ç§’) - {e}")
                
                self.transaction_timings.append({
                    'worker_id': worker_id,
                    'duration': worker_duration,
                    'success': False,
                    'error': str(e),
                    'start_time': worker_start,
                    'end_time': worker_end
                })
                
                self.lock_events.append({
                    'timestamp': worker_end,
                    'worker_id': worker_id,
                    'error': str(e),
                    'type': 'transaction_lock',
                    'duration': worker_duration
                })
            
            except Exception as e:
                worker_end = time.time()
                worker_duration = worker_end - worker_start
                
                logger.error(f"âŒ Worker {worker_id}: äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ ({worker_duration:.3f}ç§’) - {e}")
                
                self.transaction_timings.append({
                    'worker_id': worker_id,
                    'duration': worker_duration,
                    'success': False,
                    'error': str(e),
                    'start_time': worker_start,
                    'end_time': worker_end
                })
        
        # ä¸¦è¡Œå®Ÿè¡Œ
        threads = []
        stress_start = time.time()
        
        for i in range(num_workers):
            thread = threading.Thread(target=transaction_worker, args=(i,))
            threads.append(thread)
            thread.start()
            
            # å°‘ã—ãšã‚‰ã—ã¦èµ·å‹•ï¼ˆãƒªã‚¢ãƒ«ãªä¸¦è¡ŒçŠ¶æ³ã‚’æ¨¡æ“¬ï¼‰
            time.sleep(0.01)
        
        # å…¨å®Œäº†å¾…æ©Ÿ
        for thread in threads:
            thread.join(timeout=30)  # 30ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        
        stress_end = time.time()
        total_stress_time = stress_end - stress_start
        
        # çµæœåˆ†æ
        successful_transactions = len([t for t in self.transaction_timings if t['success']])
        failed_transactions = len([t for t in self.transaction_timings if not t['success']])
        
        logger.info(f"ğŸ“Š ä¸¦è¡Œãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆå®Œäº†:")
        logger.info(f"  ç·æ™‚é–“: {total_stress_time:.3f}ç§’")
        logger.info(f"  æˆåŠŸ: {successful_transactions}å€‹")
        logger.info(f"  å¤±æ•—: {failed_transactions}å€‹")
        
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM analyses WHERE symbol = ?", (test_symbol,))
                conn.commit()
                logger.info("ğŸ§¹ ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆãƒ¬ã‚³ãƒ¼ãƒ‰å‰Šé™¤å®Œäº†")
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¤±æ•—: {e}")
    
    def analyze_wal_file(self):
        """WALãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ"""
        wal_path = Path(str(self.db_path) + "-wal")
        shm_path = Path(str(self.db_path) + "-shm")
        
        logger.info("ğŸ“ WALãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ")
        
        try:
            if wal_path.exists():
                wal_size = wal_path.stat().st_size
                logger.info(f"  WALãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {wal_size:,} bytes")
                
                if wal_size > 1000000:  # 1MBä»¥ä¸Š
                    logger.warning(f"âš ï¸ å¤§ããªWALãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: {wal_size:,} bytes")
                    logger.warning("  WALãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆãŒå¿…è¦ãªå¯èƒ½æ€§")
            else:
                logger.info("  WALãƒ•ã‚¡ã‚¤ãƒ«: å­˜åœ¨ã—ã¾ã›ã‚“")
            
            if shm_path.exists():
                shm_size = shm_path.stat().st_size
                logger.info(f"  SHMãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {shm_size:,} bytes")
            else:
                logger.info("  SHMãƒ•ã‚¡ã‚¤ãƒ«: å­˜åœ¨ã—ã¾ã›ã‚“")
                
        except Exception as e:
            logger.error(f"âŒ WALãƒ•ã‚¡ã‚¤ãƒ«åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
    
    def generate_sqlite_report(self):
        """SQLiteç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        print("\n" + "="*70)
        print("ğŸ—ƒï¸ SQLiteè©³ç´°ç›£è¦–ãƒ¬ãƒãƒ¼ãƒˆ")
        print("="*70)
        
        # 1. ãƒ­ãƒƒã‚¯ç«¶åˆçµ±è¨ˆ
        lock_count = len(self.lock_events)
        print(f"\nğŸ”’ ãƒ­ãƒƒã‚¯ç«¶åˆçµ±è¨ˆ:")
        print(f"  ãƒ­ãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ: {lock_count}ä»¶")
        
        if lock_count > 0:
            lock_types = {}
            for event in self.lock_events:
                event_type = event.get('type', 'unknown')
                lock_types[event_type] = lock_types.get(event_type, 0) + 1
            
            for lock_type, count in lock_types.items():
                print(f"    {lock_type}: {count}ä»¶")
            
            # æœ€æ–°5ä»¶ã®ãƒ­ãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ
            print(f"  æœ€æ–°ãƒ­ãƒƒã‚¯ã‚¤ãƒ™ãƒ³ãƒˆ:")
            for event in self.lock_events[-5:]:
                timestamp = event['timestamp']
                if isinstance(timestamp, float):
                    time_str = datetime.fromtimestamp(timestamp).strftime('%H:%M:%S.%f')[:-3]
                else:
                    time_str = str(timestamp)
                print(f"    {time_str} - {event.get('type', 'unknown')}: {event.get('error', 'N/A')}")
        
        # 2. ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ
        if self.transaction_timings:
            successful_trans = [t for t in self.transaction_timings if t['success']]
            failed_trans = [t for t in self.transaction_timings if not t['success']]
            
            print(f"\nğŸ’¾ ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³çµ±è¨ˆ:")
            print(f"  ç·æ•°: {len(self.transaction_timings)}å€‹")
            print(f"  æˆåŠŸ: {len(successful_trans)}å€‹")
            print(f"  å¤±æ•—: {len(failed_trans)}å€‹")
            
            if successful_trans:
                trans_times = [t['duration'] for t in successful_trans]
                avg_time = sum(trans_times) / len(trans_times)
                max_time = max(trans_times)
                
                print(f"  å¹³å‡æ™‚é–“: {avg_time:.3f}ç§’")
                print(f"  æœ€å¤§æ™‚é–“: {max_time:.3f}ç§’")
                
                if max_time > 1.0:
                    print(f"  âš ï¸ é•·æ™‚é–“ãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³æ¤œå‡º: {max_time:.3f}ç§’")
        
        # 3. æ¥ç¶šç›£è¦–çµ±è¨ˆ
        if self.monitoring_data:
            connection_times = [m['duration'] for m in self.monitoring_data if m['success']]
            
            if connection_times:
                print(f"\nğŸ”Œ æ¥ç¶šç›£è¦–çµ±è¨ˆ:")
                print(f"  æˆåŠŸæ¥ç¶š: {len(connection_times)}å›")
                print(f"  å¹³å‡æ¥ç¶šæ™‚é–“: {sum(connection_times)/len(connection_times):.3f}ç§’")
                print(f"  æœ€å¤§æ¥ç¶šæ™‚é–“: {max(connection_times):.3f}ç§’")
        
        # 4. SQLiteå¥å…¨æ€§è©•ä¾¡
        print(f"\nğŸ¥ SQLiteå¥å…¨æ€§è©•ä¾¡:")
        
        # ãƒ­ãƒƒã‚¯ç«¶åˆç‡
        total_operations = len(self.monitoring_data) + len(self.transaction_timings)
        if total_operations > 0:
            lock_rate = len(self.lock_events) / total_operations * 100
            print(f"  ãƒ­ãƒƒã‚¯ç«¶åˆç‡: {lock_rate:.1f}%")
            
            if lock_rate > 10:
                print(f"  ğŸ”´ é«˜ã„ãƒ­ãƒƒã‚¯ç«¶åˆç‡ - SQLiteä¸¦è¡Œå‡¦ç†é™ç•Œã®å¯èƒ½æ€§")
            elif lock_rate > 5:
                print(f"  ğŸŸ¡ ä¸­ç¨‹åº¦ã®ãƒ­ãƒƒã‚¯ç«¶åˆ - æœ€é©åŒ–ãŒæ¨å¥¨")
            else:
                print(f"  âœ… å¥å…¨ãªãƒ­ãƒƒã‚¯ç«¶åˆç‡")
        
        # çµè«–
        print(f"\nğŸ“‹ åˆ†æçµè«–:")
        if len(self.lock_events) > 5:
            print(f"  ğŸš¨ SQLiteä¸¦è¡Œå‡¦ç†åˆ¶é™ãŒ5ç§’å®Œäº†ã®åŸå› ã§ã‚ã‚‹å¯èƒ½æ€§ãŒé«˜ã„")
            print(f"  ğŸ’¡ æ¨å¥¨å¯¾å¿œ: WALãƒ¢ãƒ¼ãƒ‰ã€æ¥ç¶šãƒ—ãƒ¼ãƒ«ã€ã¾ãŸã¯PostgreSQLã¸ã®ç§»è¡Œ")
        elif len(self.lock_events) > 0:
            print(f"  âš ï¸ è»½å¾®ãªãƒ­ãƒƒã‚¯ç«¶åˆæ¤œå‡º - ç›£è¦–ç¶™ç¶šãŒå¿…è¦")
        else:
            print(f"  âœ… SQLiteãƒ­ãƒƒã‚¯å•é¡Œã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        print("="*70)

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
    monitor = SQLiteDetailedMonitor()
    
    print("ğŸ—ƒï¸ SQLiteè©³ç´°ç›£è¦–ãƒ„ãƒ¼ãƒ«")
    print("="*70)
    
    try:
        # 1. ç¾åœ¨ã®SQLiteè¨­å®šç¢ºèª
        print("\nğŸ“Š ç¾åœ¨ã®SQLiteè¨­å®šç¢ºèª")
        settings = monitor.enable_sqlite_logging()
        
        # 2. SQLiteæœ€é©åŒ–
        print("\nâš¡ SQLiteè¨­å®šæœ€é©åŒ–")
        monitor.optimize_sqlite_settings()
        
        # 3. WALãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
        print("\nğŸ“ WALãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ")
        monitor.analyze_wal_file()
        
        # 4. ãƒ­ãƒƒã‚¯ç›£è¦–é–‹å§‹
        print("\nğŸ”’ ãƒ­ãƒƒã‚¯ç›£è¦–é–‹å§‹")
        lock_thread = monitor.monitor_database_locks(duration_seconds=30)
        
        # 5. ä¸¦è¡Œãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ
        print("\nğŸ”¥ ä¸¦è¡Œãƒˆãƒ©ãƒ³ã‚¶ã‚¯ã‚·ãƒ§ãƒ³ã‚¹ãƒˆãƒ¬ã‚¹ãƒ†ã‚¹ãƒˆ")
        monitor.test_concurrent_transactions(num_workers=30)
        
        # 6. å®Œäº†å¾…æ©Ÿ
        print("\nâ³ ç›£è¦–å®Œäº†å¾…æ©Ÿ...")
        time.sleep(5)
        
        # 7. ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        monitor.generate_sqlite_report()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç›£è¦–ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
        monitor.generate_sqlite_report()
        
    except Exception as e:
        print(f"\nâŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        monitor.generate_sqlite_report()

if __name__ == "__main__":
    main()