"""
æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºã‚¨ãƒ³ã‚¸ãƒ³
scalable_analysis_systemã§ä½¿ç”¨ã™ã‚‹ãŸã‚ã®çµ±åˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""

import pandas as pd
import numpy as np
from scipy.signal import argrelextrema
from typing import List, Dict, Any, Optional
import sys
import os
import logging

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from interfaces.data_types import SupportResistanceLevel

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)
logger.setLevel(logging.INFO)


class SupportResistanceDetector:
    """
    æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºã‚¨ãƒ³ã‚¸ãƒ³
    æ—¢å­˜ã®support_resistance_visualizer.pyã®æ©Ÿèƒ½ã‚’çµ±åˆ
    """
    
    def __init__(self, min_touches: int = 2, tolerance_pct: float = 0.01, fractal_window: int = 5):
        """
        Args:
            min_touches: æœ‰åŠ¹ãªæ”¯æŒç·šãƒ»æŠµæŠ—ç·šã¨èªå®šã™ã‚‹ãŸã‚ã®æœ€å°ã‚¿ãƒƒãƒå›æ•°
            tolerance_pct: ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°è¨±å®¹ç¯„å›²ï¼ˆ%ï¼‰
            fractal_window: ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«æ¤œå‡ºã®ã‚¦ã‚£ãƒ³ãƒ‰ã‚¦ã‚µã‚¤ã‚º
        """
        self.min_touches = min_touches
        self.tolerance_pct = tolerance_pct
        self.fractal_window = fractal_window
    
    def detect_levels_from_ohlcv(self, df: pd.DataFrame, current_price: float) -> tuple[List[SupportResistanceLevel], List[SupportResistanceLevel]]:
        """
        OHLCVãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ”¯æŒç·šãƒ»æŠµæŠ—ç·šã‚’æ¤œå‡º
        
        Args:
            df: OHLCVãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ  (columns: timestamp, open, high, low, close, volume)
            current_price: ç¾åœ¨ä¾¡æ ¼
            
        Returns:
            tuple: (æ”¯æŒç·šãƒªã‚¹ãƒˆ, æŠµæŠ—ç·šãƒªã‚¹ãƒˆ)
        """
        if len(df) < 10:
            raise ValueError(f"ãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚æœ€ä½10æœ¬å¿…è¦ã§ã™ãŒã€{len(df)}æœ¬ã—ã‹ã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        try:
            # ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«ãƒ¬ãƒ™ãƒ«ã‚’æ¤œå‡º
            resistance_levels, support_levels = self._detect_fractal_levels(df)
            
            # ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°
            resistance_clusters = self._cluster_price_levels(resistance_levels)
            support_clusters = self._cluster_price_levels(support_levels)
            
            # è©³ç´°ãªåˆ†æã‚’å®Ÿè¡Œ
            resistance_objects = []
            support_objects = []
            
            # æŠµæŠ—ç·šã®å‡¦ç†
            for cluster in resistance_clusters:
                if len(cluster) >= self.min_touches:
                    level_info = self._calculate_level_details(cluster, df)
                    if level_info and level_info['price'] > current_price:  # ç¾åœ¨ä¾¡æ ¼ã‚ˆã‚Šä¸Šã®æŠµæŠ—ç·šã®ã¿
                        distance_pct = ((level_info['price'] - current_price) / current_price) * 100
                        resistance_objects.append(
                            SupportResistanceLevel(
                                price=level_info['price'],
                                strength=level_info['strength'],
                                touch_count=level_info['touch_count'],
                                level_type='resistance',
                                first_touch=pd.to_datetime(min(level_info.get('timestamps', [df['timestamp'].iloc[0]]))),
                                last_touch=pd.to_datetime(max(level_info.get('timestamps', [df['timestamp'].iloc[-1]]))),
                                volume_at_level=level_info.get('avg_volume', 0),
                                distance_from_current=distance_pct
                            )
                        )
            
            # æ”¯æŒç·šã®å‡¦ç†
            for cluster in support_clusters:
                if len(cluster) >= self.min_touches:
                    level_info = self._calculate_level_details(cluster, df)
                    if level_info and level_info['price'] < current_price:  # ç¾åœ¨ä¾¡æ ¼ã‚ˆã‚Šä¸‹ã®æ”¯æŒç·šã®ã¿
                        distance_pct = ((current_price - level_info['price']) / current_price) * 100
                        support_objects.append(
                            SupportResistanceLevel(
                                price=level_info['price'],
                                strength=level_info['strength'],
                                touch_count=level_info['touch_count'],
                                level_type='support',
                                first_touch=pd.to_datetime(min(level_info.get('timestamps', [df['timestamp'].iloc[0]]))),
                                last_touch=pd.to_datetime(max(level_info.get('timestamps', [df['timestamp'].iloc[-1]]))),
                                volume_at_level=level_info.get('avg_volume', 0),
                                distance_from_current=distance_pct
                            )
                        )
            
            # å¼·åº¦é †ã§ã‚½ãƒ¼ãƒˆ
            resistance_objects.sort(key=lambda x: x.strength, reverse=True)
            support_objects.sort(key=lambda x: x.strength, reverse=True)
            
            # æ¤œå‡ºæˆåŠŸã‚’ãƒ­ã‚°ã«å‡ºåŠ›
            if support_objects or resistance_objects:
                logger.info(f"âœ… æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºæˆåŠŸ:")
                logger.info(f"   ğŸ“Š æ”¯æŒç·š: {len(support_objects)}å€‹æ¤œå‡º")
                if support_objects:
                    for i, s in enumerate(support_objects[:3], 1):  # ä¸Šä½3å€‹è¡¨ç¤º
                        logger.info(f"      {i}. ä¾¡æ ¼: ${s.price:.2f} (ç¾åœ¨ä¾¡æ ¼ã®{s.distance_from_current:.1f}%ä¸‹) å¼·åº¦: {s.strength:.2f} ã‚¿ãƒƒãƒæ•°: {s.touch_count}")
                    if len(support_objects) > 3:
                        logger.info(f"      ... ä»–{len(support_objects)-3}å€‹")
                        
                logger.info(f"   ğŸ“ˆ æŠµæŠ—ç·š: {len(resistance_objects)}å€‹æ¤œå‡º")
                if resistance_objects:
                    for i, r in enumerate(resistance_objects[:3], 1):  # ä¸Šä½3å€‹è¡¨ç¤º
                        logger.info(f"      {i}. ä¾¡æ ¼: ${r.price:.2f} (ç¾åœ¨ä¾¡æ ¼ã®{r.distance_from_current:.1f}%ä¸Š) å¼·åº¦: {r.strength:.2f} ã‚¿ãƒƒãƒæ•°: {r.touch_count}")
                    if len(resistance_objects) > 3:
                        logger.info(f"      ... ä»–{len(resistance_objects)-3}å€‹")
            else:
                logger.warning(f"âš ï¸  æ”¯æŒç·šãƒ»æŠµæŠ—ç·šãŒæ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ (ç¾åœ¨ä¾¡æ ¼: ${current_price:.2f})")
            
            return support_objects, resistance_objects
            
        except Exception as e:
            raise Exception(f"æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºã«å¤±æ•—: {str(e)}")
    
    def _detect_fractal_levels(self, df: pd.DataFrame) -> tuple[List[tuple], List[tuple]]:
        """ãƒ•ãƒ©ã‚¯ã‚¿ãƒ«åˆ†æã«ã‚ˆã‚‹å±€æ‰€æœ€é«˜å€¤ãƒ»æœ€å®‰å€¤ã®æ¤œå‡º"""
        high = df['high']
        low = df['low']
        
        # å±€æ‰€æœ€é«˜å€¤ï¼ˆæŠµæŠ—ç·šå€™è£œï¼‰
        resistance_indices = argrelextrema(high.values, np.greater, order=self.fractal_window)[0]
        resistance_levels = [(df.iloc[i]['timestamp'], high.iloc[i]) for i in resistance_indices]
        
        # å±€æ‰€æœ€å®‰å€¤ï¼ˆæ”¯æŒç·šå€™è£œï¼‰
        support_indices = argrelextrema(low.values, np.less, order=self.fractal_window)[0]
        support_levels = [(df.iloc[i]['timestamp'], low.iloc[i]) for i in support_indices]
        
        return resistance_levels, support_levels
    
    def _cluster_price_levels(self, levels: List[tuple]) -> List[List[tuple]]:
        """è¿‘ã„ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«ã‚’ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°"""
        if not levels:
            return []
        
        # ä¾¡æ ¼ã§ã‚½ãƒ¼ãƒˆ
        sorted_levels = sorted(levels, key=lambda x: x[1])
        clusters = []
        current_cluster = [sorted_levels[0]]
        
        for i in range(1, len(sorted_levels)):
            current_price = sorted_levels[i][1]
            cluster_avg = np.mean([level[1] for level in current_cluster])
            
            # è¨±å®¹ç¯„å›²å†…ãªã‚‰åŒã˜ã‚¯ãƒ©ã‚¹ã‚¿ã«è¿½åŠ 
            if abs(current_price - cluster_avg) / cluster_avg <= self.tolerance_pct:
                current_cluster.append(sorted_levels[i])
            else:
                # æ–°ã—ã„ã‚¯ãƒ©ã‚¹ã‚¿ã‚’é–‹å§‹
                clusters.append(current_cluster)
                current_cluster = [sorted_levels[i]]
        
        clusters.append(current_cluster)
        return clusters
    
    def _calculate_level_details(self, cluster: List[tuple], df: pd.DataFrame, window: int = 10) -> Optional[Dict[str, Any]]:
        """å„ãƒ¬ãƒ™ãƒ«ã®è©³ç´°æƒ…å ±ã‚’è¨ˆç®—"""
        if len(cluster) < 1:
            return None
        
        touch_count = len(cluster)
        level_price = np.mean([level[1] for level in cluster])
        timestamps = [level[0] for level in cluster]
        
        # åç™ºã®å¼·ã•ã¨å‡ºæ¥é«˜ã‚’è¨ˆç®—
        bounce_strengths = []
        volume_spikes = []
        
        for timestamp in timestamps:
            try:
                idx = df[df['timestamp'] == timestamp].index[0]
                start_idx = max(0, idx - window//2)
                end_idx = min(len(df), idx + window//2 + 1)
                
                local_data = df.iloc[start_idx:end_idx]
                if len(local_data) > 0:
                    # åç™ºå¼·åº¦è¨ˆç®—
                    high_range = local_data['high'].max() - local_data['high'].min()
                    low_range = local_data['low'].max() - local_data['low'].min()
                    price_range = max(high_range, low_range)
                    bounce_strength = price_range / level_price if level_price > 0 else 0
                    bounce_strengths.append(bounce_strength)
                    
                    # å‡ºæ¥é«˜ã‚¹ãƒ‘ã‚¤ã‚¯è¨ˆç®—
                    touch_volume = df.iloc[idx]['volume']
                    avg_volume = df['volume'].rolling(window=20).mean().iloc[idx]
                    volume_spike = touch_volume / avg_volume if avg_volume > 0 else 1
                    volume_spikes.append(volume_spike)
            except:
                continue
        
        avg_bounce = np.mean(bounce_strengths) if bounce_strengths else 0
        avg_volume_spike = np.mean(volume_spikes) if volume_spikes else 1
        
        # æ™‚é–“çš„è¦ç´ 
        if len(timestamps) > 1:
            time_span = (pd.to_datetime(max(timestamps)) - pd.to_datetime(min(timestamps))).total_seconds() / 3600
            recency = (df['timestamp'].max() - pd.to_datetime(max(timestamps))).total_seconds() / 3600
        else:
            time_span = 0
            recency = float('inf')
        
        # ç·åˆå¼·åº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
        touch_weight = 3
        bounce_weight = 50
        time_weight = 0.05
        recency_weight = 0.02
        volume_weight = 10
        
        raw_strength = (touch_count * touch_weight + 
                       avg_bounce * bounce_weight + 
                       time_span * time_weight - 
                       recency * recency_weight +
                       avg_volume_spike * volume_weight)
        
        # 0.0-1.0ã®ç¯„å›²ã«æ­£è¦åŒ–
        strength = min(max(raw_strength / 200.0, 0.0), 1.0)
        
        return {
            'price': level_price,
            'strength': strength,
            'touch_count': touch_count,
            'avg_bounce': avg_bounce,
            'time_span': time_span,
            'recency': recency,
            'timestamps': timestamps,
            'avg_volume': np.mean([df.iloc[df[df['timestamp'] == ts].index[0]]['volume'] for ts in timestamps if len(df[df['timestamp'] == ts]) > 0]) if timestamps else 0
        }
    
    def get_nearest_levels(self, support_levels: List[SupportResistanceLevel], 
                          resistance_levels: List[SupportResistanceLevel], 
                          current_price: float, max_count: int = 3) -> tuple[List[SupportResistanceLevel], List[SupportResistanceLevel]]:
        """
        ç¾åœ¨ä¾¡æ ¼ã«æœ€ã‚‚è¿‘ã„æ”¯æŒç·šãƒ»æŠµæŠ—ç·šã‚’å–å¾—
        
        Args:
            support_levels: æ”¯æŒç·šãƒªã‚¹ãƒˆ
            resistance_levels: æŠµæŠ—ç·šãƒªã‚¹ãƒˆ
            current_price: ç¾åœ¨ä¾¡æ ¼
            max_count: æœ€å¤§å–å¾—æ•°
            
        Returns:
            tuple: (æœ€å¯„ã‚Šæ”¯æŒç·šãƒªã‚¹ãƒˆ, æœ€å¯„ã‚ŠæŠµæŠ—ç·šãƒªã‚¹ãƒˆ)
        """
        # ç¾åœ¨ä¾¡æ ¼ã‚ˆã‚Šä¸‹ã®æ”¯æŒç·šï¼ˆä¾¡æ ¼ã®è¿‘ã„é †ï¼‰
        valid_supports = [s for s in support_levels if s.price < current_price]
        valid_supports.sort(key=lambda x: abs(current_price - x.price))
        nearest_supports = valid_supports[:max_count]
        
        # ç¾åœ¨ä¾¡æ ¼ã‚ˆã‚Šä¸Šã®æŠµæŠ—ç·šï¼ˆä¾¡æ ¼ã®è¿‘ã„é †ï¼‰
        valid_resistances = [r for r in resistance_levels if r.price > current_price]
        valid_resistances.sort(key=lambda x: abs(x.price - current_price))
        nearest_resistances = valid_resistances[:max_count]
        
        return nearest_supports, nearest_resistances


def test_support_resistance_detector():
    """æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºã®ãƒ†ã‚¹ãƒˆé–¢æ•°"""
    print("=== æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºãƒ†ã‚¹ãƒˆ ===")
    
    # ã‚µãƒ³ãƒ—ãƒ«OHLCVãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    np.random.seed(42)
    dates = pd.date_range('2024-01-01', periods=1000, freq='1h')
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰ã®ã‚ã‚‹ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
    base_price = 50000
    trend = np.linspace(0, 5000, 1000)  # ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰
    noise = np.random.normal(0, 1000, 1000)  # ãƒã‚¤ã‚º
    prices = base_price + trend + noise
    
    # OHLCV ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
    df = pd.DataFrame({
        'timestamp': dates,
        'open': prices + np.random.normal(0, 100, 1000),
        'high': prices + np.abs(np.random.normal(500, 200, 1000)),
        'low': prices - np.abs(np.random.normal(500, 200, 1000)),
        'close': prices,
        'volume': np.random.uniform(1000000, 5000000, 1000)
    })
    
    current_price = prices[-1]
    print(f"ç¾åœ¨ä¾¡æ ¼: {current_price:.2f}")
    
    # æ¤œå‡ºå™¨ã‚’åˆæœŸåŒ–
    detector = SupportResistanceDetector(min_touches=2, tolerance_pct=0.01)
    
    try:
        # æ”¯æŒç·šãƒ»æŠµæŠ—ç·šã‚’æ¤œå‡º
        support_levels, resistance_levels = detector.detect_levels_from_ohlcv(df, current_price)
        
        print(f"æ¤œå‡ºã•ã‚ŒãŸæ”¯æŒç·š: {len(support_levels)}å€‹")
        for i, level in enumerate(support_levels[:5]):  # ä¸Šä½5å€‹è¡¨ç¤º
            print(f"  {i+1}. ä¾¡æ ¼: {level.price:.2f}, å¼·åº¦: {level.strength:.3f}, ã‚¿ãƒƒãƒæ•°: {level.touch_count}")
        
        print(f"æ¤œå‡ºã•ã‚ŒãŸæŠµæŠ—ç·š: {len(resistance_levels)}å€‹")
        for i, level in enumerate(resistance_levels[:5]):  # ä¸Šä½5å€‹è¡¨ç¤º
            print(f"  {i+1}. ä¾¡æ ¼: {level.price:.2f}, å¼·åº¦: {level.strength:.3f}, ã‚¿ãƒƒãƒæ•°: {level.touch_count}")
        
        # æœ€å¯„ã‚Šãƒ¬ãƒ™ãƒ«ã‚’å–å¾—
        nearest_supports, nearest_resistances = detector.get_nearest_levels(
            support_levels, resistance_levels, current_price, max_count=3
        )
        
        print(f"\næœ€å¯„ã‚Šæ”¯æŒç·š (ä¸Šä½3å€‹):")
        for i, level in enumerate(nearest_supports):
            distance_pct = ((current_price - level.price) / current_price) * 100
            print(f"  {i+1}. ä¾¡æ ¼: {level.price:.2f} ({distance_pct:.1f}%ä¸‹), å¼·åº¦: {level.strength:.3f}")
        
        print(f"æœ€å¯„ã‚ŠæŠµæŠ—ç·š (ä¸Šä½3å€‹):")
        for i, level in enumerate(nearest_resistances):
            distance_pct = ((level.price - current_price) / current_price) * 100
            print(f"  {i+1}. ä¾¡æ ¼: {level.price:.2f} ({distance_pct:.1f}%ä¸Š), å¼·åº¦: {level.strength:.3f}")
        
        print("\nâœ… æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºãƒ†ã‚¹ãƒˆæˆåŠŸ!")
        return True
        
    except Exception as e:
        print(f"âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—: {str(e)}")
        return False


if __name__ == "__main__":
    test_support_resistance_detector()