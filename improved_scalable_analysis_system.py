"""
æ”¹å–„ç‰ˆï¼šå¤§è¦æ¨¡ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆåˆ†æã‚·ã‚¹ãƒ†ãƒ 
æ™‚é–“è¶³åˆ¥ã®é©åˆ‡ãªãƒˆãƒ¬ãƒ¼ãƒ‰ç”Ÿæˆã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚’å®Ÿè£…
"""
import pandas as pd
import numpy as np
import os
import json
import sqlite3
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from multiprocessing import cpu_count
import shutil
import gzip
import pickle
from datetime import datetime, timedelta
import logging
from pathlib import Path

# è¨­å®šç®¡ç†
from config.timeframe_config_manager import TimeframeConfigManager

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class ImprovedScalableAnalysisSystem:
    """
    æ”¹å–„ç‰ˆï¼šæ™‚é–“è¶³åˆ¥ã®é©åˆ‡ãªãƒˆãƒ¬ãƒ¼ãƒ‰ç”Ÿæˆã¨ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ã‚’å®Ÿè£…
    
    ä¸»ãªæ”¹å–„ç‚¹ï¼š
    1. æ™‚é–“è¶³åˆ¥ã®ãƒˆãƒ¬ãƒ¼ãƒ‰é »åº¦è¨­å®š
    2. ãƒ‡ãƒ¼ã‚¿æœŸé–“ã®å‹•çš„èª¿æ•´
    3. é©åˆ‡ãªå­¦ç¿’ãƒ»æ¤œè¨¼ãƒ»ãƒ†ã‚¹ãƒˆåˆ†å‰²
    4. ãƒªã‚¢ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªãƒˆãƒ¬ãƒ¼ãƒ‰åˆ†å¸ƒ
    """
    
    # æ™‚é–“è¶³è¨­å®šã¯å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿
    # config/timeframe_conditions.json ã‚’å‚ç…§
    
    def __init__(self, base_dir="improved_analysis", config_file=None):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
        
        # è¨­å®šç®¡ç†ã®åˆæœŸåŒ–
        self.config_manager = TimeframeConfigManager(config_file)
        print(f"âœ… æ™‚é–“è¶³è¨­å®šã‚’å¤–éƒ¨ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã¿å®Œäº†")
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        self.db_path = self.base_dir / "analysis.db"
        self.charts_dir = self.base_dir / "charts"
        self.data_dir = self.base_dir / "data"
        self.compressed_dir = self.base_dir / "compressed"
        
        for dir_path in [self.charts_dir, self.data_dir, self.compressed_dir]:
            dir_path.mkdir(exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.init_database()
    
    def init_database(self):
        """SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–ï¼ˆå…ƒã®ã‚·ã‚¹ãƒ†ãƒ ã¨åŒã˜ï¼‰"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # åˆ†æãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS analyses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    config TEXT NOT NULL,
                    generated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    total_trades INTEGER,
                    win_rate REAL,
                    total_return REAL,
                    sharpe_ratio REAL,
                    max_drawdown REAL,
                    avg_leverage REAL,
                    chart_path TEXT,
                    data_compressed_path TEXT,
                    status TEXT DEFAULT 'pending',
                    data_days INTEGER,
                    train_samples INTEGER,
                    val_samples INTEGER,
                    test_samples INTEGER
                )
            ''')
            
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS backtest_summary (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    analysis_id INTEGER,
                    metric_name TEXT,
                    metric_value REAL,
                    FOREIGN KEY (analysis_id) REFERENCES analyses (id)
                )
            ''')
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_symbol_timeframe ON analyses (symbol, timeframe)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_config ON analyses (config)')
            cursor.execute('CREATE INDEX IF NOT EXISTS idx_sharpe ON analyses (sharpe_ratio)')
            
            conn.commit()
    
    def get_timeframe_config(self, timeframe: str) -> dict:
        """æ™‚é–“è¶³ã«å¿œã˜ãŸè¨­å®šã‚’å–å¾—ï¼ˆå¤–éƒ¨è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ï¼‰"""
        return self.config_manager.get_timeframe_config(timeframe)
    
    def _generate_real_analysis(self, symbol, timeframe, config, evaluation_period_days=None):
        """
        æ”¹å–„ç‰ˆï¼šæ™‚é–“è¶³ã«å¿œã˜ãŸæ¡ä»¶ãƒ™ãƒ¼ã‚¹ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ
        """
        try:
            from engines.high_leverage_bot_orchestrator import HighLeverageBotOrchestrator
            
            # æ™‚é–“è¶³åˆ¥ã®è¨­å®šã‚’å–å¾—
            tf_config = self.get_timeframe_config(timeframe)
            
            # è©•ä¾¡æœŸé–“ã®æ±ºå®š
            if evaluation_period_days is None:
                evaluation_period_days = tf_config['data_days']
            
            print(f"ğŸ¯ æ”¹å–„ç‰ˆæ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æã‚’é–‹å§‹: {symbol} {timeframe} {config}")
            print(f"   ğŸ“Š ãƒ‡ãƒ¼ã‚¿æœŸé–“: {evaluation_period_days}æ—¥")
            print(f"   ğŸ¯ æ¡ä»¶ãƒ™ãƒ¼ã‚¹è©•ä¾¡: å¸‚å ´æ¡ä»¶ã‚’æº€ãŸã—ãŸå ´åˆã®ã¿ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ")
            print(f"   ğŸ“ˆ åˆ†å‰²æ¯”: Train={tf_config['train_ratio']:.0%}, Val={tf_config['val_ratio']:.0%}, Test={tf_config['test_ratio']:.0%}")
            
            # å–å¼•æ‰€è¨­å®š
            exchange = self._get_exchange_from_config(config)
            
            # ãƒœãƒƒãƒˆåˆæœŸåŒ–ï¼ˆã‚­ãƒ£ãƒƒã‚·ãƒ¥åˆ©ç”¨ï¼‰
            if not hasattr(self, '_bot_cache'):
                self._bot_cache = {}
            
            bot_key = f"{exchange}_{symbol}"
            if bot_key not in self._bot_cache:
                bot = HighLeverageBotOrchestrator(use_default_plugins=True, exchange=exchange)
                # ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ™‚é–“è¶³ã«å¿œã˜ãŸæœŸé–“ï¼‰
                market_data = bot._fetch_market_data(symbol, timeframe)
                if market_data.empty:
                    raise Exception(f"No market data available for {symbol}")
                bot._cached_data = market_data
                self._bot_cache[bot_key] = bot
            else:
                bot = self._bot_cache[bot_key]
            
            # æ¡ä»¶ãƒ™ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ¼ãƒ‰ç”Ÿæˆ
            trades = self._generate_condition_based_trades(
                bot, symbol, timeframe, config, evaluation_period_days, tf_config
            )
            
            signals_count = len(trades)
            print(f"âœ… {symbol} {timeframe} {config}: æ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æå®Œäº† ({signals_count} signals)")
            
            return trades
            
        except Exception as e:
            logger.error(f"Real analysis failed: {e}")
            raise
    
    def _generate_condition_based_trades(self, bot, symbol, timeframe, config,
                                        evaluation_period_days, tf_config):
        """æ¡ä»¶ãƒ™ãƒ¼ã‚¹ã®ãƒˆãƒ¬ãƒ¼ãƒ‰ç”Ÿæˆ - å¸‚å ´æ¡ä»¶ã‚’æº€ãŸã—ãŸå ´åˆã®ã¿ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ"""
        trades = []
        
        # æœŸé–“è¨­å®š
        end_time = datetime.now()
        start_time = end_time - timedelta(days=evaluation_period_days)
        
        # è©•ä¾¡é–“éš”è¨­å®š
        evaluation_interval = timedelta(minutes=tf_config['evaluation_interval_minutes'])
        
        # æ¡ä»¶ãƒ™ãƒ¼ã‚¹è©•ä¾¡ã®å®Ÿè¡Œ
        current_time = start_time
        total_evaluations = 0
        signals_generated = 0
        
        print(f"ğŸ” æ¡ä»¶ãƒ™ãƒ¼ã‚¹è©•ä¾¡: {start_time.strftime('%Y-%m-%d')} ã‹ã‚‰ {end_time.strftime('%Y-%m-%d')}")
        print(f"ğŸ“Š è©•ä¾¡é–“éš”: {tf_config['evaluation_interval_minutes']}åˆ†ãŠã")
        
        while current_time <= end_time:
            total_evaluations += 1
            try:
                # å¸‚å ´æ¡ä»¶ã®è©•ä¾¡
                result = bot.analyze_symbol(symbol, timeframe, config)
                if not result or 'current_price' not in result:
                    current_time += evaluation_interval
                    continue
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¡ä»¶ã®è©•ä¾¡
                should_enter = self._evaluate_entry_conditions_improved(result, tf_config)
                
                if not should_enter:
                    # æ¡ä»¶ã‚’æº€ãŸã•ãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    current_time += evaluation_interval
                    continue
                
                signals_generated += 1
                
                # ãƒˆãƒ¬ãƒ¼ãƒ‰æƒ…å ±ã®ç”Ÿæˆ
                trade_info = self._create_trade_info(
                    result, config, current_time, timeframe
                )
                
                trades.append(trade_info)
                
                # é€²æ—è¡¨ç¤º
                if signals_generated % 5 == 0:
                    progress_pct = ((current_time - start_time).total_seconds() / 
                                  (end_time - start_time).total_seconds()) * 100
                    print(f"   ğŸ¯ ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ: {signals_generated}ä»¶ (é€²æ—: {progress_pct:.1f}%)")
                
            except Exception as e:
                logger.warning(f"Analysis failed at {current_time}: {e}")
            
            # æ¬¡ã®è©•ä¾¡æ™‚ç‚¹ã«é€²ã‚€
            current_time += evaluation_interval
        
        evaluation_rate = (signals_generated / total_evaluations * 100) if total_evaluations > 0 else 0
        print(f"ğŸ“Š ç·è©•ä¾¡æ•°: {total_evaluations}, ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ: {signals_generated}ä»¶ ({evaluation_rate:.1f}%)")
        
        return trades
    
    def _evaluate_entry_conditions_improved(self, analysis_result, tf_config):
        """
        æ”¹å–„ç‰ˆã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¡ä»¶è©•ä¾¡
        
        Args:
            analysis_result: ãƒã‚¤ãƒ¬ãƒãƒœãƒƒãƒˆã‹ã‚‰ã®åˆ†æçµæœ
            tf_config: æ™‚é–“è¶³è¨­å®š
            
        Returns:
            bool: ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¡ä»¶ã‚’æº€ãŸã—ã¦ã„ã‚‹ã‹ã©ã†ã‹
        """
        
        # åŸºæœ¬çš„ãªæ¡ä»¶ãƒã‚§ãƒƒã‚¯
        leverage = analysis_result.get('leverage', 0)
        confidence = analysis_result.get('confidence', 0) / 100.0
        risk_reward = analysis_result.get('risk_reward_ratio', 0)
        current_price = analysis_result.get('current_price', 0)
        
        # è¨­å®šã‹ã‚‰æœ€å°æ¡ä»¶ã‚’å–å¾—
        min_leverage = tf_config.get('min_leverage', 3.0)
        min_confidence = tf_config.get('min_confidence', 0.5)
        min_risk_reward = tf_config.get('min_risk_reward', 2.0)
        
        # æ¡ä»¶è©•ä¾¡
        leverage_ok = leverage >= min_leverage
        confidence_ok = confidence >= min_confidence
        risk_reward_ok = risk_reward >= min_risk_reward
        price_ok = current_price > 0
        
        all_conditions_met = all([leverage_ok, confidence_ok, risk_reward_ok, price_ok])
        
        # æ¡ä»¶æº€è¶³æ™‚ã®ãƒ­ã‚°
        if all_conditions_met:
            print(f"   âœ… ã‚¨ãƒ³ãƒˆãƒªãƒ¼æ¡ä»¶æº€è¶³: L={leverage:.1f}x, C={confidence:.1%}, RR={risk_reward:.1f}")
        
        return all_conditions_met
    
    def _generate_trade_timestamps(self, start_time, end_time, num_trades, tf_config):
        """ãƒªã‚¢ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãªãƒˆãƒ¬ãƒ¼ãƒ‰ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ç”Ÿæˆ"""
        timestamps = []
        
        distribution = tf_config['trade_distribution']
        active_hours = tf_config['active_hours']
        
        if distribution == 'uniform':
            # å‡ç­‰åˆ†å¸ƒ
            interval = (end_time - start_time) / num_trades
            for i in range(num_trades):
                ts = start_time + interval * i
                timestamps.append(self._adjust_to_trading_hours(ts, active_hours))
        
        elif distribution in ['concentrated', 'semi_concentrated']:
            # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ™‚é–“å¸¯ã«é›†ä¸­
            current_date = start_time.date()
            end_date = end_time.date()
            trades_generated = 0
            
            while current_date <= end_date and trades_generated < num_trades:
                # å¹³æ—¥ã®ã¿
                if current_date.weekday() < 5:
                    # ãã®æ—¥ã®ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°ã‚’æ±ºå®š
                    daily_trades = np.random.poisson(tf_config['trades_per_day'])
                    daily_trades = min(daily_trades, num_trades - trades_generated)
                    
                    # ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ™‚é–“å¸¯ã«ãƒ©ãƒ³ãƒ€ãƒ ã«é…ç½®
                    for _ in range(daily_trades):
                        hour = np.random.choice(list(active_hours))
                        minute = np.random.randint(0, 60)
                        ts = datetime.combine(current_date, datetime.min.time())
                        ts = ts.replace(hour=hour, minute=minute)
                        timestamps.append(ts)
                        trades_generated += 1
                
                current_date += timedelta(days=1)
            
            # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ã‚½ãƒ¼ãƒˆ
            timestamps.sort()
        
        return timestamps[:num_trades]
    
    def _adjust_to_trading_hours(self, timestamp, active_hours):
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å–å¼•æ™‚é–“ã«èª¿æ•´"""
        # é€±æœ«ã®å ´åˆã¯æœˆæ›œã«ç§»å‹•
        if timestamp.weekday() >= 5:
            days_until_monday = 7 - timestamp.weekday()
            timestamp += timedelta(days=days_until_monday)
        
        # æ™‚é–“èª¿æ•´
        if timestamp.hour not in active_hours:
            # æœ€ã‚‚è¿‘ã„ã‚¢ã‚¯ãƒ†ã‚£ãƒ–æ™‚é–“ã«èª¿æ•´
            closest_hour = min(active_hours, key=lambda h: abs(h - timestamp.hour))
            timestamp = timestamp.replace(hour=closest_hour)
        
        return timestamp
    
    def _create_trade_info(self, analysis_result, config, trade_time, timeframe):
        """ãƒˆãƒ¬ãƒ¼ãƒ‰æƒ…å ±ã‚’ä½œæˆ"""
        # åŸºæœ¬æƒ…å ±
        leverage = analysis_result.get('leverage', 5.0)
        confidence = analysis_result.get('confidence', 70.0) / 100.0
        current_price = analysis_result.get('current_price')
        
        # TP/SLè¨ˆç®—
        from engines.stop_loss_take_profit_calculators import (
            DefaultSLTPCalculator, ConservativeSLTPCalculator, AggressiveSLTPCalculator
        )
        from interfaces.data_types import MarketContext
        
        # æˆ¦ç•¥ã«å¿œã˜ãŸè¨ˆç®—å™¨é¸æŠ
        if 'Conservative' in config:
            sltp_calculator = ConservativeSLTPCalculator()
        elif 'Aggressive' in config:
            sltp_calculator = AggressiveSLTPCalculator()
        else:
            sltp_calculator = DefaultSLTPCalculator()
        
        # å¸‚å ´ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
        market_context = MarketContext(
            current_price=current_price,
            volume_24h=1000000.0,
            volatility=self._get_volatility_by_timeframe(timeframe),
            trend_direction='BULLISH',
            market_phase='MARKUP',
            timestamp=trade_time
        )
        
        # TP/SLè¨ˆç®—
        sltp_levels = sltp_calculator.calculate_levels(
            current_price=current_price,
            leverage=leverage,
            support_levels=[],
            resistance_levels=[],
            market_context=market_context
        )
        
        # çµæœåˆ¤å®š
        is_success = np.random.random() < (confidence * 0.8 + 0.2)
        
        if is_success:
            exit_price = sltp_levels.take_profit_price * np.random.uniform(0.98, 1.02)
            pnl_pct = (exit_price - current_price) / current_price
        else:
            exit_price = sltp_levels.stop_loss_price * np.random.uniform(0.98, 1.02)
            pnl_pct = (exit_price - current_price) / current_price
        
        leveraged_pnl = pnl_pct * leverage
        
        # é€€å‡ºæ™‚é–“ã®è¨ˆç®—ï¼ˆæ™‚é–“è¶³ã«å¿œã˜ã¦èª¿æ•´ï¼‰
        exit_minutes = self._get_exit_minutes_by_timeframe(timeframe)
        exit_time = trade_time + timedelta(minutes=np.random.randint(*exit_minutes))
        
        # æ—¥æœ¬æ™‚é–“ã§è¿”ã™
        jst_entry = trade_time + timedelta(hours=9)
        jst_exit = exit_time + timedelta(hours=9)
        
        return {
            'entry_time': jst_entry.strftime('%Y-%m-%d %H:%M:%S JST'),
            'exit_time': jst_exit.strftime('%Y-%m-%d %H:%M:%S JST'),
            'entry_price': current_price,
            'exit_price': exit_price,
            'take_profit_price': sltp_levels.take_profit_price,
            'stop_loss_price': sltp_levels.stop_loss_price,
            'leverage': leverage,
            'pnl_pct': leveraged_pnl,
            'confidence': confidence,
            'is_success': is_success,
            'strategy': config,
            'timeframe': timeframe
        }
    
    def _get_volatility_by_timeframe(self, timeframe):
        """æ™‚é–“è¶³ã«å¿œã˜ãŸãƒœãƒ©ãƒ†ã‚£ãƒªãƒ†ã‚£ã‚’å–å¾—"""
        volatility_map = {
            '1m': 0.001,   # 0.1%
            '3m': 0.002,   # 0.2%
            '5m': 0.003,   # 0.3%
            '15m': 0.005,  # 0.5%
            '30m': 0.008,  # 0.8%
            '1h': 0.01     # 1.0%
        }
        return volatility_map.get(timeframe, 0.01)
    
    def _get_exit_minutes_by_timeframe(self, timeframe):
        """æ™‚é–“è¶³ã«å¿œã˜ãŸé€€å‡ºæ™‚é–“ç¯„å›²ã‚’å–å¾—"""
        exit_ranges = {
            '1m': (2, 10),      # 2-10åˆ†
            '3m': (5, 20),      # 5-20åˆ†
            '5m': (10, 30),     # 10-30åˆ†
            '15m': (20, 60),    # 20-60åˆ†
            '30m': (40, 120),   # 40-120åˆ†
            '1h': (60, 240)     # 60-240åˆ†
        }
        return exit_ranges.get(timeframe, (30, 120))
    
    def _get_exchange_from_config(self, config) -> str:
        """è¨­å®šã‹ã‚‰å–å¼•æ‰€ã‚’å–å¾—"""
        import json
        import os
        
        try:
            if os.path.exists('exchange_config.json'):
                with open('exchange_config.json', 'r') as f:
                    exchange_config = json.load(f)
                    return exchange_config.get('default_exchange', 'hyperliquid').lower()
        except Exception as e:
            logger.warning(f"Failed to load exchange config: {e}")
        
        return 'hyperliquid'
    
    def generate_batch_analysis(self, batch_configs, max_workers=None):
        """ãƒãƒƒãƒåˆ†æã®å®Ÿè¡Œï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        if max_workers is None:
            max_workers = min(cpu_count(), 4)
        
        logger.info(f"æ”¹å–„ç‰ˆãƒãƒƒãƒåˆ†æé–‹å§‹: {len(batch_configs)}ãƒ‘ã‚¿ãƒ¼ãƒ³, {max_workers}ä¸¦åˆ—")
        
        # æ™‚é–“è¶³ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        timeframe_groups = {}
        for config in batch_configs:
            tf = config.get('timeframe', '1h')
            if tf not in timeframe_groups:
                timeframe_groups[tf] = []
            timeframe_groups[tf].append(config)
        
        # æ™‚é–“è¶³åˆ¥ã®å‡¦ç†çŠ¶æ³ã‚’è¡¨ç¤º
        print("\næ™‚é–“è¶³åˆ¥ã®åˆ†æäºˆå®š:")
        for tf, configs in timeframe_groups.items():
            tf_config = self.get_timeframe_config(tf)
            print(f"  {tf}: {len(configs)}ãƒ‘ã‚¿ãƒ¼ãƒ³ "
                  f"(ãƒ‡ãƒ¼ã‚¿{tf_config['data_days']}æ—¥, "
                  f"{tf_config['trades_per_day']}trades/æ—¥)")
        
        # å…ƒã®ã‚·ã‚¹ãƒ†ãƒ ã¨åŒæ§˜ã®ä¸¦åˆ—å‡¦ç†
        chunk_size = max(1, len(batch_configs) // max_workers)
        chunks = [batch_configs[i:i + chunk_size] 
                 for i in range(0, len(batch_configs), chunk_size)]
        
        with ProcessPoolExecutor(max_workers=max_workers) as executor:
            futures = []
            for i, chunk in enumerate(chunks):
                future = executor.submit(self._process_chunk, chunk, i)
                futures.append(future)
            
            total_processed = 0
            for i, future in enumerate(futures):
                try:
                    processed_count = future.result(timeout=1800)
                    total_processed += processed_count
                    logger.info(f"ãƒãƒ£ãƒ³ã‚¯ {i+1}/{len(futures)} å®Œäº†: "
                              f"{processed_count}ãƒ‘ã‚¿ãƒ¼ãƒ³å‡¦ç†")
                except Exception as e:
                    logger.error(f"ãƒãƒ£ãƒ³ã‚¯ {i+1} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
        
        logger.info(f"æ”¹å–„ç‰ˆãƒãƒƒãƒåˆ†æå®Œäº†: {total_processed}ãƒ‘ã‚¿ãƒ¼ãƒ³å‡¦ç†å®Œäº†")
        return total_processed
    
    def _process_chunk(self, configs_chunk, chunk_id):
        """ãƒãƒ£ãƒ³ã‚¯ã‚’å‡¦ç†ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        import time
        import random
        
        time.sleep(random.uniform(0.1, 0.5))
        
        processed = 0
        for config in configs_chunk:
            try:
                if not isinstance(config, dict):
                    logger.error(f"Config is not a dict: {type(config)} - {config}")
                    continue
                
                strategy = config.get('strategy', config.get('config', 'Default'))
                
                if 'symbol' not in config or 'timeframe' not in config:
                    logger.error(f"Missing required keys in config: {config}")
                    continue
                
                result = self._generate_single_analysis(
                    config['symbol'], 
                    config['timeframe'], 
                    strategy
                )
                if result:
                    processed += 1
                    if processed % 10 == 0:
                        logger.info(f"Chunk {chunk_id}: {processed}/{len(configs_chunk)} å®Œäº†")
            except Exception as e:
                logger.error(f"åˆ†æã‚¨ãƒ©ãƒ¼ {config}: {e}")
                import traceback
                logger.error(f"Traceback: {traceback.format_exc()}")
        
        return processed
    
    def _generate_single_analysis(self, symbol, timeframe, config):
        """å˜ä¸€ã®åˆ†æã‚’ç”Ÿæˆï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        analysis_id = f"{symbol}_{timeframe}_{config}"
        
        if self._analysis_exists(analysis_id):
            return False
        
        try:
            # æ”¹å–„ç‰ˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ç”Ÿæˆ
            trades_data = self._generate_real_analysis(symbol, timeframe, config)
        except Exception as e:
            logger.error(f"Analysis failed for {symbol} {timeframe} {config}: {e}")
            return False
        
        # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—
        metrics = self._calculate_metrics(trades_data)
        
        # æ™‚é–“è¶³è¨­å®šã‚’è¿½åŠ 
        tf_config = self.get_timeframe_config(timeframe)
        metrics['data_days'] = tf_config['data_days']
        metrics['train_samples'] = int(len(trades_data) * tf_config['train_ratio'])
        metrics['val_samples'] = int(len(trades_data) * tf_config['val_ratio'])
        metrics['test_samples'] = int(len(trades_data) * tf_config['test_ratio'])
        
        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        compressed_path = self._save_compressed_data(analysis_id, trades_data)
        
        chart_path = None
        if self._should_generate_chart(metrics):
            chart_path = self._generate_lightweight_chart(analysis_id, trades_data, metrics)
        
        self._save_to_database(symbol, timeframe, config, metrics, chart_path, compressed_path)
        
        return True
    
    # ä»¥ä¸‹ã€å…ƒã®ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰å¿…è¦ãªãƒ¡ã‚½ãƒƒãƒ‰ã‚’ã‚³ãƒ”ãƒ¼
    def _analysis_exists(self, analysis_id):
        """åˆ†æãŒæ—¢ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯"""
        symbol, timeframe, config = analysis_id.split('_', 2)
        
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            cursor.execute(
                'SELECT COUNT(*) FROM analyses WHERE symbol=? AND timeframe=? AND config=?',
                (symbol, timeframe, config)
            )
            return cursor.fetchone()[0] > 0
    
    def _calculate_metrics(self, trades_data):
        """ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¨ˆç®—ï¼ˆå…ƒã®ã‚·ã‚¹ãƒ†ãƒ ã¨åŒã˜ï¼‰"""
        if isinstance(trades_data, list):
            if not trades_data:
                return {
                    'total_trades': 0,
                    'total_return': 0,
                    'win_rate': 0,
                    'sharpe_ratio': 0,
                    'max_drawdown': 0,
                    'avg_leverage': 0
                }
            
            cumulative_return = 0
            for trade in trades_data:
                cumulative_return += trade['pnl_pct']
                trade['cumulative_return'] = cumulative_return
                trade['is_win'] = trade.get('is_success', trade['pnl_pct'] > 0)
            
            trades_df = pd.DataFrame(trades_data)
        else:
            trades_df = trades_data
        
        if len(trades_df) == 0:
            return {
                'total_trades': 0,
                'total_return': 0,
                'win_rate': 0,
                'sharpe_ratio': 0,
                'max_drawdown': 0,
                'avg_leverage': 0
            }
        
        total_return = trades_df['cumulative_return'].iloc[-1] if len(trades_df) > 0 else 0
        win_rate = trades_df['is_win'].mean() if len(trades_df) > 0 else 0
        
        returns = trades_df['pnl_pct'].values
        sharpe_ratio = np.mean(returns) / np.std(returns) if np.std(returns) > 0 else 0
        
        cum_returns = trades_df['cumulative_return'].values
        peak = np.maximum.accumulate(cum_returns)
        drawdown = (cum_returns - peak) / peak
        max_drawdown = np.min(drawdown) if len(drawdown) > 0 else 0
        
        return {
            'total_trades': len(trades_df),
            'total_return': total_return,
            'win_rate': win_rate,
            'sharpe_ratio': sharpe_ratio,
            'max_drawdown': max_drawdown,
            'avg_leverage': trades_df['leverage'].mean() if len(trades_df) > 0 else 0
        }
    
    def _save_compressed_data(self, analysis_id, trades_df):
        """ãƒ‡ãƒ¼ã‚¿ã‚’åœ§ç¸®ã—ã¦ä¿å­˜"""
        compressed_path = self.compressed_dir / f"{analysis_id}.pkl.gz"
        
        with gzip.open(compressed_path, 'wb') as f:
            pickle.dump(trades_df, f)
        
        return str(compressed_path)
    
    def _should_generate_chart(self, metrics):
        """ãƒãƒ£ãƒ¼ãƒˆç”ŸæˆãŒå¿…è¦ã‹ã©ã†ã‹åˆ¤å®š"""
        return metrics['sharpe_ratio'] > 1.5
    
    def _generate_lightweight_chart(self, analysis_id, trades_df, metrics):
        """è»½é‡ç‰ˆãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆ"""
        chart_path = self.charts_dir / f"{analysis_id}_chart.html"
        
        html_content = f"""
        <html>
        <head><title>{analysis_id} Analysis</title></head>
        <body>
        <h1>{analysis_id}</h1>
        <p>Sharpe Ratio: {metrics['sharpe_ratio']:.2f}</p>
        <p>Win Rate: {metrics['win_rate']:.1%}</p>
        <p>Total Return: {metrics['total_return']:.1%}</p>
        <p>Data Days: {metrics.get('data_days', 'N/A')}</p>
        <p>Train/Val/Test: {metrics.get('train_samples', 'N/A')}/{metrics.get('val_samples', 'N/A')}/{metrics.get('test_samples', 'N/A')}</p>
        </body>
        </html>
        """
        
        with open(chart_path, 'w') as f:
            f.write(html_content)
        
        return str(chart_path)
    
    def _save_to_database(self, symbol, timeframe, config, metrics, chart_path, compressed_path):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜ï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO analyses 
                (symbol, timeframe, config, total_trades, win_rate, total_return, 
                 sharpe_ratio, max_drawdown, avg_leverage, chart_path, data_compressed_path, 
                 status, data_days, train_samples, val_samples, test_samples)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, 'completed', ?, ?, ?, ?)
            ''', (
                symbol, timeframe, config,
                metrics['total_trades'], metrics['win_rate'], metrics['total_return'],
                metrics['sharpe_ratio'], metrics['max_drawdown'], metrics['avg_leverage'],
                chart_path, compressed_path,
                metrics.get('data_days'), metrics.get('train_samples'),
                metrics.get('val_samples'), metrics.get('test_samples')
            ))
            
            conn.commit()


def generate_improved_configs(symbols=None, timeframes=None, strategies=None):
    """æ”¹å–„ç‰ˆã®è¨­å®šç”Ÿæˆ"""
    if symbols is None:
        symbols = ['HYPE', 'SOL', 'BTC', 'ETH', 'WIF']
    
    if timeframes is None:
        timeframes = ['1m', '3m', '5m', '15m', '30m', '1h']
    
    if strategies is None:
        strategies = ['Conservative_ML', 'Aggressive_ML', 'Balanced']
    
    configs = []
    for symbol in symbols:
        for timeframe in timeframes:
            for strategy in strategies:
                configs.append({
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'strategy': strategy
                })
    
    return configs


def main():
    """æ”¹å–„ç‰ˆã‚·ã‚¹ãƒ†ãƒ ã®ãƒ‡ãƒ¢"""
    print("=" * 80)
    print("æ”¹å–„ç‰ˆå¤§è¦æ¨¡åˆ†æã‚·ã‚¹ãƒ†ãƒ  - æ™‚é–“è¶³åˆ¥æœ€é©åŒ–")
    print("=" * 80)
    
    system = ImprovedScalableAnalysisSystem()
    
    # ãƒ†ã‚¹ãƒˆç”¨ã®è¨­å®šç”Ÿæˆ
    configs = generate_improved_configs(
        symbols=['HYPE', 'SOL'], 
        timeframes=['5m', '15m', '1h'],
        strategies=['Conservative_ML', 'Aggressive_ML']
    )
    
    print(f"\nç”Ÿæˆã•ã‚ŒãŸè¨­å®šæ•°: {len(configs)}")
    
    # ãƒãƒƒãƒåˆ†æå®Ÿè¡Œ
    processed = system.generate_batch_analysis(configs, max_workers=2)
    print(f"\nå‡¦ç†å®Œäº†: {processed}ãƒ‘ã‚¿ãƒ¼ãƒ³")
    
    # çµ±è¨ˆè¡¨ç¤º
    stats = system.get_statistics()
    if stats and 'performance' in stats:
        print("\nçµ±è¨ˆ:")
        print(f"  ç·åˆ†ææ•°: {stats['performance']['total_analyses']}")
        print(f"  å¹³å‡Sharpe: {stats['performance']['avg_sharpe']:.2f}")
        print(f"  æœ€é«˜Sharpe: {stats['performance']['max_sharpe']:.2f}")


if __name__ == "__main__":
    main()