#!/usr/bin/env python3
"""
æ®‹å­˜ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®è©³ç´°èª¿æŸ»
ã©ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã©ã®å€¤ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç‰¹å®š
"""

import pandas as pd
import pickle
import gzip
from pathlib import Path

def investigate_hardcoded_files():
    """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®è©³ç´°èª¿æŸ»"""
    print("ğŸ” æ®‹å­˜ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®è©³ç´°èª¿æŸ»")
    print("=" * 70)
    
    compressed_dir = Path("large_scale_analysis/compressed")
    
    # å•é¡Œã®ã‚ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©³ç´°èª¿æŸ»
    problem_files = [
        "TAO_1h_Full_ML.pkl.gz",
        "CAKE_3m_Aggressive_Traditional.pkl.gz", 
        "TAO_5m_Full_ML.pkl.gz"
    ]
    
    hardcoded_values = [100.0, 105.0, 97.62, 1000.0]
    
    for filename in problem_files:
        file_path = compressed_dir / filename
        if not file_path.exists():
            continue
            
        print(f"\nğŸ“Š {filename} ã®è©³ç´°åˆ†æ:")
        
        try:
            with gzip.open(file_path, 'rb') as f:
                data = pickle.load(f)
            
            if isinstance(data, list):
                df = pd.DataFrame(data)
            elif isinstance(data, pd.DataFrame):
                df = data
            else:
                continue
                
            print(f"  ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
            
            # å„ä¾¡æ ¼ã‚«ãƒ©ãƒ ã®è©³ç´°
            price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price', 'exit_price']
            
            for col in price_columns:
                if col in df.columns:
                    values = df[col].values
                    print(f"\n  {col}:")
                    print(f"    ç¯„å›²: {values.min():.6f} - {values.max():.6f}")
                    
                    # å„ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’ãƒã‚§ãƒƒã‚¯
                    for hv in hardcoded_values:
                        matching = sum(abs(val - hv) < 0.001 for val in values)
                        if matching > 0:
                            print(f"    âŒ {hv}: {matching}ä»¶æ¤œå‡º")
                            # å®Ÿéš›ã®å€¤ã‚’è¡¨ç¤º
                            matching_values = [val for val in values if abs(val - hv) < 0.001]
                            print(f"       å®Ÿéš›ã®å€¤: {matching_values[:3]}")
                    
                    # æœ€åˆã®5ä»¶ã‚’è¡¨ç¤º
                    print(f"    æœ€åˆã®5ä»¶: {values[:5]}")
                    
        except Exception as e:
            print(f"  âŒ ã‚¨ãƒ©ãƒ¼: {e}")

def check_file_timestamps():
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ” ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—")
    print("=" * 70)
    
    import os
    from datetime import datetime
    
    compressed_dir = Path("large_scale_analysis/compressed")
    
    problem_files = [
        "TAO_1h_Full_ML.pkl.gz",
        "CAKE_3m_Aggressive_Traditional.pkl.gz",
        "TAO_5m_Full_ML.pkl.gz",
        "TAO_3m_Aggressive_Traditional.pkl.gz",
        "TRUMP_15m_Full_ML.pkl.gz"
    ]
    
    for filename in problem_files:
        file_path = compressed_dir / filename
        if file_path.exists():
            mtime = os.path.getmtime(file_path)
            dt = datetime.fromtimestamp(mtime)
            print(f"{filename}: {dt.strftime('%Y-%m-%d %H:%M:%S')}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ“‹ æ®‹å­˜ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ")
    print("=" * 70)
    
    # 1. è©³ç´°èª¿æŸ»
    investigate_hardcoded_files()
    
    # 2. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ç¢ºèª
    check_file_timestamps()
    
    print("\n" + "=" * 70)
    print("ğŸ“‹ çµè«–:")
    print("- Phase 1ã§å‰Šé™¤ã—æã­ãŸå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ®‹å­˜")
    print("- æ–°è¦ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆBTC, TRXï¼‰ã«ã¯ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãªã—")
    print("- æ®‹å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚‚å‰Šé™¤ã™ã‚Œã°å®Œå…¨ã«ã‚¯ãƒªãƒ¼ãƒ³")

if __name__ == '__main__':
    main()