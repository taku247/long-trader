"""
Multi-Symbol Real Market Analysis System
è¤‡æ•°éŠ˜æŸ„ã§ã®ã‚·ã‚¹ãƒ†ãƒ å …ç‰¢æ€§ã¨MLæ€§èƒ½ã‚’è©•ä¾¡
"""
import pandas as pd
import numpy as np
import os
import json
import sqlite3
from datetime import datetime
import logging
import subprocess
import sys
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class MultiSymbolAnalysisSystem:
    def __init__(self, base_dir="real_market_analysis"):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        self.db_path = self.base_dir / "market_analysis.db"
        self.results_dir = self.base_dir / "results"
        self.results_dir.mkdir(exist_ok=True)
        
        # åˆ©ç”¨å¯èƒ½éŠ˜æŸ„ã®ç¢ºèª
        self.available_symbols = self.detect_available_symbols()
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.init_database()
    
    def detect_available_symbols(self):
        """åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ã‚’æ¤œå‡º"""
        available = []
        symbols_to_check = ['HYPE', 'SOL', 'PEPE', 'WIF', 'BONK']
        
        for symbol in symbols_to_check:
            reduced_features_file = f"{symbol.lower()}_1h_90days_reduced_features.csv"
            if os.path.exists(reduced_features_file):
                available.append(symbol)
                logger.info(f"åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„: {symbol}")
            else:
                logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãªã—: {symbol}")
        
        return available
    
    def init_database(self):
        """SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # ãƒãƒ«ãƒã‚·ãƒ³ãƒœãƒ«åˆ†æçµæœãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS multi_symbol_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    analysis_id TEXT NOT NULL,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    data_quality_score REAL,
                    ml_accuracy REAL,
                    pipeline_success BOOLEAN,
                    records_count INTEGER,
                    features_count INTEGER,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            conn.commit()
    
    def analyze_existing_data(self, symbol, timeframe):
        """æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        reduced_features_file = f"{symbol.lower()}_{timeframe}_90days_reduced_features.csv"
        
        if not os.path.exists(reduced_features_file):
            return None
        
        try:
            df = pd.read_csv(reduced_features_file)
            quality_score = 1.0 - (df.isnull().sum().sum() / (len(df) * len(df.columns)))
            
            return {
                'symbol': symbol,
                'timeframe': timeframe,
                'status': 'success',
                'records': len(df),
                'features': len(df.columns) - 1,
                'quality_score': quality_score,
                'file_path': reduced_features_file
            }
        except Exception as e:
            logger.error(f"ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¨ãƒ©ãƒ¼ {symbol}: {e}")
            return None
    
    def run_support_resistance_analysis(self, symbol, timeframe):
        """ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"ã‚µãƒãƒ¬ã‚¸åˆ†æ: {symbol} {timeframe}")
        
        try:
            cmd = [
                sys.executable,
                "support_resistance_visualizer.py",
                "--symbol", symbol,
                "--timeframe", timeframe,
                "--min-touches", "2"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                chart_file = f"{symbol.lower()}_{timeframe}_support_resistance_analysis.png"
                if os.path.exists(chart_file):
                    return {'status': 'success', 'chart_path': chart_file}
                    
            return {'status': 'failed', 'error': 'ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆå¤±æ•—'}
            
        except Exception as e:
            return {'status': 'failed', 'error': str(e)}
    
    def run_ml_training(self, symbol, timeframe):
        """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        logger.info(f"MLè¨“ç·´: {symbol} {timeframe}")
        
        try:
            cmd = [
                sys.executable,
                "support_resistance_ml.py",
                "--symbol", symbol,
                "--timeframe", timeframe,
                "--min-touches", "2"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                model_file = f"{symbol.lower()}_{timeframe}_sr_breakout_model.pkl"
                if os.path.exists(model_file):
                    # ç²¾åº¦ã‚’æŠ½å‡º
                    accuracy = 0.0
                    if "ç²¾åº¦:" in result.stdout:
                        import re
                        match = re.search(r'ç²¾åº¦:\s*(\d+\.\d+)', result.stdout)
                        if match:
                            accuracy = float(match.group(1))
                    elif "å¹³å‡ç²¾åº¦:" in result.stdout:
                        match = re.search(r'å¹³å‡ç²¾åº¦:\s*(\d+\.\d+)', result.stdout)
                        if match:
                            accuracy = float(match.group(1))
                    
                    return {'status': 'success', 'accuracy': accuracy, 'output': result.stdout}
                    
            return {'status': 'failed', 'error': 'ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå¤±æ•—', 'output': result.stdout}
            
        except Exception as e:
            return {'status': 'failed', 'error': str(e)}
    
    def run_comprehensive_analysis(self):
        """åŒ…æ‹¬çš„ãªåˆ†æã‚’å®Ÿè¡Œ"""
        timeframe = '1h'
        analysis_id = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        logger.info(f"ãƒãƒ«ãƒã‚·ãƒ³ãƒœãƒ«åˆ†æé–‹å§‹: {self.available_symbols}")
        
        results = {
            'analysis_id': analysis_id,
            'symbols_analyzed': self.available_symbols,
            'data_analysis': [],
            'support_resistance': [],
            'ml_training': [],
            'performance_comparison': {},
            'summary': {}
        }
        
        # 1. æ—¢å­˜ãƒ‡ãƒ¼ã‚¿åˆ†æ
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ‡ãƒ¼ã‚¿å“è³ªåˆ†æ ===")
        for symbol in self.available_symbols:
            data_result = self.analyze_existing_data(symbol, timeframe)
            if data_result:
                results['data_analysis'].append(data_result)
        
        # æˆåŠŸã—ãŸã‚·ãƒ³ãƒœãƒ«ã®ã¿ã§æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ
        successful_symbols = [r['symbol'] for r in results['data_analysis'] if r['status'] == 'success']
        
        # 2. ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æ
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—2: ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æ ===")
        for symbol in successful_symbols:
            sr_result = self.run_support_resistance_analysis(symbol, timeframe)
            sr_result.update({'symbol': symbol, 'timeframe': timeframe})
            results['support_resistance'].append(sr_result)
        
        # 3. æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—3: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´ ===")
        for symbol in successful_symbols:
            ml_result = self.run_ml_training(symbol, timeframe)
            ml_result.update({'symbol': symbol, 'timeframe': timeframe})
            results['ml_training'].append(ml_result)
        
        # 4. æ€§èƒ½æ¯”è¼ƒ
        results['performance_comparison'] = self.generate_performance_comparison(results)
        
        # 5. ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        results['summary'] = self.generate_summary(results)
        
        # 6. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²
        self.save_to_database(analysis_id, results)
        
        # 7. çµæœã‚’JSONã§ä¿å­˜
        results_file = self.results_dir / f"multi_symbol_analysis_{analysis_id}.json"
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"åˆ†æå®Œäº†: {results_file}")
        return results
    
    def generate_performance_comparison(self, results):
        """æ€§èƒ½æ¯”è¼ƒã‚’ç”Ÿæˆ"""
        comparison = {}
        
        # å„éŠ˜æŸ„ã®ç·åˆæ€§èƒ½
        for symbol in self.available_symbols:
            comparison[symbol] = {
                'data_quality': None,
                'sr_success': False,
                'ml_accuracy': None,
                'pipeline_success': False
            }
            
            # ãƒ‡ãƒ¼ã‚¿å“è³ª
            data_info = next((r for r in results['data_analysis'] if r['symbol'] == symbol), None)
            if data_info:
                comparison[symbol]['data_quality'] = data_info['quality_score']
            
            # ã‚µãƒãƒ¬ã‚¸æˆåŠŸ
            sr_info = next((r for r in results['support_resistance'] if r['symbol'] == symbol), None)
            if sr_info:
                comparison[symbol]['sr_success'] = sr_info['status'] == 'success'
            
            # MLç²¾åº¦
            ml_info = next((r for r in results['ml_training'] if r['symbol'] == symbol), None)
            if ml_info and ml_info['status'] == 'success':
                comparison[symbol]['ml_accuracy'] = ml_info.get('accuracy', 0)
            
            # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å…¨ä½“ã®æˆåŠŸ
            comparison[symbol]['pipeline_success'] = all([
                comparison[symbol]['data_quality'] is not None,
                comparison[symbol]['sr_success'],
                comparison[symbol]['ml_accuracy'] is not None
            ])
        
        return comparison
    
    def generate_summary(self, results):
        """ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        successful_pipelines = sum(1 for perf in results['performance_comparison'].values() if perf['pipeline_success'])
        
        ml_accuracies = [perf['ml_accuracy'] for perf in results['performance_comparison'].values() 
                        if perf['ml_accuracy'] is not None]
        avg_ml_accuracy = np.mean(ml_accuracies) if ml_accuracies else 0
        
        data_qualities = [perf['data_quality'] for perf in results['performance_comparison'].values() 
                         if perf['data_quality'] is not None]
        avg_data_quality = np.mean(data_qualities) if data_qualities else 0
        
        return {
            'symbols_tested': len(self.available_symbols),
            'successful_pipelines': successful_pipelines,
            'pipeline_success_rate': successful_pipelines / len(self.available_symbols) if self.available_symbols else 0,
            'avg_ml_accuracy': avg_ml_accuracy,
            'avg_data_quality': avg_data_quality,
            'ml_accuracy_range': {
                'min': min(ml_accuracies) if ml_accuracies else 0,
                'max': max(ml_accuracies) if ml_accuracies else 0,
                'std': np.std(ml_accuracies) if ml_accuracies else 0
            }
        }
    
    def save_to_database(self, analysis_id, results):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«çµæœã‚’ä¿å­˜"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            for symbol in self.available_symbols:
                perf = results['performance_comparison'][symbol]
                data_info = next((r for r in results['data_analysis'] if r['symbol'] == symbol), {})
                
                cursor.execute('''
                    INSERT INTO multi_symbol_results 
                    (analysis_id, symbol, timeframe, data_quality_score, ml_accuracy, 
                     pipeline_success, records_count, features_count)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?)
                ''', (
                    analysis_id, symbol, '1h',
                    perf['data_quality'],
                    perf['ml_accuracy'],
                    perf['pipeline_success'],
                    data_info.get('records', 0),
                    data_info.get('features', 0)
                ))
            
            conn.commit()
    
    def display_results(self, results):
        """çµæœã‚’è¡¨ç¤º"""
        print("=" * 80)
        print("ãƒãƒ«ãƒã‚·ãƒ³ãƒœãƒ«å®Ÿå¸‚å ´åˆ†æçµæœ")
        print("=" * 80)
        
        # ã‚µãƒãƒªãƒ¼
        summary = results['summary']
        print(f"\n=== åˆ†æã‚µãƒãƒªãƒ¼ ===")
        print(f"ãƒ†ã‚¹ãƒˆéŠ˜æŸ„æ•°: {summary['symbols_tested']}")
        print(f"æˆåŠŸãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {summary['successful_pipelines']}")
        print(f"æˆåŠŸç‡: {summary['pipeline_success_rate']:.1%}")
        print(f"å¹³å‡MLç²¾åº¦: {summary['avg_ml_accuracy']:.3f}")
        print(f"å¹³å‡ãƒ‡ãƒ¼ã‚¿å“è³ª: {summary['avg_data_quality']:.3f}")
        print(f"MLç²¾åº¦ç¯„å›²: {summary['ml_accuracy_range']['min']:.3f} - {summary['ml_accuracy_range']['max']:.3f}")
        print(f"MLç²¾åº¦æ¨™æº–åå·®: {summary['ml_accuracy_range']['std']:.3f}")
        
        # éŠ˜æŸ„åˆ¥è©³ç´°
        print(f"\n=== éŠ˜æŸ„åˆ¥è©³ç´°çµæœ ===")
        for symbol in self.available_symbols:
            perf = results['performance_comparison'][symbol]
            print(f"\n{symbol}:")
            
            data_quality_str = f"{perf['data_quality']:.3f}" if perf['data_quality'] is not None else "N/A"
            print(f"  ãƒ‡ãƒ¼ã‚¿å“è³ª: {data_quality_str}")
            print(f"  ã‚µãƒãƒ¬ã‚¸åˆ†æ: {'âœ“' if perf['sr_success'] else 'âœ—'}")
            
            ml_accuracy_str = f"{perf['ml_accuracy']:.3f}" if perf['ml_accuracy'] is not None else "N/A"
            print(f"  MLç²¾åº¦: {ml_accuracy_str}")
            print(f"  ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³: {'ğŸŸ¢ æˆåŠŸ' if perf['pipeline_success'] else 'ğŸ”´ å¤±æ•—'}")
        
        # MLç²¾åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
        print(f"\n=== MLç²¾åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===")
        ml_ranking = [(symbol, perf['ml_accuracy']) for symbol, perf in results['performance_comparison'].items() 
                     if perf['ml_accuracy'] is not None]
        ml_ranking.sort(key=lambda x: x[1], reverse=True)
        
        for i, (symbol, accuracy) in enumerate(ml_ranking, 1):
            print(f"{i}. {symbol}: {accuracy:.3f}")
        
        print(f"\nâœ… ãƒãƒ«ãƒã‚·ãƒ³ãƒœãƒ«åˆ†æå®Œäº†")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ãƒãƒ«ãƒã‚·ãƒ³ãƒœãƒ«å®Ÿå¸‚å ´åˆ†æã‚·ã‚¹ãƒ†ãƒ ")
    print("è¤‡æ•°éŠ˜æŸ„ã§ã®ã‚·ã‚¹ãƒ†ãƒ å …ç‰¢æ€§ã¨MLæ€§èƒ½ã‚’è©•ä¾¡")
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = MultiSymbolAnalysisSystem()
    
    if not system.available_symbols:
        print("âŒ åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    # åˆ†æå®Ÿè¡Œ
    results = system.run_comprehensive_analysis()
    
    # çµæœè¡¨ç¤º
    system.display_results(results)

if __name__ == "__main__":
    main()