"""
å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ 
æ—¢å­˜ã®OHLCVã‚·ã‚¹ãƒ†ãƒ ã¨MLã‚·ã‚¹ãƒ†ãƒ ã‚’çµ±åˆã—ãŸå®Ÿç”¨çš„ãªåˆ†æã‚¨ãƒ³ã‚¸ãƒ³
"""
import pandas as pd
import numpy as np
import os
import json
import sqlite3
from datetime import datetime
import logging
import subprocess
import sys
from pathlib import Path

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class RealMarketAnalysisSystem:
    def __init__(self, base_dir="real_market_analysis"):
        self.base_dir = Path(base_dir)
        self.base_dir.mkdir(exist_ok=True)
        
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 
        self.db_path = self.base_dir / "market_analysis.db"
        self.results_dir = self.base_dir / "results"
        self.results_dir.mkdir(exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
        self.init_database()
    
    def init_database(self):
        """SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’åˆæœŸåŒ–"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # å¸‚å ´ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS market_data_status (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    records_count INTEGER,
                    features_count INTEGER,
                    data_quality_score REAL,
                    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    UNIQUE(symbol, timeframe)
                )
            ''')
            conn.commit()
    
    def fetch_market_data(self, symbols, timeframes):
        """æŒ‡å®šã—ãŸã‚·ãƒ³ãƒœãƒ«ãƒ»ã‚¿ã‚¤ãƒ ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¸‚å ´ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        results = []
        
        for symbol in symbols:
            for timeframe in timeframes:
                logger.info(f"å¸‚å ´ãƒ‡ãƒ¼ã‚¿ç¢ºèªä¸­: {symbol} {timeframe}")
                
                # ã¾ãšæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
                reduced_features_file = f"{symbol.lower()}_{timeframe}_90days_reduced_features.csv"
                
                if os.path.exists(reduced_features_file):
                    logger.info(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨: {reduced_features_file}")
                    try:
                        # ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚“ã§å“è³ªãƒã‚§ãƒƒã‚¯
                        df = pd.read_csv(reduced_features_file)
                        quality_score = 1.0 - (df.isnull().sum().sum() / (len(df) * len(df.columns)))
                        
                        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«è¨˜éŒ²
                        with sqlite3.connect(self.db_path) as conn:
                            cursor = conn.cursor()
                            cursor.execute('''
                                INSERT OR REPLACE INTO market_data_status 
                                (symbol, timeframe, records_count, features_count, data_quality_score)
                                VALUES (?, ?, ?, ?, ?)
                            ''', (symbol, timeframe, len(df), len(df.columns) - 1, quality_score))
                            conn.commit()
                        
                        results.append({
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'status': 'success',
                            'records': len(df),
                            'features': len(df.columns) - 1,
                            'quality_score': quality_score
                        })
                        
                        logger.info(f"âœ“ {symbol} {timeframe}: {len(df)}ä»¶, {len(df.columns)-1}ç‰¹å¾´é‡")
                        
                    except Exception as e:
                        logger.error(f"æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
                        results.append({
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'status': 'failed',
                            'error': f'æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}'
                        })
                else:
                    # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã—ãªã„å ´åˆã¯æ–°è¦å–å¾—
                    logger.info(f"æ–°è¦ãƒ‡ãƒ¼ã‚¿å–å¾—: {symbol} {timeframe}")
                    try:
                        cmd = [
                            sys.executable,
                            "ohlcv_by_claude.py",
                            "--symbol", symbol,
                            "--timeframe", timeframe
                        ]
                        
                        result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
                        
                        if result.returncode == 0 and os.path.exists(reduced_features_file):
                            # æ–°ã—ãç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†
                            df = pd.read_csv(reduced_features_file)
                            quality_score = 1.0 - (df.isnull().sum().sum() / (len(df) * len(df.columns)))
                            
                            with sqlite3.connect(self.db_path) as conn:
                                cursor = conn.cursor()
                                cursor.execute('''
                                    INSERT OR REPLACE INTO market_data_status 
                                    (symbol, timeframe, records_count, features_count, data_quality_score)
                                    VALUES (?, ?, ?, ?, ?)
                                ''', (symbol, timeframe, len(df), len(df.columns) - 1, quality_score))
                                conn.commit()
                            
                            results.append({
                                'symbol': symbol,
                                'timeframe': timeframe,
                                'status': 'success',
                                'records': len(df),
                                'features': len(df.columns) - 1,
                                'quality_score': quality_score
                            })
                            
                            logger.info(f"âœ“ {symbol} {timeframe}: {len(df)}ä»¶, {len(df.columns)-1}ç‰¹å¾´é‡")
                        else:
                            results.append({
                                'symbol': symbol,
                                'timeframe': timeframe,
                                'status': 'failed',
                                'error': 'ãƒ‡ãƒ¼ã‚¿å–å¾—/ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆå¤±æ•—'
                            })
                    except subprocess.TimeoutExpired:
                        results.append({
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'status': 'failed',
                            'error': 'ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ'
                        })
                    except Exception as e:
                        results.append({
                            'symbol': symbol,
                            'timeframe': timeframe,
                            'status': 'failed',
                            'error': str(e)
                        })
        
        return results
    
    def analyze_support_resistance(self, symbol, timeframe):
        """ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æã‚’å®Ÿè¡Œ"""
        logger.info(f"ã‚µãƒãƒ¬ã‚¸åˆ†æé–‹å§‹: {symbol} {timeframe}")
        
        try:
            cmd = [
                sys.executable,
                "support_resistance_visualizer.py",
                "--symbol", symbol,
                "--timeframe", timeframe,
                "--min-touches", "2"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            
            if result.returncode == 0:
                chart_file = f"{symbol.lower()}_{timeframe}_support_resistance_analysis.png"
                if os.path.exists(chart_file):
                    return {'status': 'success', 'chart_path': chart_file}
                    
            return {'status': 'failed', 'error': 'ãƒãƒ£ãƒ¼ãƒˆç”Ÿæˆå¤±æ•—'}
            
        except Exception as e:
            return {'status': 'failed', 'error': str(e)}
    
    def train_ml_models(self, symbol, timeframe):
        """æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´"""
        logger.info(f"MLè¨“ç·´é–‹å§‹: {symbol} {timeframe}")
        
        try:
            cmd = [
                sys.executable,
                "support_resistance_ml.py",
                "--symbol", symbol,
                "--timeframe", timeframe,
                "--min-touches", "2"
            ]
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)
            
            if result.returncode == 0:
                model_file = f"{symbol.lower()}_{timeframe}_sr_breakout_model.pkl"
                if os.path.exists(model_file):
                    # ç²¾åº¦ã‚’æŠ½å‡ºï¼ˆæ”¹è‰¯ç‰ˆï¼‰
                    accuracy = 0.0
                    if "ç²¾åº¦:" in result.stdout:
                        import re
                        # "ç²¾åº¦: 0.570" ã®ã‚ˆã†ãªå½¢å¼ã‚’æ¢ã™
                        match = re.search(r'ç²¾åº¦:\s*(\d+\.\d+)', result.stdout)
                        if match:
                            accuracy = float(match.group(1))
                    elif "å¹³å‡ç²¾åº¦:" in result.stdout:
                        # "å¹³å‡ç²¾åº¦: 0.5696" ã®ã‚ˆã†ãªå½¢å¼ã‚‚æ¢ã™
                        match = re.search(r'å¹³å‡ç²¾åº¦:\s*(\d+\.\d+)', result.stdout)
                        if match:
                            accuracy = float(match.group(1))
                    
                    return {'status': 'success', 'accuracy': accuracy}
                    
            return {'status': 'failed', 'error': 'ãƒ¢ãƒ‡ãƒ«ç”Ÿæˆå¤±æ•—'}
            
        except Exception as e:
            return {'status': 'failed', 'error': str(e)}
    
    def generate_comprehensive_analysis(self, symbols=None, timeframes=None):
        """åŒ…æ‹¬çš„ãªåˆ†æã‚’å®Ÿè¡Œ"""
        if symbols is None:
            symbols = ['HYPE']  # 1éŠ˜æŸ„ã§ãƒ†ã‚¹ãƒˆ
        if timeframes is None:
            timeframes = ['1h']
        
        logger.info(f"åŒ…æ‹¬åˆ†æé–‹å§‹: {symbols} x {timeframes}")
        
        results = {
            'data_fetch': [],
            'support_resistance': [],
            'ml_training': [],
            'summary': {}
        }
        
        # 1. ãƒ‡ãƒ¼ã‚¿å–å¾—
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—1: å¸‚å ´ãƒ‡ãƒ¼ã‚¿å–å¾— ===")
        data_results = self.fetch_market_data(symbols, timeframes)
        results['data_fetch'] = data_results
        
        # æˆåŠŸã—ãŸãƒ‡ãƒ¼ã‚¿ã®ã¿ã§æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’å®Ÿè¡Œ
        successful_pairs = [(r['symbol'], r['timeframe']) for r in data_results if r['status'] == 'success']
        
        # 2. ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æ
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—2: ã‚µãƒãƒ¼ãƒˆãƒ»ãƒ¬ã‚¸ã‚¹ã‚¿ãƒ³ã‚¹åˆ†æ ===")
        for symbol, timeframe in successful_pairs:
            sr_result = self.analyze_support_resistance(symbol, timeframe)
            sr_result.update({'symbol': symbol, 'timeframe': timeframe})
            results['support_resistance'].append(sr_result)
        
        # 3. æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´
        logger.info("=== ã‚¹ãƒ†ãƒƒãƒ—3: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«è¨“ç·´ ===")
        for symbol, timeframe in successful_pairs:
            ml_result = self.train_ml_models(symbol, timeframe)
            ml_result.update({'symbol': symbol, 'timeframe': timeframe})
            results['ml_training'].append(ml_result)
        
        # 4. çµæœã‚µãƒãƒªãƒ¼
        results['summary'] = self.generate_analysis_summary(results)
        
        # 5. çµæœã‚’JSONã§ä¿å­˜
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        results_file = self.results_dir / f"comprehensive_analysis_{timestamp}.json"
        
        with open(results_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2, default=str)
        
        logger.info(f"åˆ†æå®Œäº†: {results_file}")
        return results
    
    def generate_analysis_summary(self, results):
        """åˆ†æçµæœã®ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        data_success = len([r for r in results['data_fetch'] if r['status'] == 'success'])
        sr_success = len([r for r in results['support_resistance'] if r['status'] == 'success'])
        ml_success = len([r for r in results['ml_training'] if r['status'] == 'success'])
        
        total_features = sum([r.get('features', 0) for r in results['data_fetch'] if r['status'] == 'success'])
        avg_quality = np.mean([r.get('quality_score', 0) for r in results['data_fetch'] if r['status'] == 'success']) if data_success > 0 else 0
        
        ml_accuracies = [r.get('accuracy', 0) for r in results['ml_training'] if r['status'] == 'success' and r.get('accuracy', 0) > 0]
        avg_accuracy = np.mean(ml_accuracies) if ml_accuracies else 0
        
        return {
            'total_pairs_attempted': len(results['data_fetch']),
            'data_fetch_success': data_success,
            'support_resistance_success': sr_success,
            'ml_training_success': ml_success,
            'total_features_generated': total_features,
            'avg_data_quality': avg_quality,
            'avg_ml_accuracy': avg_accuracy,
            'pipeline_success_rate': ml_success / len(results['data_fetch']) if results['data_fetch'] else 0
        }

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("=" * 60)
    print("å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿çµ±åˆã‚·ã‚¹ãƒ†ãƒ  - è¤‡æ•°éŠ˜æŸ„åˆ†æ")
    print("=" * 60)
    
    # ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–
    system = RealMarketAnalysisSystem()
    
    # è¤‡æ•°éŠ˜æŸ„ã§ã®å …ç‰¢æ€§ãƒ†ã‚¹ãƒˆ
    symbols = ['HYPE', 'SOL', 'PEPE', 'WIF', 'BONK']
    print(f"\nè¤‡æ•°éŠ˜æŸ„åˆ†æå®Ÿè¡Œä¸­...")
    print(f"å¯¾è±¡: {', '.join(symbols)}, 1æ™‚é–“è¶³")
    print(f"å„éŠ˜æŸ„ã®MLæ€§èƒ½ã¨ã‚·ã‚¹ãƒ†ãƒ å …ç‰¢æ€§ã‚’è©•ä¾¡")
    
    results = system.generate_comprehensive_analysis(
        symbols=symbols,
        timeframes=['1h']
    )
    
    # çµæœè¡¨ç¤º
    print("\n=== åˆ†æçµæœã‚µãƒãƒªãƒ¼ ===")
    summary = results['summary']
    print(f"å¯¾è±¡ãƒšã‚¢æ•°: {summary['total_pairs_attempted']}")
    print(f"ãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸ: {summary['data_fetch_success']}")
    print(f"ã‚µãƒãƒ¬ã‚¸åˆ†ææˆåŠŸ: {summary['support_resistance_success']}")
    print(f"MLè¨“ç·´æˆåŠŸ: {summary['ml_training_success']}")
    print(f"ç”Ÿæˆç‰¹å¾´é‡æ•°: {summary['total_features_generated']}")
    print(f"ãƒ‡ãƒ¼ã‚¿å“è³ªå¹³å‡: {summary['avg_data_quality']:.3f}")
    print(f"MLç²¾åº¦å¹³å‡: {summary['avg_ml_accuracy']:.3f}")
    print(f"ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³æˆåŠŸç‡: {summary['pipeline_success_rate']:.1%}")
    
    # éŠ˜æŸ„åˆ¥æ€§èƒ½æ¯”è¼ƒ
    print("\n=== éŠ˜æŸ„åˆ¥æ€§èƒ½æ¯”è¼ƒ ===")
    symbol_performance = {}
    
    for result in results['data_fetch']:
        symbol = result['symbol']
        if symbol not in symbol_performance:
            symbol_performance[symbol] = {'data': None, 'sr': None, 'ml': None}
        symbol_performance[symbol]['data'] = result
    
    for result in results['support_resistance']:
        symbol = result['symbol']
        if symbol in symbol_performance:
            symbol_performance[symbol]['sr'] = result
    
    for result in results['ml_training']:
        symbol = result['symbol']
        if symbol in symbol_performance:
            symbol_performance[symbol]['ml'] = result
    
    # å„éŠ˜æŸ„ã®è©³ç´°è¡¨ç¤º
    for symbol, perf in symbol_performance.items():
        print(f"\n{symbol}:")
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—
        data_status = "âœ“" if perf['data'] and perf['data']['status'] == 'success' else "âœ—"
        print(f"  ãƒ‡ãƒ¼ã‚¿å–å¾—: {data_status}")
        if perf['data'] and perf['data']['status'] == 'success':
            print(f"    {perf['data']['records']}ä»¶, {perf['data']['features']}ç‰¹å¾´é‡, å“è³ª{perf['data']['quality_score']:.3f}")
        
        # ã‚µãƒãƒ¬ã‚¸åˆ†æ
        sr_status = "âœ“" if perf['sr'] and perf['sr']['status'] == 'success' else "âœ—"
        print(f"  ã‚µãƒãƒ¬ã‚¸åˆ†æ: {sr_status}")
        
        # MLè¨“ç·´
        ml_status = "âœ“" if perf['ml'] and perf['ml']['status'] == 'success' else "âœ—"
        print(f"  MLè¨“ç·´: {ml_status}")
        if perf['ml'] and perf['ml']['status'] == 'success' and perf['ml'].get('accuracy', 0) > 0:
            print(f"    ç²¾åº¦: {perf['ml']['accuracy']:.3f}")
        
        # ç·åˆè©•ä¾¡
        pipeline_success = all([
            perf['data'] and perf['data']['status'] == 'success',
            perf['sr'] and perf['sr']['status'] == 'success',
            perf['ml'] and perf['ml']['status'] == 'success'
        ])
        status_emoji = "ğŸŸ¢" if pipeline_success else "ğŸ”´"
        print(f"  ç·åˆ: {status_emoji} {'å®Œå…¨æˆåŠŸ' if pipeline_success else 'éƒ¨åˆ†çš„å¤±æ•—'}")
    
    # MLç²¾åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    print("\n=== MLç²¾åº¦ãƒ©ãƒ³ã‚­ãƒ³ã‚° ===")
    ml_accuracies = []
    for symbol, perf in symbol_performance.items():
        if perf['ml'] and perf['ml']['status'] == 'success' and perf['ml'].get('accuracy', 0) > 0:
            ml_accuracies.append((symbol, perf['ml']['accuracy']))
    
    ml_accuracies.sort(key=lambda x: x[1], reverse=True)
    for i, (symbol, accuracy) in enumerate(ml_accuracies, 1):
        print(f"{i}. {symbol}: {accuracy:.3f}")
    
    print("\nâœ… è¤‡æ•°éŠ˜æŸ„å®Ÿå¸‚å ´ãƒ‡ãƒ¼ã‚¿çµ±åˆãƒ†ã‚¹ãƒˆå®Œäº†")

if __name__ == "__main__":
    main()