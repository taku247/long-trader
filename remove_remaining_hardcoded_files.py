#!/usr/bin/env python3
"""
æ®‹å­˜ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨å‰Šé™¤
Phase 1-2å¾Œã«æ®‹ã£ãŸå¤ã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã—ã¦å‰Šé™¤
"""

import os
import pickle
import gzip
from pathlib import Path
from datetime import datetime

def identify_and_remove_hardcoded_files():
    """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®šã—ã¦å‰Šé™¤"""
    print("ğŸ—‘ï¸ æ®‹å­˜ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒ•ã‚¡ã‚¤ãƒ«ã®å®Œå…¨å‰Šé™¤")
    print("=" * 70)
    
    compressed_dir = Path("large_scale_analysis/compressed")
    
    # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒªã‚¹ãƒˆ
    hardcoded_values = [100.0, 105.0, 97.62, 97.619, 97.61904761904762, 1000.0, 1050.0, 976.2]
    
    # å‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒªã‚¹ãƒˆ
    files_to_delete = []
    
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒ£ãƒ³
    all_files = list(compressed_dir.glob("*.pkl.gz"))
    print(f"ğŸ“ ã‚¹ã‚­ãƒ£ãƒ³å¯¾è±¡: {len(all_files)}ãƒ•ã‚¡ã‚¤ãƒ«")
    
    for file_path in all_files:
        try:
            with gzip.open(file_path, 'rb') as f:
                data = pickle.load(f)
            
            if isinstance(data, list):
                df_data = data
            elif hasattr(data, 'to_dict'):
                df_data = data.to_dict('records')
            else:
                continue
            
            # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚§ãƒƒã‚¯
            hardcoded_found = False
            
            for record in df_data[:10]:  # æœ€åˆã®10ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ãƒã‚§ãƒƒã‚¯
                if isinstance(record, dict):
                    for key in ['entry_price', 'take_profit_price', 'stop_loss_price', 'exit_price']:
                        if key in record:
                            value = record[key]
                            for hv in hardcoded_values:
                                if abs(value - hv) < 0.001:
                                    hardcoded_found = True
                                    break
                    if hardcoded_found:
                        break
            
            if hardcoded_found:
                files_to_delete.append(file_path)
                
        except Exception:
            # ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
            pass
    
    print(f"\nâŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«: {len(files_to_delete)}ä»¶")
    
    if files_to_delete:
        print("\nå‰Šé™¤å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«:")
        for i, file_path in enumerate(files_to_delete):
            print(f"  {i+1}. {file_path.name}")
        
        # ç¢ºèªã¨å‰Šé™¤
        print(f"\nğŸ—‘ï¸ {len(files_to_delete)}ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ä¸­...")
        
        deleted_count = 0
        for file_path in files_to_delete:
            try:
                file_path.unlink()
                deleted_count += 1
            except Exception as e:
                print(f"  âŒ å‰Šé™¤å¤±æ•—: {file_path.name} - {e}")
        
        print(f"âœ… {deleted_count}ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†")
    else:
        print("âœ… ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’å«ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã‚ã‚Šã¾ã›ã‚“")

def verify_cleanup():
    """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œã®æ¤œè¨¼"""
    print("\nğŸ” ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å¾Œã®æ¤œè¨¼")
    print("=" * 70)
    
    compressed_dir = Path("large_scale_analysis/compressed")
    
    # å†åº¦ã‚¹ã‚­ãƒ£ãƒ³
    hardcoded_values = [100.0, 105.0, 97.62, 1000.0]
    total_hardcoded = 0
    
    all_files = list(compressed_dir.glob("*.pkl.gz"))
    print(f"ğŸ“ æ®‹å­˜ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(all_files)}")
    
    for file_path in all_files:
        try:
            with gzip.open(file_path, 'rb') as f:
                data = pickle.load(f)
            
            if isinstance(data, list):
                for record in data:
                    if isinstance(record, dict):
                        for key in ['entry_price', 'take_profit_price', 'stop_loss_price']:
                            if key in record:
                                value = record[key]
                                for hv in hardcoded_values:
                                    if abs(value - hv) < 0.001:
                                        total_hardcoded += 1
                                        
        except Exception:
            pass
    
    if total_hardcoded == 0:
        print("âœ… ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã¯å®Œå…¨ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸï¼")
    else:
        print(f"âŒ ã¾ã {total_hardcoded}ä»¶ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒæ®‹ã£ã¦ã„ã¾ã™")

def show_current_status():
    """ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º"""
    print("\nğŸ“Š ç¾åœ¨ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹")
    print("=" * 70)
    
    compressed_dir = Path("large_scale_analysis/compressed")
    all_files = list(compressed_dir.glob("*.pkl.gz"))
    
    # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¨ˆç®—
    total_size = sum(f.stat().st_size for f in all_files) / (1024 * 1024)  # MB
    
    print(f"ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(all_files)}")
    print(f"ç·ã‚µã‚¤ã‚º: {total_size:.1f} MB")
    
    # æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«è¡¨ç¤º
    files_with_time = [(f, f.stat().st_mtime) for f in all_files]
    files_with_time.sort(key=lambda x: x[1], reverse=True)
    
    print("\næœ€æ–°5ãƒ•ã‚¡ã‚¤ãƒ«:")
    for file_path, mtime in files_with_time[:5]:
        dt = datetime.fromtimestamp(mtime)
        print(f"  {file_path.name} - {dt.strftime('%Y-%m-%d %H:%M')}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸš€ æ®‹å­˜ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒ•ã‚¡ã‚¤ãƒ«å®Œå…¨å‰Šé™¤ãƒ—ãƒ­ã‚»ã‚¹")
    print("=" * 70)
    
    # 1. å‰Šé™¤å®Ÿè¡Œ
    identify_and_remove_hardcoded_files()
    
    # 2. æ¤œè¨¼
    verify_cleanup()
    
    # 3. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹è¡¨ç¤º
    show_current_status()
    
    print("\n" + "=" * 70)
    print("âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ—ãƒ­ã‚»ã‚¹å®Œäº†")

if __name__ == '__main__':
    main()