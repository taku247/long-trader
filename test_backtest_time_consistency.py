#!/usr/bin/env python3
"""
ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ç³»åˆ—æ•´åˆæ€§ã®å°‚ç”¨ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
å®Ÿéš›ã®HYPEå•é¡Œã‚’å†ç¾ã—ã¦ä¿®æ­£åŠ¹æœã‚’æ¤œè¨¼
"""

import unittest
import pandas as pd
import numpy as np
from datetime import datetime, timezone, timedelta
import sys
import os
from pathlib import Path
import tempfile

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

class TestBacktestTimeConsistency(unittest.TestCase):
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ç³»åˆ—æ•´åˆæ€§ã®ç‰¹åŒ–ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """HYPEå•é¡Œã‚’æ¨¡æ“¬ã—ãŸãƒ†ã‚¹ãƒˆç’°å¢ƒ"""
        # HYPEå•é¡Œã®å®Ÿéš›ã®æ™‚ç³»åˆ—ã‚’æ¨¡æ“¬
        self.hype_problem_time = datetime(2025, 3, 24, 10, 0, tzinfo=timezone.utc)
        self.current_time = datetime(2025, 6, 25, 8, 40, tzinfo=timezone.utc)
        
        # å®Ÿéš›ã®å•é¡ŒçŠ¶æ³ã‚’æ¨¡æ“¬ã—ãŸãƒ‡ãƒ¼ã‚¿ä½œæˆ
        self.hype_like_data = self._create_hype_problem_data()
        
    def _create_hype_problem_data(self):
        """HYPEå•é¡Œã‚’æ¨¡æ“¬ã—ãŸOHLCVãƒ‡ãƒ¼ã‚¿ä½œæˆ"""
        # 3ãƒ¶æœˆå‰ã‹ã‚‰ç¾åœ¨ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿
        start_date = datetime(2025, 1, 1, tzinfo=timezone.utc)
        end_date = self.current_time
        
        dates = pd.date_range(start=start_date, end=end_date, freq='1H')
        
        # HYPEå•é¡Œã‚’æ¨¡æ“¬ï¼š3æœˆ24æ—¥ä»¥é™ã«ä¾¡æ ¼ãŒå¤§ããä¸Šæ˜‡
        data = []
        base_price = 170.0
        
        for date in dates:
            if date <= self.hype_problem_time:
                # 3æœˆ24æ—¥ä»¥å‰ï¼šæ¯”è¼ƒçš„å®‰å®šã—ãŸä¾¡æ ¼ï¼ˆ170-180ï¼‰
                trend_factor = 1.0
                volatility = 0.01
            else:
                # 3æœˆ24æ—¥ä»¥é™ï¼šä¾¡æ ¼ä¸Šæ˜‡ï¼ˆ180-200ï¼‰
                days_after = (date - self.hype_problem_time).days
                trend_factor = 1.0 + (days_after * 0.002)  # å¾ã€…ã«ä¸Šæ˜‡
                volatility = 0.015
            
            price = base_price * trend_factor
            noise = np.random.normal(0, price * volatility)
            final_price = max(1.0, price + noise)
            
            # OHLCVç”Ÿæˆ
            open_price = final_price
            high_price = final_price * (1 + abs(np.random.normal(0, 0.005)))
            low_price = final_price * (1 - abs(np.random.normal(0, 0.005)))
            close_price = final_price * (1 + np.random.normal(0, 0.003))
            volume = abs(np.random.normal(1000, 200))
            
            data.append({
                'timestamp': date,
                'open': open_price,
                'high': high_price,
                'low': low_price,
                'close': close_price,
                'volume': volume
            })
        
        return pd.DataFrame(data)
    
    def test_hype_problem_reproduction(self):
        """HYPEå•é¡Œã®å†ç¾ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª HYPEå•é¡Œå†ç¾ãƒ†ã‚¹ãƒˆ")
        
        # å•é¡ŒçŠ¶æ³ã®å†ç¾ï¼šå…¨ãƒ‡ãƒ¼ã‚¿ã§æ”¯æŒç·šæ¤œå‡º
        all_data = self.hype_like_data
        problem_time_price = self._get_price_at_time(all_data, self.hype_problem_time)
        
        print(f"   HYPEå•é¡Œæ™‚åˆ»: {self.hype_problem_time}")
        print(f"   å•é¡Œæ™‚åˆ»ã®ä¾¡æ ¼: {problem_time_price:.2f}")
        print(f"   å…¨ãƒ‡ãƒ¼ã‚¿ç¯„å›²: {all_data['timestamp'].min()} ï½ {all_data['timestamp'].max()}")
        print(f"   å…¨ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(all_data)}è¡Œ")
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã§ã®æ”¯æŒç·šæ¤œå‡ºï¼ˆå•é¡Œã®ã‚ã‚‹ã‚±ãƒ¼ã‚¹ï¼‰
        try:
            support_levels_all = self._detect_support_levels_simple(all_data, problem_time_price)
            print(f"   å…¨ãƒ‡ãƒ¼ã‚¿æ”¯æŒç·š: {len(support_levels_all)}å€‹")
            
            # ç¾åœ¨ä¾¡æ ¼ã‚ˆã‚Šä¸‹ã®æ”¯æŒç·šã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            supports_below = [s for s in support_levels_all if s < problem_time_price]
            print(f"   ç¾åœ¨ä¾¡æ ¼ä¸‹ã®æ”¯æŒç·š: {len(supports_below)}å€‹")
            
            if len(supports_below) == 0:
                print("   âŒ HYPEå•é¡Œå†ç¾: ç¾åœ¨ä¾¡æ ¼ä¸‹æ–¹ã«ã‚µãƒãƒ¼ãƒˆãƒ¬ãƒ™ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                problem_reproduced = True
            else:
                print("   âœ… æ”¯æŒç·šæ¤œå‡ºæˆåŠŸï¼ˆå•é¡Œæœªå†ç¾ï¼‰")
                problem_reproduced = False
                
        except Exception as e:
            print(f"   âŒ HYPEå•é¡Œå†ç¾: {e}")
            problem_reproduced = True
        
        # ã“ã®æ®µéšã§ã¯å•é¡ŒãŒå†ç¾ã•ã‚Œã‚‹ã“ã¨ã‚’æœŸå¾…
        self.assertTrue(problem_reproduced or len(supports_below) == 0, "HYPEå•é¡ŒãŒå†ç¾ã•ã‚Œã‚‹ã“ã¨")
        
    def test_future_data_exclusion_fix(self):
        """å°†æ¥ãƒ‡ãƒ¼ã‚¿é™¤å¤–ã«ã‚ˆã‚‹ä¿®æ­£åŠ¹æœãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª å°†æ¥ãƒ‡ãƒ¼ã‚¿é™¤å¤–ä¿®æ­£åŠ¹æœãƒ†ã‚¹ãƒˆ")
        
        # ä¿®æ­£ç‰ˆï¼šå•é¡Œæ™‚åˆ»ä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
        historical_data = self.hype_like_data[self.hype_like_data['timestamp'] <= self.hype_problem_time]
        problem_time_price = self._get_price_at_time(historical_data, self.hype_problem_time)
        
        print(f"   ä¿®æ­£ç‰ˆãƒ‡ãƒ¼ã‚¿ç¯„å›²: {historical_data['timestamp'].min()} ï½ {historical_data['timestamp'].max()}")
        print(f"   ä¿®æ­£ç‰ˆãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {len(historical_data)}è¡Œï¼ˆå‰Šæ¸›: {len(self.hype_like_data) - len(historical_data)}è¡Œï¼‰")
        print(f"   å•é¡Œæ™‚åˆ»ã®ä¾¡æ ¼: {problem_time_price:.2f}")
        
        # æ­´å²ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®æ”¯æŒç·šæ¤œå‡ºï¼ˆä¿®æ­£ç‰ˆï¼‰
        try:
            support_levels_historical = self._detect_support_levels_simple(historical_data, problem_time_price)
            print(f"   æ­´å²ãƒ‡ãƒ¼ã‚¿æ”¯æŒç·š: {len(support_levels_historical)}å€‹")
            
            # ç¾åœ¨ä¾¡æ ¼ã‚ˆã‚Šä¸‹ã®æ”¯æŒç·šã‚’ã‚«ã‚¦ãƒ³ãƒˆ
            supports_below_fixed = [s for s in support_levels_historical if s < problem_time_price]
            print(f"   ç¾åœ¨ä¾¡æ ¼ä¸‹ã®æ”¯æŒç·š: {len(supports_below_fixed)}å€‹")
            
            if len(supports_below_fixed) > 0:
                print("   âœ… ä¿®æ­£åŠ¹æœç¢ºèª: é©åˆ‡ãªæ”¯æŒç·šãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
                print(f"     ä¸»ãªæ”¯æŒç·š: {supports_below_fixed[:3]}")
                fix_successful = True
            else:
                print("   âš ï¸ ä¿®æ­£å¾Œã‚‚æ”¯æŒç·šä¸è¶³ï¼ˆãƒ‡ãƒ¼ã‚¿æœŸé–“ãŒçŸ­ã„å¯èƒ½æ€§ï¼‰")
                fix_successful = False
                
        except Exception as e:
            print(f"   âŒ ä¿®æ­£ç‰ˆã§ã‚‚ã‚¨ãƒ©ãƒ¼: {e}")
            fix_successful = False
        
        # ä¿®æ­£åŠ¹æœã®ç¢ºèª
        self.assertTrue(fix_successful or len(historical_data) < 50, "ä¿®æ­£ã«ã‚ˆã‚Šæ”¯æŒç·šæ¤œå‡ºãŒæ”¹å–„ã•ã‚Œã‚‹ã“ã¨")
        
    def test_data_reduction_impact(self):
        """ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ãŒãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã«ä¸ãˆã‚‹å½±éŸ¿ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ")
        
        import time
        
        # å…¨ãƒ‡ãƒ¼ã‚¿ã§ã®å‡¦ç†æ™‚é–“æ¸¬å®š
        start_time = time.time()
        all_data_supports = self._detect_support_levels_simple(self.hype_like_data, 175.0)
        all_data_time = time.time() - start_time
        
        # æ­´å²ãƒ‡ãƒ¼ã‚¿ã®ã¿ã§ã®å‡¦ç†æ™‚é–“æ¸¬å®š
        historical_data = self.hype_like_data[self.hype_like_data['timestamp'] <= self.hype_problem_time]
        start_time = time.time()
        historical_supports = self._detect_support_levels_simple(historical_data, 175.0)
        historical_time = time.time() - start_time
        
        # çµæœæ¯”è¼ƒ
        data_reduction = (1 - len(historical_data) / len(self.hype_like_data)) * 100
        time_reduction = (1 - historical_time / all_data_time) * 100 if all_data_time > 0 else 0
        
        print(f"   å…¨ãƒ‡ãƒ¼ã‚¿å‡¦ç†: {all_data_time:.4f}ç§’, æ”¯æŒç·š{len(all_data_supports)}å€‹")
        print(f"   æ­´å²ãƒ‡ãƒ¼ã‚¿å‡¦ç†: {historical_time:.4f}ç§’, æ”¯æŒç·š{len(historical_supports)}å€‹")
        print(f"   ãƒ‡ãƒ¼ã‚¿å‰Šæ¸›ç‡: {data_reduction:.1f}%")
        print(f"   æ™‚é–“å‰Šæ¸›ç‡: {time_reduction:.1f}%")
        
        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„åŠ¹æœã®ç¢ºèª
        self.assertGreater(data_reduction, 0, "ãƒ‡ãƒ¼ã‚¿ãŒå‰Šæ¸›ã•ã‚Œã¦ã„ã‚‹ã“ã¨")
        self.assertGreaterEqual(time_reduction, 0, "å‡¦ç†æ™‚é–“ãŒæ”¹å–„ã¾ãŸã¯åŒç­‰ã§ã‚ã‚‹ã“ã¨")
        
    def test_multiple_backtest_points(self):
        """è¤‡æ•°ã®ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ç‚¹ã§ã®æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª è¤‡æ•°ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ç‚¹æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ")
        
        # ç•°ãªã‚‹æ™‚ç‚¹ã§ã®ãƒ†ã‚¹ãƒˆ
        test_points = [
            datetime(2025, 2, 1, 12, 0, tzinfo=timezone.utc),
            datetime(2025, 3, 15, 9, 0, tzinfo=timezone.utc),
            datetime(2025, 4, 10, 14, 0, tzinfo=timezone.utc),
            datetime(2025, 5, 20, 16, 0, tzinfo=timezone.utc),
        ]
        
        consistency_results = []
        
        for i, test_time in enumerate(test_points):
            print(f"   ãƒ†ã‚¹ãƒˆæ™‚ç‚¹{i+1}: {test_time}")
            
            # ãã®æ™‚ç‚¹ã¾ã§ã®ãƒ‡ãƒ¼ã‚¿
            point_data = self.hype_like_data[self.hype_like_data['timestamp'] <= test_time]
            
            if len(point_data) > 20:  # æœ€ä½é™ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆ
                point_price = self._get_price_at_time(point_data, test_time)
                
                try:
                    supports = self._detect_support_levels_simple(point_data, point_price)
                    supports_below = [s for s in supports if s < point_price]
                    
                    result = {
                        'time': test_time,
                        'price': point_price,
                        'data_points': len(point_data),
                        'supports_total': len(supports),
                        'supports_below': len(supports_below),
                        'success': len(supports_below) > 0
                    }
                    
                    print(f"     ä¾¡æ ¼: {point_price:.2f}, ãƒ‡ãƒ¼ã‚¿: {len(point_data)}è¡Œ")
                    print(f"     æ”¯æŒç·š: {len(supports)}å€‹ï¼ˆä¸‹æ–¹: {len(supports_below)}å€‹ï¼‰")
                    print(f"     çµæœ: {'âœ… æˆåŠŸ' if result['success'] else 'âŒ å¤±æ•—'}")
                    
                    consistency_results.append(result)
                    
                except Exception as e:
                    print(f"     âŒ ã‚¨ãƒ©ãƒ¼: {e}")
                    consistency_results.append({
                        'time': test_time,
                        'success': False,
                        'error': str(e)
                    })
            else:
                print(f"     âš ï¸ ãƒ‡ãƒ¼ã‚¿ä¸è¶³: {len(point_data)}è¡Œ")
        
        # æ•´åˆæ€§ç¢ºèª
        successful_points = [r for r in consistency_results if r.get('success', False)]
        success_rate = len(successful_points) / len(consistency_results) if consistency_results else 0
        
        print(f"   æˆåŠŸç‡: {success_rate:.1%} ({len(successful_points)}/{len(consistency_results)})")
        
        # ä¸€å®šã®æˆåŠŸç‡ã‚’æœŸå¾…
        self.assertGreaterEqual(success_rate, 0.5, "è¤‡æ•°æ™‚ç‚¹ã§ä¸€å®šã®æˆåŠŸç‡ã‚’ç¶­æŒã™ã‚‹ã“ã¨")
        
    def test_edge_case_boundary_times(self):
        """å¢ƒç•Œæ™‚åˆ»ã®ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª å¢ƒç•Œæ™‚åˆ»ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ")
        
        # ãƒ‡ãƒ¼ã‚¿ã®æœ€åˆã¨æœ€å¾Œã®æ™‚åˆ»
        first_time = self.hype_like_data['timestamp'].min()
        last_time = self.hype_like_data['timestamp'].max()
        middle_time = first_time + (last_time - first_time) / 2
        
        boundary_cases = [
            ('æœ€åˆã®æ™‚åˆ»', first_time),
            ('ä¸­é–“ã®æ™‚åˆ»', middle_time),
            ('æœ€å¾Œã®æ™‚åˆ»', last_time),
            ('ãƒ‡ãƒ¼ã‚¿ç¯„å›²å¤–ï¼ˆéå»ï¼‰', first_time - timedelta(days=1)),
            ('ãƒ‡ãƒ¼ã‚¿ç¯„å›²å¤–ï¼ˆæœªæ¥ï¼‰', last_time + timedelta(days=1)),
        ]
        
        for case_name, boundary_time in boundary_cases:
            print(f"   {case_name}: {boundary_time}")
            
            filtered_data = self.hype_like_data[self.hype_like_data['timestamp'] <= boundary_time]
            print(f"     ãƒ•ã‚£ãƒ«ã‚¿å¾Œãƒ‡ãƒ¼ã‚¿æ•°: {len(filtered_data)}è¡Œ")
            
            if case_name == 'ãƒ‡ãƒ¼ã‚¿ç¯„å›²å¤–ï¼ˆéå»ï¼‰':
                self.assertEqual(len(filtered_data), 0, "éå»ç¯„å›²å¤–ã§ã¯ç©ºãƒ‡ãƒ¼ã‚¿ã«ãªã‚‹ã“ã¨")
            elif case_name == 'ãƒ‡ãƒ¼ã‚¿ç¯„å›²å¤–ï¼ˆæœªæ¥ï¼‰':
                self.assertEqual(len(filtered_data), len(self.hype_like_data), "æœªæ¥ç¯„å›²å¤–ã§ã¯å…¨ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹ã“ã¨")
            elif case_name == 'æœ€åˆã®æ™‚åˆ»':
                self.assertGreaterEqual(len(filtered_data), 1, "æœ€åˆã®æ™‚åˆ»ã§ã¯å°‘ãªãã¨ã‚‚1è¡Œã¯å«ã¾ã‚Œã‚‹ã“ã¨")
            elif case_name == 'æœ€å¾Œã®æ™‚åˆ»':
                self.assertEqual(len(filtered_data), len(self.hype_like_data), "æœ€å¾Œã®æ™‚åˆ»ã§ã¯å…¨ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹ã“ã¨")
            else:
                self.assertGreater(len(filtered_data), 0, f"{case_name}ã§ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã“ã¨")
                self.assertLess(len(filtered_data), len(self.hype_like_data), f"{case_name}ã§ä¸€éƒ¨ãƒ‡ãƒ¼ã‚¿ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨")
        
        print("   âœ… å¢ƒç•Œæ™‚åˆ»ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹å®Œäº†")
    
    def _get_price_at_time(self, df, target_time):
        """æŒ‡å®šæ™‚åˆ»ã®ä¾¡æ ¼ã‚’å–å¾—"""
        if len(df) == 0:
            return 100.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä¾¡æ ¼
        
        # æœ€ã‚‚è¿‘ã„æ™‚åˆ»ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        time_diffs = abs(df['timestamp'] - target_time)
        closest_idx = time_diffs.idxmin()
        return df.loc[closest_idx, 'close']
    
    def _detect_support_levels_simple(self, df, current_price, min_touches=2):
        """ç°¡æ˜“æ”¯æŒç·šæ¤œå‡ºï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰"""
        if len(df) < 10:
            return []
        
        # ç°¡å˜ãªå±€æ‰€æœ€å°å€¤æ¤œå‡º
        from scipy.signal import argrelextrema
        
        lows = df['low'].values
        min_indices = argrelextrema(lows, np.less, order=3)[0]
        
        if len(min_indices) == 0:
            return []
        
        # ä¾¡æ ¼ãƒ¬ãƒ™ãƒ«ã®ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        min_prices = [lows[i] for i in min_indices]
        
        # è¿‘ã„ä¾¡æ ¼ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        tolerance = current_price * 0.02  # 2%ã®è¨±å®¹ç¯„å›²
        clusters = []
        
        for price in sorted(min_prices):
            added_to_cluster = False
            for cluster in clusters:
                if abs(price - np.mean(cluster)) <= tolerance:
                    cluster.append(price)
                    added_to_cluster = True
                    break
            if not added_to_cluster:
                clusters.append([price])
        
        # æœ€å°ã‚¿ãƒƒãƒæ•°ã§ãƒ•ã‚£ãƒ«ã‚¿
        support_levels = []
        for cluster in clusters:
            if len(cluster) >= min_touches:
                support_levels.append(np.mean(cluster))
        
        return sorted(support_levels)

class TestRealWorldIntegration(unittest.TestCase):
    """å®Ÿéš›ã®ã‚·ã‚¹ãƒ†ãƒ ã¨ã®çµ±åˆãƒ†ã‚¹ãƒˆ"""
    
    def test_scalable_analysis_system_with_current_time(self):
        """ScalableAnalysisSystemã§current_timeå¤‰æ•°ã®ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª ScalableAnalysisSystem current_timeçµ±åˆãƒ†ã‚¹ãƒˆ")
        
        # current_timeå¤‰æ•°ã®å‹•ä½œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        test_scenarios = [
            ('ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆãƒ¢ãƒ¼ãƒ‰', datetime(2025, 3, 24, 10, 0, tzinfo=timezone.utc)),
            ('ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¢ãƒ¼ãƒ‰', None),
        ]
        
        for scenario_name, current_time in test_scenarios:
            print(f"   ã‚·ãƒŠãƒªã‚ª: {scenario_name}")
            print(f"   current_time: {current_time}")
            
            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
            dates = pd.date_range('2025-01-01', '2025-06-01', freq='1H')
            ohlcv_data = pd.DataFrame({
                'timestamp': dates,
                'close': np.random.randn(len(dates)).cumsum() + 100
            })
            
            # æ¡ä»¶åˆ†å²ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆ
            if current_time:  # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ã¯ current_time ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹
                # ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆï¼šcurrent_timeä»¥å‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
                historical_ohlcv = ohlcv_data[ohlcv_data['timestamp'] <= current_time]
                print(f"     ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆ: ãƒ‡ãƒ¼ã‚¿åˆ¶é™ {len(historical_ohlcv)}/{len(ohlcv_data)}æœ¬")
                
                # æ¤œè¨¼
                self.assertGreater(len(historical_ohlcv), 0, f"{scenario_name}: æ­´å²ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã“ã¨")
                self.assertLessEqual(len(historical_ohlcv), len(ohlcv_data), f"{scenario_name}: ãƒ‡ãƒ¼ã‚¿ãŒåˆ¶é™ã•ã‚Œã¦ã„ã‚‹ã“ã¨")
                
                # æ™‚ç³»åˆ—æ•´åˆæ€§
                if len(historical_ohlcv) > 0:
                    latest_time = historical_ohlcv['timestamp'].max()
                    self.assertLessEqual(latest_time, current_time, f"{scenario_name}: æœ€æ–°ãƒ‡ãƒ¼ã‚¿ãŒcurrent_timeä»¥å‰ã§ã‚ã‚‹ã“ã¨")
                    
            else:
                # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ï¼šå…¨ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨
                historical_ohlcv = ohlcv_data
                print(f"     ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ : å…¨ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ {len(historical_ohlcv)}æœ¬")
                
                # æ¤œè¨¼
                self.assertEqual(len(historical_ohlcv), len(ohlcv_data), f"{scenario_name}: å…¨ãƒ‡ãƒ¼ã‚¿ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã“ã¨")
            
            print(f"     âœ… {scenario_name} æ­£å¸¸å‹•ä½œ")

def run_backtest_consistency_tests():
    """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ•´åˆæ€§ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ"""
    print("ğŸ§ª ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ç³»åˆ—æ•´åˆæ€§ - å°‚ç”¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ")
    print("="*70)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆä½œæˆ
    test_suite = unittest.TestSuite()
    
    # HYPEå•é¡Œé–¢é€£ãƒ†ã‚¹ãƒˆ
    test_suite.addTest(TestBacktestTimeConsistency('test_hype_problem_reproduction'))
    test_suite.addTest(TestBacktestTimeConsistency('test_future_data_exclusion_fix'))
    
    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ
    test_suite.addTest(TestBacktestTimeConsistency('test_data_reduction_impact'))
    test_suite.addTest(TestBacktestTimeConsistency('test_multiple_backtest_points'))
    
    # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
    test_suite.addTest(TestBacktestTimeConsistency('test_edge_case_boundary_times'))
    
    # çµ±åˆãƒ†ã‚¹ãƒˆ
    test_suite.addTest(TestRealWorldIntegration('test_scalable_analysis_system_with_current_time'))
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "="*70)
    print("ğŸ“Š ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ•´åˆæ€§ãƒ†ã‚¹ãƒˆçµæœ")
    print("="*70)
    print(f"å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {result.testsRun}")
    print(f"æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"å¤±æ•—: {len(result.failures)}")
    print(f"ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")
    
    if result.failures:
        print("\nâŒ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.failures:
            print(f"  - {test}")
    
    if result.errors:
        print("\nâš ï¸ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.errors:
            print(f"  - {test}")
    
    if result.wasSuccessful():
        print("\nâœ… å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆæ™‚ç³»åˆ—æ•´åˆæ€§ä¿®æ­£ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™ã€‚")
        print("ğŸ¯ HYPEå•é¡Œã®è§£æ±ºãŒç¢ºèªã•ã‚Œã¾ã—ãŸã€‚")
    else:
        print("\nğŸ”´ ä¸€éƒ¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚ä¿®æ­£å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    
    return result.wasSuccessful()

if __name__ == "__main__":
    run_backtest_consistency_tests()