#!/usr/bin/env python3
"""
è¤‡æ•°éŠ˜æŸ„è¿½åŠ ãƒ†ã‚¹ãƒˆ - ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œè¨¼ç”¨

BTCä»¥å¤–ã®æ§˜ã€…ãªéŠ˜æŸ„ã§å®Ÿãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä½¿ç”¨ã—ã¦
éŠ˜æŸ„è¿½åŠ ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
"""

import sys
import os
from datetime import datetime
import pandas as pd
import pickle
import gzip
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_symbol_addition(symbol, timeframe="1h", config="Conservative_ML"):
    """å˜ä¸€éŠ˜æŸ„ã®è¿½åŠ ãƒ†ã‚¹ãƒˆã¨æ¤œè¨¼"""
    print(f"\n{'='*60}")
    print(f"ğŸ” {symbol} è¿½åŠ ãƒ†ã‚¹ãƒˆ")
    print(f"{'='*60}")
    
    try:
        from scalable_analysis_system import ScalableAnalysisSystem
        
        system = ScalableAnalysisSystem()
        
        # åˆ†æã‚’å®Ÿè¡Œ
        print(f"ğŸ“Š {symbol}_{timeframe}_{config} ã®åˆ†æã‚’å®Ÿè¡Œ...")
        
        start_time = datetime.now()
        result = system._generate_single_analysis(
            symbol=symbol,
            timeframe=timeframe,
            config=config
        )
        end_time = datetime.now()
        
        print(f"âœ… åˆ†æå®Œäº†: {result}")
        print(f"â±ï¸ å‡¦ç†æ™‚é–“: {(end_time - start_time).total_seconds():.2f}ç§’")
        
        # ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’æ¤œè¨¼
        if result:
            return verify_generated_data(symbol, timeframe, config)
        else:
            print("âŒ åˆ†æãŒå¤±æ•—ã—ã¾ã—ãŸ")
            return False
            
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

def verify_generated_data(symbol, timeframe, config):
    """ç”Ÿæˆã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œè¨¼"""
    file_path = Path(f"large_scale_analysis/compressed/{symbol}_{timeframe}_{config}.pkl.gz")
    
    if not file_path.exists():
        print(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
        return False
    
    print(f"\nğŸ“Š ç”Ÿæˆãƒ‡ãƒ¼ã‚¿ã®æ¤œè¨¼: {file_path.name}")
    
    try:
        with gzip.open(file_path, 'rb') as f:
            data = pickle.load(f)
        
        # ãƒ‡ãƒ¼ã‚¿å½¢å¼ã«å¿œã˜ã¦å‡¦ç†
        if isinstance(data, list):
            df = pd.DataFrame(data)
        elif isinstance(data, pd.DataFrame):
            df = data
        else:
            print(f"â“ æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿å½¢å¼: {type(data)}")
            return False
        
        print(f"   ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
        
        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒªã‚¹ãƒˆ
        hardcoded_values = [100.0, 105.0, 97.62, 97.619, 97.6190, 1000.0]
        
        # ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’æ¤œè¨¼
        price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price', 
                       'exit_price', 'current_price']
        
        hardcoded_found = False
        suspicious_patterns = []
        
        for col in price_columns:
            if col in df.columns:
                values = df[col].values
                unique_values = pd.Series(values).unique()
                unique_count = len(unique_values)
                
                print(f"\n   {col}:")
                print(f"     ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°: {unique_count}/{len(values)}")
                print(f"     ç¯„å›²: {values.min():.4f} - {values.max():.4f}")
                print(f"     å¹³å‡: {values.mean():.4f}")
                
                # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚§ãƒƒã‚¯
                for hv in hardcoded_values:
                    matching = sum(abs(val - hv) < 0.001 for val in values)
                    if matching > 0:
                        print(f"     âŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ {hv}: {matching}ä»¶")
                        hardcoded_found = True
                
                # ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒã‚§ãƒƒã‚¯
                if unique_count == 1 and len(values) > 10:
                    suspicious_patterns.append(f"{col}ãŒå…¨ã¦åŒã˜å€¤: {values[0]:.4f}")
                
                # æœ€åˆã®5ä»¶è¡¨ç¤º
                print(f"     æœ€åˆã®5ä»¶: {[f'{v:.4f}' for v in values[:5]]}")
        
        # çµæœã‚µãƒãƒªãƒ¼
        print(f"\nğŸ“‹ æ¤œè¨¼çµæœ:")
        if hardcoded_found:
            print("   âŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸï¼")
            return False
        elif suspicious_patterns:
            print("   âš ï¸ ç–‘ã‚ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³:")
            for pattern in suspicious_patterns:
                print(f"      - {pattern}")
            return False
        else:
            print("   âœ… ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãªã— - å®Ÿãƒ‡ãƒ¼ã‚¿ä½¿ç”¨ç¢ºèª")
            return True
            
    except Exception as e:
        print(f"âŒ æ¤œè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” è¤‡æ•°éŠ˜æŸ„ã§ã®æ–°è¦è¿½åŠ ãƒ†ã‚¹ãƒˆ")
    print("=" * 70)
    print("ç›®çš„: BTCä»¥å¤–ã®éŠ˜æŸ„ã§ã‚‚ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª")
    print("=" * 70)
    
    # ãƒ†ã‚¹ãƒˆå¯¾è±¡éŠ˜æŸ„ï¼ˆæ§˜ã€…ãªã‚¿ã‚¤ãƒ—ï¼‰
    test_symbols = [
        "ETH",    # ãƒ¡ã‚¸ãƒ£ãƒ¼éŠ˜æŸ„
        "SOL",    # äººæ°—ã‚¢ãƒ«ãƒˆã‚³ã‚¤ãƒ³
        "DOGE",   # ãƒŸãƒ¼ãƒ ã‚³ã‚¤ãƒ³
        "AVAX",   # DeFié–¢é€£
        "ARB",    # L2ãƒˆãƒ¼ã‚¯ãƒ³
    ]
    
    # çµæœé›†è¨ˆ
    results = []
    
    for symbol in test_symbols:
        success = test_symbol_addition(symbol, "1h", "Conservative_ML")
        results.append({
            'symbol': symbol,
            'success': success
        })
    
    # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
    print("\n" + "=" * 70)
    print("ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 70)
    
    success_count = sum(1 for r in results if r['success'])
    total_count = len(results)
    
    for result in results:
        status = "âœ… æˆåŠŸ" if result['success'] else "âŒ å¤±æ•—"
        print(f"{result['symbol']:10} {status}")
    
    print(f"\næˆåŠŸç‡: {success_count}/{total_count} ({success_count/total_count*100:.1f}%)")
    
    if success_count == total_count:
        print("\nğŸ‰ å…¨éŠ˜æŸ„ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãªã—ï¼ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ã®å®Œå…¨é™¤å»ã‚’ç¢ºèª")
    else:
        print("\nâš ï¸ ä¸€éƒ¨ã®éŠ˜æŸ„ã§å•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ")
    
    # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤ï¼‰
    print("\nğŸ§¹ ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—...")
    cleanup_test_files(test_symbols)

def cleanup_test_files(symbols):
    """ãƒ†ã‚¹ãƒˆã§ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤"""
    compressed_dir = Path("large_scale_analysis/compressed")
    
    for symbol in symbols:
        pattern = f"{symbol}_*_Conservative_ML.pkl.gz"
        files = list(compressed_dir.glob(pattern))
        for file in files:
            try:
                file.unlink()
                print(f"   å‰Šé™¤: {file.name}")
            except:
                pass

if __name__ == '__main__':
    main()