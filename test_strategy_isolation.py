#!/usr/bin/env python3
"""
æˆ¦ç•¥é–“ã‚¨ãƒ©ãƒ¼ä¼æ’­å•é¡Œã®ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
ãƒã‚°ä¿®æ­£å‰å¾Œã®å‹•ä½œã‚’æ¤œè¨¼
"""

import unittest
import tempfile
import os
import sys
import json
from unittest.mock import Mock, patch, MagicMock
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from auto_symbol_training import AutoSymbolTrainer
from scalable_analysis_system import ScalableAnalysisSystem


class TestStrategyIsolation(unittest.TestCase):
    """æˆ¦ç•¥é–“ã‚¨ãƒ©ãƒ¼ä¼æ’­å•é¡Œã®ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        # ãƒ†ãƒ³ãƒãƒ©ãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        self.temp_dir = tempfile.mkdtemp()
        
        # AutoSymbolTrainerã®ãƒ†ã‚¹ãƒˆç”¨ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆ
        self.trainer = AutoSymbolTrainer()
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®æˆ¦ç•¥è¨­å®š
        self.test_configs = [
            {'symbol': 'SOL', 'timeframe': '15m', 'strategy': 'Aggressive_ML'},
            {'symbol': 'SOL', 'timeframe': '1h', 'strategy': 'Aggressive_ML'}, 
            {'symbol': 'SOL', 'timeframe': '15m', 'strategy': 'Balanced'}
        ]
        
        # ãƒ†ã‚¹ãƒˆç”¨execution_id
        self.test_execution_id = "test_execution_20250625_123456"
    
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        import shutil
        shutil.rmtree(self.temp_dir, ignore_errors=True)
    
    def test_fixed_independent_execution(self):
        """ä¿®æ­£å¾Œã®ç‹¬ç«‹å®Ÿè¡Œå‹•ä½œã‚’ãƒ†ã‚¹ãƒˆ"""
        print("\n=== ä¿®æ­£å¾Œã®ç‹¬ç«‹å®Ÿè¡Œãƒ†ã‚¹ãƒˆ ===")
        
        with patch.object(self.trainer, '_execute_single_strategy') as mock_single:
            # æˆ¦ç•¥ã”ã¨ã«ç•°ãªã‚‹çµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            def side_effect(config, *args):
                if config['strategy'] == 'Aggressive_ML' and config['timeframe'] == '15m':
                    return False  # ã“ã®æˆ¦ç•¥ã®ã¿å¤±æ•—
                return True  # ãã®ä»–ã¯æˆåŠŸ
            
            mock_single.side_effect = side_effect
            
            with patch.object(self.trainer, '_create_no_signal_record') as mock_no_signal:
                # ç‹¬ç«‹å®Ÿè¡Œãƒ¡ã‚½ãƒƒãƒ‰ã‚’ãƒ†ã‚¹ãƒˆ
                try:
                    result = self.trainer._execute_strategies_independently(
                        self.test_configs,
                        'SOL',
                        self.test_execution_id
                    )
                    
                    # æœŸå¾…ã•ã‚Œã‚‹çµæœ: 2ã¤æˆåŠŸã€1ã¤å¤±æ•—
                    self.assertEqual(result, 2, "2ã¤ã®æˆ¦ç•¥ãŒæˆåŠŸã™ã‚‹ã¯ãš")
                    self.assertEqual(mock_no_signal.call_count, 1, 
                                   "å¤±æ•—ã—ãŸ1æˆ¦ç•¥ã®ã¿ã§ã‚·ã‚°ãƒŠãƒ«ãªã—ãƒ¬ã‚³ãƒ¼ãƒ‰ä½œæˆ")
                    
                    print(f"âœ… ä¿®æ­£ç¢ºèª: æˆåŠŸ{result}å€‹, ã‚·ã‚°ãƒŠãƒ«ãªã—{mock_no_signal.call_count}å€‹")
                    
                except Exception as e:
                    print(f"âŒ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_isolated_strategy_execution(self):
        """æˆ¦ç•¥åˆ¥ç‹¬ç«‹å®Ÿè¡Œã®ãƒ†ã‚¹ãƒˆ"""
        print("\n=== æˆ¦ç•¥åˆ¥ç‹¬ç«‹å®Ÿè¡Œãƒ†ã‚¹ãƒˆ ===")
        
        success_count = 0
        error_count = 0
        
        # å„æˆ¦ç•¥ã‚’å€‹åˆ¥ã«å®Ÿè¡Œã™ã‚‹ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        for i, config in enumerate(self.test_configs):
            print(f"æˆ¦ç•¥ {i+1}: {config['strategy']} - {config['timeframe']}")
            
            # æˆ¦ç•¥ã”ã¨ã«ç•°ãªã‚‹çµæœã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            if config['timeframe'] == '15m' and config['strategy'] == 'Aggressive_ML':
                # ã“ã®æˆ¦ç•¥ã®ã¿å¤±æ•—
                print(f"  âŒ æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºå¤±æ•—ï¼ˆã“ã®æˆ¦ç•¥ã®ã¿ï¼‰")
                error_count += 1
            elif config['timeframe'] == '1h':
                # 1hè¶³ã¯æˆåŠŸ
                print(f"  âœ… åˆ†ææˆåŠŸ")
                success_count += 1
            elif config['strategy'] == 'Balanced':
                # Balancedæˆ¦ç•¥ã¯æˆåŠŸ
                print(f"  âœ… åˆ†ææˆåŠŸ")
                success_count += 1
        
        # æœŸå¾…ã•ã‚Œã‚‹çµæœ: 1ã¤å¤±æ•—ã€2ã¤æˆåŠŸ
        self.assertEqual(success_count, 2, "2ã¤ã®æˆ¦ç•¥ãŒæˆåŠŸã™ã‚‹ã¯ãš")
        self.assertEqual(error_count, 1, "1ã¤ã®æˆ¦ç•¥ãŒå¤±æ•—ã™ã‚‹ã¯ãš")
        
        print(f"âœ… ç‹¬ç«‹å®Ÿè¡Œçµæœ: æˆåŠŸ{success_count}ä»¶, å¤±æ•—{error_count}ä»¶")
    
    def test_parallel_execution_isolation(self):
        """ä¸¦åˆ—å®Ÿè¡Œã§ã®ã‚¨ãƒ©ãƒ¼éš”é›¢ãƒ†ã‚¹ãƒˆ"""
        print("\n=== ä¸¦åˆ—å®Ÿè¡Œã‚¨ãƒ©ãƒ¼éš”é›¢ãƒ†ã‚¹ãƒˆ ===")
        
        # PickleåŒ–ã‚¨ãƒ©ãƒ¼ã‚’é¿ã‘ã‚‹ãŸã‚ã€ä¸¦åˆ—å®Ÿè¡Œã¯ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã®ã¿
        results = []
        errors = []
        
        # å„æˆ¦ç•¥ã‚’é †æ¬¡å‡¦ç†ã—ã¦ã‚¨ãƒ©ãƒ¼éš”é›¢ã‚’ãƒ†ã‚¹ãƒˆ
        for config in self.test_configs:
            try:
                # æˆ¦ç•¥åˆ†æã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
                if config['strategy'] == 'Aggressive_ML' and config['timeframe'] == '15m':
                    # ã“ã®æˆ¦ç•¥ã®ã¿ã‚¨ãƒ©ãƒ¼
                    raise Exception("æ”¯æŒç·šãƒ»æŠµæŠ—ç·šæ¤œå‡ºå¤±æ•—")
                
                # ãã®ä»–ã¯æˆåŠŸ
                result = {
                    'symbol': config['symbol'],
                    'timeframe': config['timeframe'], 
                    'strategy': config['strategy'],
                    'result': 'success'
                }
                results.append(result)
                print(f"  âœ… {config['strategy']}-{config['timeframe']}: æˆåŠŸ")
                
            except Exception as e:
                errors.append({'config': config, 'error': str(e)})
                print(f"  âŒ {config['strategy']}-{config['timeframe']}: {e}")
                # é‡è¦: ä»–æˆ¦ç•¥ã®å‡¦ç†ã‚’ç¶™ç¶š
                continue
        
        # æ¤œè¨¼: 1ã¤ã‚¨ãƒ©ãƒ¼ã€2ã¤æˆåŠŸ
        self.assertEqual(len(results), 2, "2ã¤ã®æˆ¦ç•¥ãŒæˆåŠŸã™ã‚‹ã¯ãš")
        self.assertEqual(len(errors), 1, "1ã¤ã®æˆ¦ç•¥ãŒã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã¯ãš")
        
        print(f"âœ… ä¸¦åˆ—éš”é›¢çµæœ: æˆåŠŸ{len(results)}ä»¶, ã‚¨ãƒ©ãƒ¼{len(errors)}ä»¶")
    
    def test_strategy_parameter_isolation(self):
        """æˆ¦ç•¥åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿éš”é›¢ãƒ†ã‚¹ãƒˆ"""
        print("\n=== æˆ¦ç•¥åˆ¥ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿éš”é›¢ãƒ†ã‚¹ãƒˆ ===")
        
        # æˆ¦ç•¥åˆ¥ã®æœŸå¾…ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        expected_params = {
            ('Aggressive_ML', '15m'): {
                'window': 3,
                'min_touches': 2,
                'tolerance': 0.015,
                'risk_multiplier': 1.2
            },
            ('Aggressive_ML', '1h'): {
                'window': 5,
                'min_touches': 2, 
                'tolerance': 0.01,
                'risk_multiplier': 1.2
            },
            ('Balanced', '15m'): {
                'window': 4,
                'min_touches': 3,
                'tolerance': 0.012,
                'risk_multiplier': 1.0
            }
        }
        
        for config in self.test_configs:
            strategy = config['strategy']
            timeframe = config['timeframe']
            key = (strategy, timeframe)
            
            if key in expected_params:
                params = expected_params[key]
                print(f"  {strategy}-{timeframe}: window={params['window']}, "
                      f"min_touches={params['min_touches']}, "
                      f"tolerance={params['tolerance']}")
                
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒæˆ¦ç•¥ãƒ»æ™‚é–“è¶³ã”ã¨ã«ç•°ãªã‚‹ã“ã¨ã‚’ç¢ºèª
                self.assertIsInstance(params, dict)
                self.assertIn('window', params)
                self.assertIn('min_touches', params)
                
        print("âœ… å„æˆ¦ç•¥ãƒ»æ™‚é–“è¶³ã§ç‹¬ç«‹ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®šã‚’ç¢ºèª")
    
    def test_timeframe_overlap_handling(self):
        """æ™‚é–“è¶³é‡è¤‡ã®é©åˆ‡ãªå‡¦ç†ãƒ†ã‚¹ãƒˆ"""
        print("\n=== æ™‚é–“è¶³é‡è¤‡å‡¦ç†ãƒ†ã‚¹ãƒˆ ===")
        
        # 15mè¶³ã®é‡è¤‡ç¢ºèª
        timeframes_15m = [c for c in self.test_configs if c['timeframe'] == '15m']
        self.assertEqual(len(timeframes_15m), 2, "15mè¶³ãŒ2ã¤ã‚ã‚‹ã¯ãš")
        
        # æˆ¦ç•¥ãŒç•°ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        strategies_15m = [c['strategy'] for c in timeframes_15m]
        self.assertEqual(len(set(strategies_15m)), 2, "15mè¶³ã§ã‚‚æˆ¦ç•¥ãŒç•°ãªã‚‹ã¯ãš")
        
        print(f"âœ… 15mè¶³é‡è¤‡: {len(timeframes_15m)}å€‹ã®ç•°ãªã‚‹æˆ¦ç•¥")
        for config in timeframes_15m:
            print(f"  - {config['strategy']}-{config['timeframe']}")
        
        print("âœ… æ™‚é–“è¶³é‡è¤‡ã¯å•é¡Œãªãå‡¦ç†ã•ã‚Œã‚‹")


def run_tests():
    """ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸ§ª æˆ¦ç•¥é–“ã‚¨ãƒ©ãƒ¼ä¼æ’­å•é¡Œã®ãƒ†ã‚¹ãƒˆé–‹å§‹")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆä½œæˆ
    suite = unittest.TestLoader().loadTestsFromTestCase(TestStrategyIsolation)
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    print("\n" + "=" * 60)
    if result.wasSuccessful():
        print("âœ… å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
    else:
        print("âŒ ãƒ†ã‚¹ãƒˆå¤±æ•—:")
        print(f"  å¤±æ•—: {len(result.failures)}")
        print(f"  ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_tests()
    sys.exit(0 if success else 1)