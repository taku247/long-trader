#!/usr/bin/env python3
"""
å¤‰æ•°å®šç¾©é †åºãƒã‚°é˜²æ­¢ãƒ†ã‚¹ãƒˆ - ohlcv_dataæœªå®šç¾©ã‚¨ãƒ©ãƒ¼ã®ã‚ˆã†ãªå•é¡Œã‚’é˜²ããƒ†ã‚¹ãƒˆ

å¤‰æ•°ã®å®šç¾©å‰å‚ç…§ã‚„ã€ãƒ¡ã‚½ãƒƒãƒ‰é–“ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å•é¡Œã‚’æ¤œå‡ºã—ã¦
åŒæ§˜ã®ãƒã‚°ãŒç™ºç”Ÿã—ãªã„ã‚ˆã†ã«ã™ã‚‹åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚·ã‚¹ãƒ†ãƒ 
"""

import ast
import sys
import os
import re
from typing import Dict, List, Set, Tuple
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

class VariableDefinitionOrderChecker:
    """å¤‰æ•°å®šç¾©é †åºãƒã‚§ãƒƒã‚«ãƒ¼"""
    
    def __init__(self):
        self.critical_files = [
            "scalable_analysis_system.py",
            "auto_symbol_training.py", 
            "engines/high_leverage_bot_orchestrator.py",
            "new_symbol_addition_system.py"
        ]
        self.critical_variables = [
            "ohlcv_data",
            "custom_period_settings",
            "market_data",
            "data",
            "result",
            "bot"
        ]
    
    def check_variable_definition_order(self, file_path: str) -> Dict[str, List[str]]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…ã®å¤‰æ•°å®šç¾©é †åºã‚’ãƒã‚§ãƒƒã‚¯"""
        print(f"\nğŸ” å¤‰æ•°å®šç¾©é †åºãƒã‚§ãƒƒã‚¯: {file_path}")
        print("=" * 60)
        
        issues = {
            "undefined_references": [],
            "potential_issues": [],
            "conditional_definitions": []
        }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ASTãƒ‘ãƒ¼ã‚¹ã«ã‚ˆã‚‹è©³ç´°åˆ†æ
            tree = ast.parse(content)
            
            # å„é–¢æ•°ãƒ»ãƒ¡ã‚½ãƒƒãƒ‰ã‚’å€‹åˆ¥ã«åˆ†æ
            for node in ast.walk(tree):
                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):
                    method_issues = self._analyze_method_variables(node, content)
                    for issue_type, issue_list in method_issues.items():
                        issues[issue_type].extend(issue_list)
            
            # æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹è¿½åŠ ãƒã‚§ãƒƒã‚¯
            regex_issues = self._regex_based_checks(content, file_path)
            for issue_type, issue_list in regex_issues.items():
                issues[issue_type].extend(issue_list)
            
            # çµæœè¡¨ç¤º
            self._display_check_results(file_path, issues)
            
            return issues
            
        except Exception as e:
            print(f"âŒ {file_path} åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            return issues
    
    def _analyze_method_variables(self, method_node: ast.AST, content: str) -> Dict[str, List[str]]:
        """ãƒ¡ã‚½ãƒƒãƒ‰å†…ã®å¤‰æ•°å®šç¾©ãƒ»ä½¿ç”¨é †åºã‚’åˆ†æ"""
        issues = {
            "undefined_references": [],
            "potential_issues": [],
            "conditional_definitions": []
        }
        
        method_name = method_node.name
        defined_vars = set()
        used_vars = set()
        
        # ãƒ¡ã‚½ãƒƒãƒ‰å†…ã®å…¨ãƒãƒ¼ãƒ‰ã‚’èµ°æŸ»
        for node in ast.walk(method_node):
            if isinstance(node, ast.Assign):
                # å¤‰æ•°å®šç¾©
                for target in node.targets:
                    if isinstance(target, ast.Name):
                        defined_vars.add(target.id)
            
            elif isinstance(node, ast.Name) and isinstance(node.ctx, ast.Load):
                # å¤‰æ•°ä½¿ç”¨
                var_name = node.id
                if var_name in self.critical_variables:
                    if var_name not in defined_vars:
                        issues["undefined_references"].append(
                            f"{method_name}: '{var_name}' ãŒå®šç¾©å‰ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§"
                        )
                    used_vars.add(var_name)
        
        return issues
    
    def _regex_based_checks(self, content: str, file_path: str) -> Dict[str, List[str]]:
        """æ­£è¦è¡¨ç¾ã«ã‚ˆã‚‹è¿½åŠ ãƒã‚§ãƒƒã‚¯"""
        issues = {
            "undefined_references": [],
            "potential_issues": [],
            "conditional_definitions": []
        }
        
        lines = content.split('\n')
        
        for i, line in enumerate(lines, 1):
            # é‡è¦å¤‰æ•°ã®ä½¿ç”¨ã‚’ãƒã‚§ãƒƒã‚¯
            for var in self.critical_variables:
                if re.search(rf'\b{var}\b', line) and '=' not in line:
                    # å¤‰æ•°ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ãŒä»£å…¥ã§ãªã„
                    if self._is_potential_undefined_usage(lines, i-1, var):
                        issues["potential_issues"].append(
                            f"è¡Œ{i}: '{var}' ã®ä½¿ç”¨æ™‚ã«å®šç¾©æ¸ˆã¿ç¢ºèªãŒå¿…è¦ - {line.strip()}"
                        )
            
            # æ¡ä»¶åˆ†å²å†…ã§ã®å¤‰æ•°å®šç¾©ã‚’ãƒã‚§ãƒƒã‚¯
            if re.search(r'^\s*(if|elif|else|try|except|for|while)', line):
                next_lines = lines[i:i+10] if i < len(lines)-10 else lines[i:]
                for j, next_line in enumerate(next_lines):
                    for var in self.critical_variables:
                        if f"{var} =" in next_line:
                            issues["conditional_definitions"].append(
                                f"è¡Œ{i+j+1}: '{var}' ãŒæ¡ä»¶åˆ†å²å†…ã§å®šç¾© - {next_line.strip()}"
                            )
        
        return issues
    
    def _is_potential_undefined_usage(self, lines: List[str], current_line: int, var: str) -> bool:
        """å¤‰æ•°ãŒå®šç¾©å‰ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        # ç¾åœ¨è¡Œã‚ˆã‚Šå‰ã®è¡Œã§å¤‰æ•°ãŒå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        for i in range(current_line):
            if f"{var} =" in lines[i] or f"{var}:" in lines[i]:
                return False
        
        # é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        for i in range(max(0, current_line-20), current_line):
            if re.search(rf'def.*{var}', lines[i]) or re.search(rf'async def.*{var}', lines[i]):
                return False
        
        return True
    
    def _display_check_results(self, file_path: str, issues: Dict[str, List[str]]):
        """ãƒã‚§ãƒƒã‚¯çµæœã‚’è¡¨ç¤º"""
        total_issues = sum(len(issue_list) for issue_list in issues.values())
        
        if total_issues == 0:
            print("âœ… å¤‰æ•°å®šç¾©é †åº: å•é¡Œãªã—")
            return
        
        print(f"âš ï¸ å¤‰æ•°å®šç¾©é †åºã®å•é¡Œ: {total_issues}ä»¶ç™ºè¦‹")
        
        if issues["undefined_references"]:
            print("\nğŸ”´ æœªå®šç¾©å‚ç…§ã‚¨ãƒ©ãƒ¼:")
            for issue in issues["undefined_references"]:
                print(f"  - {issue}")
        
        if issues["potential_issues"]:
            print("\nğŸŸ¡ æ½œåœ¨çš„å•é¡Œ:")
            for issue in issues["potential_issues"]:
                print(f"  - {issue}")
        
        if issues["conditional_definitions"]:
            print("\nğŸŸ  æ¡ä»¶åˆ†å²å†…å®šç¾©:")
            for issue in issues["conditional_definitions"]:
                print(f"  - {issue}")

def test_data_flow_consistency():
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    data_flow_patterns = [
        {
            "description": "OHLCVãƒ‡ãƒ¼ã‚¿å–å¾— â†’ ä½¿ç”¨",
            "get_pattern": r"ohlcv_data\s*=.*(?:get_ohlcv_data|_fetch_market_data)",
            "use_pattern": r"ohlcv_data\.(?:index|empty|iloc)",
            "files": ["scalable_analysis_system.py", "auto_symbol_training.py"]
        },
        {
            "description": "ã‚«ã‚¹ã‚¿ãƒ æœŸé–“è¨­å®š â†’ ä½¿ç”¨",
            "get_pattern": r"custom_period_settings\s*=",
            "use_pattern": r"custom_period_settings\.get\(",
            "files": ["auto_symbol_training.py", "engines/high_leverage_bot_orchestrator.py"]
        },
        {
            "description": "ãƒœãƒƒãƒˆã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ â†’ ãƒ‡ãƒ¼ã‚¿å–å¾—",
            "get_pattern": r"bot\s*=.*HighLeverageBotOrchestrator",
            "use_pattern": r"bot\._fetch_market_data",
            "files": ["scalable_analysis_system.py"]
        }
    ]
    
    all_flows_ok = True
    
    for pattern in data_flow_patterns:
        print(f"\nğŸ“‹ {pattern['description']}")
        
        for file_path in pattern['files']:
            full_path = f"/Users/moriwakikeita/tools/long-trader/{file_path}"
            if os.path.exists(full_path):
                flow_ok = _check_data_flow_pattern(full_path, pattern)
                if not flow_ok:
                    all_flows_ok = False
                    print(f"  âŒ {file_path}: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å•é¡Œ")
                else:
                    print(f"  âœ… {file_path}: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ­£å¸¸")
            else:
                print(f"  âš ï¸ {file_path}: ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    return all_flows_ok

def _check_data_flow_pattern(file_path: str, pattern: Dict) -> bool:
    """ç‰¹å®šã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        get_matches = re.findall(pattern['get_pattern'], content)
        use_matches = re.findall(pattern['use_pattern'], content)
        
        # ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹ã®ã«ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„å ´åˆã¯å•é¡Œ
        if get_matches and not use_matches:
            return False
        
        # ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹ã®ã«ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãªã„å ´åˆã‚‚å•é¡Œ
        if use_matches and not get_matches:
            return False
        
        return True
        
    except Exception as e:
        print(f"    âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def test_critical_variable_initialization():
    """é‡è¦å¤‰æ•°ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""
    print(f"\nğŸ” é‡è¦å¤‰æ•°åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    initialization_rules = [
        {
            "variable": "ohlcv_data",
            "required_init": ["pd.DataFrame()", "get_ohlcv_data", "_fetch_market_data"],
            "files": ["scalable_analysis_system.py", "auto_symbol_training.py"]
        },
        {
            "variable": "custom_period_settings", 
            "required_init": ["dict", "get(", "json.loads"],
            "files": ["auto_symbol_training.py", "scalable_analysis_system.py"]
        },
        {
            "variable": "bot",
            "required_init": ["HighLeverageBotOrchestrator()", "=.*bot"],
            "files": ["scalable_analysis_system.py"]
        }
    ]
    
    all_init_ok = True
    
    for rule in initialization_rules:
        print(f"\nğŸ“‹ {rule['variable']} åˆæœŸåŒ–ãƒã‚§ãƒƒã‚¯")
        
        for file_path in rule['files']:
            full_path = f"/Users/moriwakikeita/tools/long-trader/{file_path}"
            if os.path.exists(full_path):
                init_ok = _check_variable_initialization(full_path, rule)
                if not init_ok:
                    all_init_ok = False
                    print(f"  âŒ {file_path}: {rule['variable']} åˆæœŸåŒ–å•é¡Œ")
                else:
                    print(f"  âœ… {file_path}: {rule['variable']} åˆæœŸåŒ–æ­£å¸¸")
    
    return all_init_ok

def _check_variable_initialization(file_path: str, rule: Dict) -> bool:
    """å¤‰æ•°åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        var_name = rule['variable']
        
        # å¤‰æ•°ãŒä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if var_name not in content:
            return True  # ä½¿ç”¨ã•ã‚Œã¦ã„ãªã‘ã‚Œã°OK
        
        # åˆæœŸåŒ–ãƒ‘ã‚¿ãƒ¼ãƒ³ã®ã„ãšã‚Œã‹ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        for init_pattern in rule['required_init']:
            if re.search(rf"{var_name}.*{init_pattern}", content):
                return True
        
        # é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ã—ã¦æ¸¡ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if re.search(rf'def.*{var_name}', content):
            return True
        
        return False
        
    except Exception as e:
        return False

def create_variable_safety_checklist():
    """å¤‰æ•°å®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆä½œæˆ"""
    checklist = """
ğŸ›¡ï¸ å¤‰æ•°å®šç¾©é †åºãƒã‚°é˜²æ­¢ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

## ğŸ”§ å®Ÿè£…æ™‚ã®ãƒã‚§ãƒƒã‚¯é …ç›®

### 1. **å¤‰æ•°å®šç¾©å‰ã®ä½¿ç”¨é˜²æ­¢**
   â–¡ å¤‰æ•°ã‚’ä½¿ç”¨ã™ã‚‹å‰ã«å¿…ãšå®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
   â–¡ æ¡ä»¶åˆ†å²å†…ã§ã®å®šç¾©ã¯ã€åˆ†å²å¤–ã§ã‚‚å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª
   â–¡ ãƒ«ãƒ¼ãƒ—å†…ã§å®šç¾©ã•ã‚Œã‚‹å¤‰æ•°ã¯ã€ãƒ«ãƒ¼ãƒ—å¤–ã§åˆæœŸåŒ–ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª

### 2. **é‡è¦å¤‰æ•°ã®å®‰å…¨ãªåˆæœŸåŒ–**
   â–¡ ohlcv_data: ãƒ‡ãƒ¼ã‚¿å–å¾—å‰ã«NoneåˆæœŸåŒ–
   â–¡ custom_period_settings: ãƒ¡ã‚½ãƒƒãƒ‰é–‹å§‹æ™‚ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
   â–¡ bot: ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ä½œæˆå‰ã«NoneåˆæœŸåŒ–
   â–¡ result: åˆ†æçµæœæ ¼ç´å‰ã«ç©ºè¾æ›¸ã§åˆæœŸåŒ–

### 3. **ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ã®ä¸€è²«æ€§**
   â–¡ ãƒ‡ãƒ¼ã‚¿å–å¾— â†’ æ¤œè¨¼ â†’ ä½¿ç”¨ ã®é †åºã‚’å®ˆã‚‹
   â–¡ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å—ã‘æ¸¡ã—ã§å‹ãƒ»å½¢å¼ãŒä¸€è‡´ã—ã¦ã„ã‚‹ã‹ç¢ºèª
   â–¡ éåŒæœŸå‡¦ç†ã§ã®å¤‰æ•°ã‚¹ã‚³ãƒ¼ãƒ—ã‚’é©åˆ‡ã«ç®¡ç†

### 4. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**
   â–¡ å¤‰æ•°ãŒæœªå®šç¾©ã®å ´åˆã®é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
   â–¡ ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
   â–¡ ä¾‹å¤–ç™ºç”Ÿæ™‚ã®å¤‰æ•°çŠ¶æ…‹ã®é©åˆ‡ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—

### 5. **ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒã‚¤ãƒ³ãƒˆ**
   â–¡ ãƒ¡ã‚½ãƒƒãƒ‰å†…ã§ä½¿ç”¨ã•ã‚Œã‚‹å¤‰æ•°ã®å®šç¾©å ´æ‰€ã‚’ç¢ºèª
   â–¡ æ¡ä»¶åˆ†å²ã§å®šç¾©ã•ã‚Œã‚‹å¤‰æ•°ã®ä»£æ›¿ãƒ‘ã‚¹ã‚’ç¢ºèª
   â–¡ è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«é–“ã§ã®å¤‰æ•°å—ã‘æ¸¡ã—ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç¢ºèª

## ğŸ§ª ãƒ†ã‚¹ãƒˆæ¨å¥¨äº‹é …

### 1. **å˜ä½“ãƒ†ã‚¹ãƒˆã§ã®ç¢ºèª**
   â–¡ å„ãƒ¡ã‚½ãƒƒãƒ‰ã§ä½¿ç”¨ã•ã‚Œã‚‹å¤‰æ•°ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
   â–¡ ç•°å¸¸ã‚±ãƒ¼ã‚¹ã§ã®å¤‰æ•°çŠ¶æ…‹ãƒ†ã‚¹ãƒˆ
   â–¡ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æœªæŒ‡å®šæ™‚ã®å‹•ä½œãƒ†ã‚¹ãƒˆ

### 2. **çµ±åˆãƒ†ã‚¹ãƒˆã§ã®ç¢ºèª**
   â–¡ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼å…¨ä½“ã§ã®å¤‰æ•°ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ
   â–¡ è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«é–“ã§ã®å¤‰æ•°å—ã‘æ¸¡ã—ãƒ†ã‚¹ãƒˆ
   â–¡ å®Ÿéš›ã®ã‚·ãƒŠãƒªã‚ªã§ã®å¤‰æ•°å®šç¾©é †åºãƒ†ã‚¹ãƒˆ

### 3. **å®šæœŸå®Ÿè¡Œæ¨å¥¨ãƒ†ã‚¹ãƒˆ**
   â–¡ test_variable_definition_order.py ã‚’å®Ÿè¡Œ
   â–¡ test_parameter_consistency_v2.py ã‚’å®Ÿè¡Œ
   â–¡ å®Ÿéš›ã®ã‚·ãƒ³ãƒœãƒ«åˆ†æã§ã®å‹•ä½œç¢ºèª

## ğŸš¨ è­¦å‘Šãƒ‘ã‚¿ãƒ¼ãƒ³

### 1. **å±é™ºãªå®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³**
   âŒ ifæ¡ä»¶å†…ã§ã®ã¿å¤‰æ•°å®šç¾©
   âŒ try-exceptå†…ã§ã®ã¿å¤‰æ•°å®šç¾©
   âŒ ãƒ«ãƒ¼ãƒ—å†…ã§ã®åˆå›ã®ã¿å¤‰æ•°å®šç¾©
   âŒ éåŒæœŸå‡¦ç†ã§ã®å¤‰æ•°ã‚¹ã‚³ãƒ¼ãƒ—æ¼ã‚Œ

### 2. **æ¨å¥¨å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³**
   âœ… ãƒ¡ã‚½ãƒƒãƒ‰é–‹å§‹æ™‚ã®å¤‰æ•°åˆæœŸåŒ–
   âœ… æ˜ç¤ºçš„ãªNone/ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤è¨­å®š
   âœ… æ®µéšçš„ãªå¤‰æ•°è¨­å®šï¼ˆå–å¾—â†’æ¤œè¨¼â†’ä½¿ç”¨ï¼‰
   âœ… é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãå¤‰æ•°æ“ä½œ

## ğŸ“‹ ä¿®æ­£ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ

```python
def example_method(self, symbol: str, custom_period_settings: dict = None):
    # 1. å¤‰æ•°åˆæœŸåŒ–ï¼ˆå¿…é ˆï¼‰
    ohlcv_data = None
    result = {}
    bot = None
    
    try:
        # 2. æ®µéšçš„ãªãƒ‡ãƒ¼ã‚¿å–å¾—
        bot = self._create_bot_instance()
        ohlcv_data = self._fetch_data(symbol, custom_period_settings)
        
        # 3. ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
        if ohlcv_data is None or ohlcv_data.empty:
            raise ValueError("Data not available")
        
        # 4. å‡¦ç†å®Ÿè¡Œ
        result = self._process_data(ohlcv_data)
        
        return result
        
    except Exception as e:
        # 5. é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
        logger.error(f"Method failed: {e}")
        return {"error": str(e)}
```
"""
    return checklist

def test_all_variable_definition_safety():
    """å…¨å¤‰æ•°å®šç¾©å®‰å…¨æ€§ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ›¡ï¸ å¤‰æ•°å®šç¾©é †åºãƒã‚°é˜²æ­¢ãƒ†ã‚¹ãƒˆ v3")
    print("=" * 70)
    print("ohlcv_dataæœªå®šç¾©ã‚¨ãƒ©ãƒ¼ã®ã‚ˆã†ãªå•é¡Œã‚’é˜²ãåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆ")
    print()
    
    checker = VariableDefinitionOrderChecker()
    
    # 1. å„ãƒ•ã‚¡ã‚¤ãƒ«ã®å¤‰æ•°å®šç¾©é †åºãƒã‚§ãƒƒã‚¯
    all_files_ok = True
    for file_path in checker.critical_files:
        full_path = f"/Users/moriwakikeita/tools/long-trader/{file_path}"
        if os.path.exists(full_path):
            issues = checker.check_variable_definition_order(full_path)
            total_issues = sum(len(issue_list) for issue_list in issues.values())
            if total_issues > 0:
                all_files_ok = False
        else:
            print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {file_path}")
            all_files_ok = False
    
    # 2. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ
    data_flow_ok = test_data_flow_consistency()
    
    # 3. é‡è¦å¤‰æ•°åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ
    init_ok = test_critical_variable_initialization()
    
    # 4. çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸ¯ å¤‰æ•°å®šç¾©å®‰å…¨æ€§ãƒ†ã‚¹ãƒˆçµæœ")
    print("=" * 70)
    print(f"ğŸ“„ ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ•°å®šç¾©é †åº: {'âœ… æ­£å¸¸' if all_files_ok else 'âŒ å•é¡Œ'}")
    print(f"ğŸ”„ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ä¸€è²«æ€§: {'âœ… æ­£å¸¸' if data_flow_ok else 'âŒ å•é¡Œ'}")
    print(f"ğŸ”§ é‡è¦å¤‰æ•°åˆæœŸåŒ–: {'âœ… æ­£å¸¸' if init_ok else 'âŒ å•é¡Œ'}")
    
    overall_success = all_files_ok and data_flow_ok and init_ok
    
    print(f"\n{'='*70}")
    print(f"ğŸ† æœ€çµ‚åˆ¤å®š: {'âœ… å¤‰æ•°å®‰å…¨æ€§OK' if overall_success else 'âš ï¸ è¦ä¿®æ­£'}")
    print(f"{'='*70}")
    
    if overall_success:
        print("ğŸ‰ å¤‰æ•°å®šç¾©é †åºãƒã‚°ãŒç™ºç”Ÿã™ã‚‹ãƒªã‚¹ã‚¯ã¯ä½ã„ã§ã™ï¼")
        print("ğŸ”’ ohlcv_dataæœªå®šç¾©ã‚¨ãƒ©ãƒ¼ã®ã‚ˆã†ãªå•é¡Œã¯äºˆé˜²ã•ã‚Œã¦ã„ã¾ã™")
    else:
        print("ğŸ”§ å¤‰æ•°å®šç¾©ã«é–¢ã™ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã™")
        print("âš ï¸ ä¿®æ­£ã—ã¦ã‹ã‚‰æœ¬ç•ªç’°å¢ƒã§ä½¿ç”¨ã—ã¦ãã ã•ã„")
    
    # ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆè¡¨ç¤º
    print(create_variable_safety_checklist())
    
    return overall_success

if __name__ == "__main__":
    success = test_all_variable_definition_safety()
    sys.exit(0 if success else 1)