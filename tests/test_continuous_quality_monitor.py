#!/usr/bin/env python3
"""
ç¶™ç¶šçš„å“è³ªç›£è¦–ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

ç›®çš„:
1. éŠ˜æŸ„è¿½åŠ å¾Œã®ãƒˆãƒ¬ãƒ¼ãƒ‰çµæœå“è³ªã‚’è‡ªå‹•ãƒã‚§ãƒƒã‚¯
2. ç•°å¸¸ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã®æ—©æœŸæ¤œçŸ¥
3. CI/CDãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®å“è³ªã‚²ãƒ¼ãƒˆ

ç‰¹å¾´:
- æ–°è¦éŠ˜æŸ„è¿½åŠ æ™‚ã®è‡ªå‹•å®Ÿè¡Œ
- Slack/ãƒ¡ãƒ¼ãƒ«é€šçŸ¥é€£æº
- å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰ç›£è¦–
"""

import sys
import os
import unittest
import pandas as pd
import numpy as np
import pickle
import gzip
import json
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Tuple, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class TradeResultQualityMonitor(unittest.TestCase):
    """ãƒˆãƒ¬ãƒ¼ãƒ‰çµæœå“è³ªç›£è¦–"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.compressed_dir = Path("large_scale_analysis/compressed")
        self.quality_thresholds = {
            'min_unique_entry_prices': 5,      # æœ€å°å›ºæœ‰ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼æ•°
            'min_price_variation_cv': 0.01,    # æœ€å°å¤‰å‹•ä¿‚æ•°
            'max_market_deviation_pct': 25,    # æœ€å¤§å¸‚å ´ä¾¡æ ¼ä¹–é›¢ç‡
            'min_trades_per_strategy': 10,     # æˆ¦ç•¥ã‚ãŸã‚Šæœ€å°ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°
            'max_identical_price_ratio': 0.5   # åŒä¸€ä¾¡æ ¼ã®æœ€å¤§æ¯”ç‡
        }
        
    def test_new_symbols_have_valid_price_distribution(self):
        """æ–°è¦éŠ˜æŸ„ã®ä¾¡æ ¼åˆ†å¸ƒãŒå¦¥å½“ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        recent_symbols = self._get_recently_added_symbols(days=7)
        
        if not recent_symbols:
            self.skipTest("éå»7æ—¥é–“ã«è¿½åŠ ã•ã‚ŒãŸæ–°è¦éŠ˜æŸ„ãŒã‚ã‚Šã¾ã›ã‚“")
        
        quality_issues = []
        
        for symbol in recent_symbols:
            issues = self._analyze_symbol_price_quality(symbol)
            if issues:
                quality_issues.extend(issues)
        
        self.assertEqual(len(quality_issues), 0,
                        f"æ–°è¦éŠ˜æŸ„ã§å“è³ªå•é¡Œã‚’æ¤œå‡º: {quality_issues}")
    
    def test_all_strategies_use_dynamic_pricing(self):
        """å…¨æˆ¦ç•¥ãŒå‹•çš„ä¾¡æ ¼è¨­å®šã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        static_pricing_strategies = self._detect_static_pricing_strategies()
        
        self.assertEqual(len(static_pricing_strategies), 0,
                        f"é™çš„ä¾¡æ ¼è¨­å®šã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹æˆ¦ç•¥: {static_pricing_strategies}")
    
    def test_backtest_results_are_realistic(self):
        """ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœãŒç¾å®Ÿçš„ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        unrealistic_results = self._detect_unrealistic_backtest_results()
        
        self.assertEqual(len(unrealistic_results), 0,
                        f"éç¾å®Ÿçš„ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœ: {unrealistic_results}")
    
    def test_price_calculation_consistency(self):
        """ä¾¡æ ¼è¨ˆç®—ã®ä¸€è²«æ€§ã‚’ç¢ºèª"""
        inconsistencies = self._check_price_calculation_consistency()
        
        self.assertEqual(len(inconsistencies), 0,
                        f"ä¾¡æ ¼è¨ˆç®—ã®ä¸€è²«æ€§é•å: {inconsistencies}")
    
    def _get_recently_added_symbols(self, days: int = 7) -> List[str]:
        """æœ€è¿‘è¿½åŠ ã•ã‚ŒãŸéŠ˜æŸ„ã‚’å–å¾—"""
        recent_symbols = set()
        
        if not self.compressed_dir.exists():
            return list(recent_symbols)
        
        cutoff_time = datetime.now() - timedelta(days=days)
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                if mtime > cutoff_time:
                    parts = file_path.stem.replace('.pkl', '').split('_')
                    if len(parts) >= 1:
                        recent_symbols.add(parts[0])
            except Exception:
                continue
        
        return list(recent_symbols)
    
    def _analyze_symbol_price_quality(self, symbol: str) -> List[Dict]:
        """éŠ˜æŸ„ã®ä¾¡æ ¼å“è³ªã‚’åˆ†æ"""
        issues = []
        
        symbol_files = list(self.compressed_dir.glob(f"{symbol}_*.pkl.gz"))
        
        for file_path in symbol_files:
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # å“è³ªãƒã‚§ãƒƒã‚¯
                strategy_issues = self._check_strategy_quality(
                    df, symbol, timeframe, strategy
                )
                issues.extend(strategy_issues)
            
            except Exception as e:
                issues.append({
                    'symbol': symbol,
                    'file': str(file_path),
                    'issue_type': 'FILE_READ_ERROR',
                    'description': f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}",
                    'severity': 'HIGH'
                })
        
        return issues
    
    def _check_strategy_quality(self, df: pd.DataFrame, symbol: str, 
                              timeframe: str, strategy: str) -> List[Dict]:
        """æˆ¦ç•¥ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        # 1. ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°ãƒã‚§ãƒƒã‚¯
        if len(df) < self.quality_thresholds['min_trades_per_strategy']:
            issues.append({
                'symbol': symbol,
                'timeframe': timeframe,
                'strategy': strategy,
                'issue_type': 'INSUFFICIENT_TRADES',
                'description': f"ãƒˆãƒ¬ãƒ¼ãƒ‰æ•°ä¸è¶³: {len(df)}ä»¶",
                'severity': 'MEDIUM'
            })
        
        # 2. ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã®å“è³ªãƒã‚§ãƒƒã‚¯
        if 'entry_price' in df.columns:
            entry_issues = self._check_price_column_quality(
                df, 'entry_price', symbol, timeframe, strategy
            )
            issues.extend(entry_issues)
        
        # 3. TP/SLä¾¡æ ¼ã®å“è³ªãƒã‚§ãƒƒã‚¯
        for price_col in ['take_profit_price', 'stop_loss_price']:
            if price_col in df.columns:
                price_issues = self._check_price_column_quality(
                    df, price_col, symbol, timeframe, strategy
                )
                issues.extend(price_issues)
        
        # 4. ä¾¡æ ¼é–¢ä¿‚ã®è«–ç†ãƒã‚§ãƒƒã‚¯
        logic_issues = self._check_price_logic(df, symbol, timeframe, strategy)
        issues.extend(logic_issues)
        
        return issues
    
    def _check_price_column_quality(self, df: pd.DataFrame, column: str,
                                   symbol: str, timeframe: str, strategy: str) -> List[Dict]:
        """ä¾¡æ ¼ã‚«ãƒ©ãƒ ã®å“è³ªã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        values = pd.to_numeric(df[column], errors='coerce').dropna()
        if len(values) == 0:
            return issues
        
        # 1. å›ºæœ‰å€¤æ•°ãƒã‚§ãƒƒã‚¯
        unique_count = len(values.unique())
        if unique_count < self.quality_thresholds['min_unique_entry_prices']:
            issues.append({
                'symbol': symbol,
                'timeframe': timeframe,
                'strategy': strategy,
                'column': column,
                'issue_type': 'LOW_PRICE_DIVERSITY',
                'description': f"å›ºæœ‰ä¾¡æ ¼æ•°ä¸è¶³: {unique_count}ç¨®é¡",
                'severity': 'HIGH'
            })
        
        # 2. å¤‰å‹•ä¿‚æ•°ãƒã‚§ãƒƒã‚¯
        if len(values) > 1:
            cv = values.std() / values.mean() if values.mean() > 0 else 0
            if cv < self.quality_thresholds['min_price_variation_cv']:
                issues.append({
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'strategy': strategy,
                    'column': column,
                    'issue_type': 'LOW_PRICE_VARIATION',
                    'description': f"ä¾¡æ ¼å¤‰å‹•ä¸è¶³: CV={cv:.6f}",
                    'severity': 'HIGH'
                })
        
        # 3. åŒä¸€å€¤æ¯”ç‡ãƒã‚§ãƒƒã‚¯
        value_counts = values.value_counts()
        if len(value_counts) > 0:
            most_common_ratio = value_counts.iloc[0] / len(values)
            if most_common_ratio > self.quality_thresholds['max_identical_price_ratio']:
                issues.append({
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'strategy': strategy,
                    'column': column,
                    'issue_type': 'HIGH_IDENTICAL_PRICE_RATIO',
                    'description': f"åŒä¸€ä¾¡æ ¼æ¯”ç‡: {most_common_ratio:.1%}",
                    'severity': 'HIGH'
                })
        
        return issues
    
    def _check_price_logic(self, df: pd.DataFrame, symbol: str,
                          timeframe: str, strategy: str) -> List[Dict]:
        """ä¾¡æ ¼ã®è«–ç†çš„å¦¥å½“æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        required_cols = ['entry_price', 'take_profit_price', 'stop_loss_price']
        if not all(col in df.columns for col in required_cols):
            return issues
        
        entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
        tp_prices = pd.to_numeric(df['take_profit_price'], errors='coerce').dropna()
        sl_prices = pd.to_numeric(df['stop_loss_price'], errors='coerce').dropna()
        
        if len(entry_prices) == 0 or len(tp_prices) == 0 or len(sl_prices) == 0:
            return issues
        
        # ãƒ­ãƒ³ã‚°ãƒã‚¸ã‚·ãƒ§ãƒ³å‰æã§ã®ãƒã‚§ãƒƒã‚¯
        min_length = min(len(entry_prices), len(tp_prices), len(sl_prices))
        
        # TP > Entry ãƒã‚§ãƒƒã‚¯
        invalid_tp = sum(tp <= entry for tp, entry in 
                        zip(tp_prices[:min_length], entry_prices[:min_length]))
        if invalid_tp > 0:
            issues.append({
                'symbol': symbol,
                'timeframe': timeframe,
                'strategy': strategy,
                'issue_type': 'INVALID_TP_LOGIC',
                'description': f"åˆ©ç¢ºä¾¡æ ¼ãŒã‚¨ãƒ³ãƒˆãƒªãƒ¼ä»¥ä¸‹: {invalid_tp}ä»¶",
                'severity': 'HIGH'
            })
        
        # SL < Entry ãƒã‚§ãƒƒã‚¯
        invalid_sl = sum(sl >= entry for sl, entry in 
                        zip(sl_prices[:min_length], entry_prices[:min_length]))
        if invalid_sl > 0:
            issues.append({
                'symbol': symbol,
                'timeframe': timeframe,
                'strategy': strategy,
                'issue_type': 'INVALID_SL_LOGIC',
                'description': f"æåˆ‡ä¾¡æ ¼ãŒã‚¨ãƒ³ãƒˆãƒªãƒ¼ä»¥ä¸Š: {invalid_sl}ä»¶",
                'severity': 'HIGH'
            })
        
        return issues
    
    def _detect_static_pricing_strategies(self) -> List[Dict]:
        """é™çš„ä¾¡æ ¼è¨­å®šã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹æˆ¦ç•¥ã‚’æ¤œå‡º"""
        static_strategies = []
        
        if not self.compressed_dir.exists():
            return static_strategies
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # é™çš„ä¾¡æ ¼è¨­å®šã‚’ãƒã‚§ãƒƒã‚¯
                if 'entry_price' in df.columns:
                    entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                    
                    if len(entry_prices) > 5:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«
                        unique_count = len(entry_prices.unique())
                        cv = entry_prices.std() / entry_prices.mean() if entry_prices.mean() > 0 else 0
                        
                        # é™çš„ä¾¡æ ¼è¨­å®šã®ç–‘ã„
                        if unique_count <= 2 or cv < 0.001:
                            static_strategies.append({
                                'symbol': symbol,
                                'timeframe': timeframe,
                                'strategy': strategy,
                                'unique_prices': unique_count,
                                'coefficient_of_variation': cv,
                                'total_trades': len(entry_prices)
                            })
            
            except Exception:
                continue
        
        return static_strategies
    
    def _detect_unrealistic_backtest_results(self) -> List[Dict]:
        """éç¾å®Ÿçš„ãªãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆçµæœã‚’æ¤œå‡º"""
        unrealistic_results = []
        
        if not self.compressed_dir.exists():
            return unrealistic_results
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty or len(df) < 10:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # éç¾å®Ÿçš„ãªçµæœã‚’ãƒã‚§ãƒƒã‚¯
                unrealistic_checks = self._check_unrealistic_metrics(df, symbol, timeframe, strategy)
                unrealistic_results.extend(unrealistic_checks)
            
            except Exception:
                continue
        
        return unrealistic_results
    
    def _check_unrealistic_metrics(self, df: pd.DataFrame, symbol: str, 
                                  timeframe: str, strategy: str) -> List[Dict]:
        """éç¾å®Ÿçš„ãªãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        # PnLé–¢é€£ãƒã‚§ãƒƒã‚¯
        if 'pnl' in df.columns:
            pnl_values = pd.to_numeric(df['pnl'], errors='coerce').dropna()
            
            if len(pnl_values) > 0:
                # å‹ç‡ãƒã‚§ãƒƒã‚¯
                win_rate = (pnl_values > 0).mean()
                if win_rate > 0.95:  # 95%ä»¥ä¸Šã®å‹ç‡ã¯éç¾å®Ÿçš„
                    issues.append({
                        'symbol': symbol,
                        'timeframe': timeframe,
                        'strategy': strategy,
                        'issue_type': 'UNREALISTIC_WIN_RATE',
                        'description': f"å‹ç‡ãŒéç¾å®Ÿçš„: {win_rate:.1%}",
                        'severity': 'HIGH'
                    })
                
                # å¹³å‡åˆ©ç›Šãƒã‚§ãƒƒã‚¯
                avg_profit = pnl_values.mean()
                if avg_profit > 50:  # å¹³å‡50%ä»¥ä¸Šã®åˆ©ç›Šã¯éç¾å®Ÿçš„
                    issues.append({
                        'symbol': symbol,
                        'timeframe': timeframe,
                        'strategy': strategy,
                        'issue_type': 'UNREALISTIC_AVG_PROFIT',
                        'description': f"å¹³å‡åˆ©ç›ŠãŒéç¾å®Ÿçš„: {avg_profit:.1f}%",
                        'severity': 'HIGH'
                    })
        
        return issues
    
    def _check_price_calculation_consistency(self) -> List[Dict]:
        """ä¾¡æ ¼è¨ˆç®—ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        inconsistencies = []
        
        # åŒä¸€éŠ˜æŸ„ãƒ»åŒä¸€æ™‚é–“è¶³ã§ã®æˆ¦ç•¥é–“ä¾¡æ ¼å·®ã‚’ãƒã‚§ãƒƒã‚¯
        symbol_timeframe_groups = {}
        
        if not self.compressed_dir.exists():
            return inconsistencies
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                    
                    key = f"{symbol}_{timeframe}"
                    if key not in symbol_timeframe_groups:
                        symbol_timeframe_groups[key] = []
                    
                    symbol_timeframe_groups[key].append({
                        'strategy': strategy,
                        'file_path': file_path
                    })
            except Exception:
                continue
        
        # å„ã‚°ãƒ«ãƒ¼ãƒ—ã§ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        for key, strategies in symbol_timeframe_groups.items():
            if len(strategies) > 1:
                symbol, timeframe = key.split('_', 1)
                consistency_issues = self._check_strategy_group_consistency(
                    symbol, timeframe, strategies
                )
                inconsistencies.extend(consistency_issues)
        
        return inconsistencies
    
    def _check_strategy_group_consistency(self, symbol: str, timeframe: str, 
                                        strategies: List[Dict]) -> List[Dict]:
        """æˆ¦ç•¥ã‚°ãƒ«ãƒ¼ãƒ—ã®ä¸€è²«æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        issues = []
        
        strategy_prices = {}
        
        for strategy_info in strategies:
            try:
                with gzip.open(strategy_info['file_path'], 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty or 'entry_price' not in df.columns:
                    continue
                
                entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                if len(entry_prices) > 0:
                    strategy_prices[strategy_info['strategy']] = entry_prices.mean()
            
            except Exception:
                continue
        
        # æˆ¦ç•¥é–“ã®ä¾¡æ ¼å·®ã‚’ãƒã‚§ãƒƒã‚¯
        if len(strategy_prices) > 1:
            prices = list(strategy_prices.values())
            price_range = max(prices) - min(prices)
            avg_price = np.mean(prices)
            
            # å¹³å‡ä¾¡æ ¼ã®10%ä»¥ä¸Šã®å·®ã¯ä¸€è²«æ€§ã®å•é¡Œ
            if price_range > avg_price * 0.1:
                issues.append({
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'issue_type': 'PRICE_INCONSISTENCY_BETWEEN_STRATEGIES',
                    'description': f"æˆ¦ç•¥é–“ä¾¡æ ¼å·®: {price_range:.6f} (å¹³å‡ã®{price_range/avg_price:.1%})",
                    'strategy_prices': strategy_prices,
                    'severity': 'MEDIUM'
                })
        
        return issues

class QualityMetricsReporter:
    """å“è³ªãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ¬ãƒãƒ¼ã‚¿ãƒ¼"""
    
    @staticmethod
    def generate_quality_report(test_result: unittest.TestResult) -> Dict[str, Any]:
        """å“è³ªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        report = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'overall_status': 'PASS' if test_result.wasSuccessful() else 'FAIL',
            'tests_run': test_result.testsRun,
            'failures': len(test_result.failures),
            'errors': len(test_result.errors),
            'issues_detected': [],
            'recommendations': []
        }
        
        # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã‹ã‚‰ã®å•é¡ŒæŠ½å‡º
        for test, traceback in test_result.failures:
            if 'ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º' in traceback:
                report['issues_detected'].append({
                    'type': 'HARDCODED_VALUES',
                    'severity': 'HIGH',
                    'description': 'ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ'
                })
                report['recommendations'].append(
                    'scalable_analysis_system.pyã¨high_leverage_bot_orchestrator.pyã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’é™¤å»ã—ã¦ãã ã•ã„'
                )
            
            if 'å“è³ªå•é¡Œã‚’æ¤œå‡º' in traceback:
                report['issues_detected'].append({
                    'type': 'QUALITY_ISSUES',
                    'severity': 'HIGH',
                    'description': 'æ–°è¦éŠ˜æŸ„ã§å“è³ªå•é¡ŒãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸ'
                })
                report['recommendations'].append(
                    'ä¾¡æ ¼è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã‚’è¦‹ç›´ã—ã€å‹•çš„ä¾¡æ ¼ç”Ÿæˆã‚’ç¢ºä¿ã—ã¦ãã ã•ã„'
                )
        
        return report
    
    @staticmethod
    def save_report(report: Dict[str, Any], filename: str = None):
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"quality_report_{timestamp}.json"
        
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        return filename

if __name__ == '__main__':
    print("ğŸ¯ ç¶™ç¶šçš„å“è³ªç›£è¦–ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
    suite = unittest.TestLoader().loadTestsFromTestCase(TradeResultQualityMonitor)
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
    reporter = QualityMetricsReporter()
    quality_report = reporter.generate_quality_report(result)
    report_file = reporter.save_report(quality_report)
    
    print("\n" + "=" * 60)
    print("ğŸ“Š å“è³ªç›£è¦–çµæœ")
    print("=" * 60)
    print(f"å…¨ä½“ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {quality_report['overall_status']}")
    print(f"å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {quality_report['tests_run']}")
    print(f"å¤±æ•—: {quality_report['failures']}")
    print(f"ã‚¨ãƒ©ãƒ¼: {quality_report['errors']}")
    print(f"å“è³ªãƒ¬ãƒãƒ¼ãƒˆ: {report_file}")
    
    if quality_report['issues_detected']:
        print("\nâš ï¸  æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        for issue in quality_report['issues_detected']:
            print(f"  - {issue['type']}: {issue['description']}")
    
    if quality_report['recommendations']:
        print("\nğŸ’¡ æ¨å¥¨äº‹é …:")
        for rec in quality_report['recommendations']:
            print(f"  - {rec}")
    
    # CI/CDç”¨çµ‚äº†ã‚³ãƒ¼ãƒ‰
    exit_code = 1 if not result.wasSuccessful() else 0
    exit(exit_code)