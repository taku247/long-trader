#!/usr/bin/env python3
"""
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥å°‚ç”¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

ç›®çš„:
1. æ–°ã—ã„éŠ˜æŸ„è¿½åŠ æ™‚ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®è‡ªå‹•æ¤œçŸ¥
2. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã®ä¾¡æ ¼è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã®å¦¥å½“æ€§æ¤œè¨¼
3. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ã®ä½¿ç”¨æ¤œçŸ¥ã¨è­¦å‘Š

ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°:
- éŠ˜æŸ„è¿½åŠ å¾Œã®è‡ªå‹•å®Ÿè¡Œ
- CIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®ç¶™ç¶šç›£è¦–
- å®šæœŸçš„ãªå“è³ªãƒã‚§ãƒƒã‚¯
"""

import sys
import os
import unittest
import pandas as pd
import numpy as np
import pickle
import gzip
import asyncio
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Tuple, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class HardcodedValueDetector(unittest.TestCase):
    """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.compressed_dir = Path("large_scale_analysis/compressed")
        self.known_hardcoded_values = [
            100.0, 105.0, 97.62, 100.00, 105.00, 97.620,
            0.04705, 0.050814, 0.044810,  # GMTæ¤œå‡ºå€¤
            102.0, 95.0, 98.0, 103.0     # è¿½åŠ ã®ç–‘ã‚ã—ã„å€¤
        ]
        self.tolerance = 0.0001  # è¨±å®¹èª¤å·®
        
    def test_no_hardcoded_entry_prices(self):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª"""
        violations = self._scan_for_hardcoded_values(['entry_price'])
        
        self.assertEqual(len(violations), 0, 
                        f"ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º: {violations}")
    
    def test_no_hardcoded_tp_sl_prices(self):
        """TP/SLä¾¡æ ¼ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª"""
        violations = self._scan_for_hardcoded_values(['take_profit_price', 'stop_loss_price'])
        
        self.assertEqual(len(violations), 0, 
                        f"TP/SLä¾¡æ ¼ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º: {violations}")
    
    def test_price_variation_exists(self):
        """ä¾¡æ ¼ã«é©åˆ‡ãªå¤‰å‹•ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        low_variation_cases = self._check_price_variation()
        
        self.assertEqual(len(low_variation_cases), 0,
                        f"ä¾¡æ ¼å¤‰å‹•ãŒä¸è¶³ã—ã¦ã„ã‚‹æˆ¦ç•¥: {low_variation_cases}")
    
    def test_prices_near_current_market(self):
        """ä¾¡æ ¼ãŒç¾åœ¨å¸‚å ´ä¾¡æ ¼ã«è¿‘ã„ã“ã¨ã‚’ç¢ºèª"""
        price_deviation_cases = []
        
        # å„éŠ˜æŸ„ã®ç¾åœ¨ä¾¡æ ¼ã‚’å–å¾—ã—ã¦ãƒã‚§ãƒƒã‚¯
        symbols = self._get_available_symbols()
        
        for symbol in symbols:
            current_price = self._get_current_market_price(symbol)
            if current_price:
                deviations = self._check_price_deviation_from_market(symbol, current_price)
                price_deviation_cases.extend(deviations)
        
        self.assertEqual(len(price_deviation_cases), 0,
                        f"å¸‚å ´ä¾¡æ ¼ã‹ã‚‰å¤§ããä¹–é›¢ã—ãŸä¾¡æ ¼: {price_deviation_cases}")
    
    def test_no_identical_price_patterns(self):
        """åŒä¸€ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¢ºèª"""
        identical_patterns = self._detect_identical_patterns()
        
        self.assertEqual(len(identical_patterns), 0,
                        f"åŒä¸€ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º: {identical_patterns}")
    
    def _scan_for_hardcoded_values(self, target_columns: List[str]) -> List[Dict]:
        """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        violations = []
        
        if not self.compressed_dir.exists():
            return violations
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # å¯¾è±¡ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
                for col in target_columns:
                    if col in df.columns:
                        violations.extend(
                            self._check_column_for_hardcoded_values(
                                df, col, symbol, timeframe, strategy
                            )
                        )
            
            except Exception as e:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
                continue
        
        return violations
    
    def _check_column_for_hardcoded_values(self, df: pd.DataFrame, column: str, 
                                         symbol: str, timeframe: str, strategy: str) -> List[Dict]:
        """ã‚«ãƒ©ãƒ å†…ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’ãƒã‚§ãƒƒã‚¯"""
        violations = []
        
        values = pd.to_numeric(df[column], errors='coerce').dropna()
        if len(values) == 0:
            return violations
        
        for hardcoded_val in self.known_hardcoded_values:
            matching_count = sum(abs(val - hardcoded_val) < self.tolerance for val in values)
            
            if matching_count > 0:
                violation_percentage = matching_count / len(values) * 100
                
                violations.append({
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'strategy': strategy,
                    'column': column,
                    'hardcoded_value': hardcoded_val,
                    'matching_count': matching_count,
                    'total_count': len(values),
                    'percentage': violation_percentage,
                    'severity': 'HIGH' if violation_percentage > 50 else 'MEDIUM'
                })
        
        return violations
    
    def _check_price_variation(self) -> List[Dict]:
        """ä¾¡æ ¼å¤‰å‹•ã®ä¸è¶³ã‚’ãƒã‚§ãƒƒã‚¯"""
        low_variation_cases = []
        
        if not self.compressed_dir.exists():
            return low_variation_cases
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ä¾¡æ ¼å¤‰å‹•ã‚’ãƒã‚§ãƒƒã‚¯
                price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price']
                
                for col in price_columns:
                    if col in df.columns:
                        values = pd.to_numeric(df[col], errors='coerce').dropna()
                        
                        if len(values) > 1:
                            # æ¨™æº–åå·®ãƒã‚§ãƒƒã‚¯
                            std_dev = values.std()
                            mean_val = values.mean()
                            cv = std_dev / mean_val if mean_val > 0 else 0  # å¤‰å‹•ä¿‚æ•°
                            
                            # å›ºæœ‰å€¤æ•°ãƒã‚§ãƒƒã‚¯
                            unique_count = len(values.unique())
                            unique_ratio = unique_count / len(values)
                            
                            # ç•°å¸¸åˆ¤å®š
                            if cv < 0.001 or unique_ratio < 0.1:
                                low_variation_cases.append({
                                    'symbol': symbol,
                                    'timeframe': timeframe,
                                    'strategy': strategy,
                                    'column': col,
                                    'coefficient_of_variation': cv,
                                    'unique_ratio': unique_ratio,
                                    'unique_count': unique_count,
                                    'total_count': len(values),
                                    'std_dev': std_dev,
                                    'mean': mean_val
                                })
            
            except Exception as e:
                continue
        
        return low_variation_cases
    
    def _get_current_market_price(self, symbol: str) -> Optional[float]:
        """ç¾åœ¨ã®å¸‚å ´ä¾¡æ ¼ã‚’å–å¾—"""
        try:
            from hyperliquid_api_client import MultiExchangeAPIClient
            
            async def fetch_price():
                client = MultiExchangeAPIClient()
                end_time = datetime.now(timezone.utc)
                start_time = end_time - timedelta(hours=1)
                
                data = await client.get_ohlcv_data(symbol, '1h', start_time, end_time)
                if not data.empty:
                    return float(data['close'].iloc[-1])
                return None
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                return loop.run_until_complete(fetch_price())
            finally:
                loop.close()
                
        except Exception as e:
            print(f"å¸‚å ´ä¾¡æ ¼å–å¾—ã‚¨ãƒ©ãƒ¼ ({symbol}): {e}")
            return None
    
    def _check_price_deviation_from_market(self, symbol: str, current_price: float) -> List[Dict]:
        """å¸‚å ´ä¾¡æ ¼ã‹ã‚‰ã®ä¹–é›¢ã‚’ãƒã‚§ãƒƒã‚¯"""
        deviations = []
        
        if not self.compressed_dir.exists():
            return deviations
        
        for file_path in self.compressed_dir.glob(f"{symbol}_*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã®ä¹–é›¢ã‚’ãƒã‚§ãƒƒã‚¯
                if 'entry_price' in df.columns:
                    entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                    
                    if len(entry_prices) > 0:
                        mean_entry = entry_prices.mean()
                        deviation_pct = abs(mean_entry - current_price) / current_price * 100
                        
                        # 30%ä»¥ä¸Šã®ä¹–é›¢ã¯ç•°å¸¸
                        if deviation_pct > 30:
                            deviations.append({
                                'symbol': symbol,
                                'timeframe': timeframe,
                                'strategy': strategy,
                                'current_market_price': current_price,
                                'mean_entry_price': mean_entry,
                                'deviation_percentage': deviation_pct,
                                'severity': 'HIGH' if deviation_pct > 50 else 'MEDIUM'
                            })
            
            except Exception as e:
                continue
        
        return deviations
    
    def _detect_identical_patterns(self) -> List[Dict]:
        """åŒä¸€ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º"""
        identical_patterns = []
        
        if not self.compressed_dir.exists():
            return identical_patterns
        
        # éŠ˜æŸ„ã”ã¨ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åé›†
        symbol_patterns = {}
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
                if all(col in df.columns for col in ['entry_price', 'take_profit_price', 'stop_loss_price']):
                    entry = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                    tp = pd.to_numeric(df['take_profit_price'], errors='coerce').dropna()
                    sl = pd.to_numeric(df['stop_loss_price'], errors='coerce').dropna()
                    
                    if len(entry) > 0 and len(tp) > 0 and len(sl) > 0:
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆï¼ˆå¹³å‡å€¤ã®çµ„ã¿åˆã‚ã›ï¼‰
                        pattern = (
                            round(entry.mean(), 6),
                            round(tp.mean(), 6),
                            round(sl.mean(), 6)
                        )
                        
                        if symbol not in symbol_patterns:
                            symbol_patterns[symbol] = []
                        
                        symbol_patterns[symbol].append({
                            'pattern': pattern,
                            'timeframe': timeframe,
                            'strategy': strategy,
                            'file_path': str(file_path)
                        })
            
            except Exception as e:
                continue
        
        # åŒä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        for symbol, patterns in symbol_patterns.items():
            pattern_groups = {}
            
            for item in patterns:
                pattern = item['pattern']
                if pattern not in pattern_groups:
                    pattern_groups[pattern] = []
                pattern_groups[pattern].append(item)
            
            # åŒä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¤‡æ•°æˆ¦ç•¥ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å ´åˆ
            for pattern, items in pattern_groups.items():
                if len(items) > 1:
                    identical_patterns.append({
                        'symbol': symbol,
                        'pattern': pattern,
                        'strategies': [f"{item['timeframe']}_{item['strategy']}" for item in items],
                        'count': len(items),
                        'severity': 'HIGH' if len(items) > 3 else 'MEDIUM'
                    })
        
        return identical_patterns
    
    def _get_available_symbols(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        symbols = set()
        
        if self.compressed_dir.exists():
            for file_path in self.compressed_dir.glob("*.pkl.gz"):
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 1:
                    symbols.add(parts[0])
        
        return list(symbols)

class ContinuousMonitoringTest(unittest.TestCase):
    """ç¶™ç¶šç›£è¦–ç”¨ãƒ†ã‚¹ãƒˆ"""
    
    def test_latest_symbol_additions(self):
        """æœ€æ–°ã®éŠ˜æŸ„è¿½åŠ ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª"""
        # éå»24æ™‚é–“ä»¥å†…ã«ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        recent_files = self._get_recent_files(hours=24)
        
        if not recent_files:
            self.skipTest("24æ™‚é–“ä»¥å†…ã«æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        detector = HardcodedValueDetector()
        detector.setUp()
        
        violations = []
        for file_path in recent_files:
            # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
                price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price']
                for col in price_columns:
                    if col in df.columns:
                        violations.extend(
                            detector._check_column_for_hardcoded_values(
                                df, col, "RECENT", "RECENT", str(file_path.name)
                            )
                        )
            
            except Exception as e:
                continue
        
        self.assertEqual(len(violations), 0,
                        f"æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º: {violations}")
    
    def _get_recent_files(self, hours: int = 24) -> List[Path]:
        """æŒ‡å®šæ™‚é–“ä»¥å†…ã«ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        recent_files = []
        compressed_dir = Path("large_scale_analysis/compressed")
        
        if not compressed_dir.exists():
            return recent_files
        
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        for file_path in compressed_dir.glob("*.pkl.gz"):
            try:
                mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                if mtime > cutoff_time:
                    recent_files.append(file_path)
            except Exception:
                continue
        
        return recent_files

def create_monitoring_suite():
    """ç›£è¦–ç”¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä½œæˆ"""
    suite = unittest.TestSuite()
    
    # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ
    suite.addTest(unittest.makeSuite(HardcodedValueDetector))
    
    # ç¶™ç¶šç›£è¦–ãƒ†ã‚¹ãƒˆ
    suite.addTest(unittest.makeSuite(ContinuousMonitoringTest))
    
    return suite

if __name__ == '__main__':
    print("ğŸ” ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
    runner = unittest.TextTestRunner(verbosity=2)
    suite = create_monitoring_suite()
    result = runner.run(suite)
    
    # çµæœãƒ¬ãƒãƒ¼ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ“Š ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥çµæœ")
    print("=" * 60)
    print(f"å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {result.testsRun}")
    print(f"å¤±æ•—: {len(result.failures)}")
    print(f"ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")
    
    if result.failures:
        print("\nâŒ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        for test, traceback in result.failures:
            print(f"  - {test}")
    
    if result.errors:
        print("\nğŸ’¥ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼:")
        for test, traceback in result.errors:
            print(f"  - {test}")
    
    if not result.failures and not result.errors:
        print("\nâœ… ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    exit_code = 1 if (result.failures or result.errors) else 0
    exit(exit_code)