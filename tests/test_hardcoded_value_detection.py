#!/usr/bin/env python3
"""
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥å°‚ç”¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

ç›®çš„:
1. æ–°ã—ã„éŠ˜æŸ„è¿½åŠ æ™‚ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã®è‡ªå‹•æ¤œçŸ¥
2. ãƒãƒƒã‚¯ãƒ†ã‚¹ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã®ä¾¡æ ¼è¨ˆç®—ãƒ­ã‚¸ãƒƒã‚¯ã®å¦¥å½“æ€§æ¤œè¨¼
3. ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿæ§‹ã®ä½¿ç”¨æ¤œçŸ¥ã¨è­¦å‘Š

ä½¿ç”¨ã‚¿ã‚¤ãƒŸãƒ³ã‚°:
- éŠ˜æŸ„è¿½åŠ å¾Œã®è‡ªå‹•å®Ÿè¡Œ
- CIãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã§ã®ç¶™ç¶šç›£è¦–
- å®šæœŸçš„ãªå“è³ªãƒã‚§ãƒƒã‚¯
"""

import sys
import os
import unittest
import pandas as pd
import numpy as np
import pickle
import gzip
import asyncio
from pathlib import Path
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Tuple, Any, Optional

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class HardcodedValueDetector(unittest.TestCase):
    """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ"""
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.compressed_dir = Path("large_scale_analysis/compressed")
        self.known_hardcoded_values = [
            100.0, 105.0, 97.62, 100.00, 105.00, 97.620,
            0.04705, 0.050814, 0.044810,  # GMTæ¤œå‡ºå€¤
            102.0, 95.0, 98.0, 103.0     # è¿½åŠ ã®ç–‘ã‚ã—ã„å€¤
        ]
        self.tolerance = 0.0001  # è¨±å®¹èª¤å·®
        
    def test_no_forced_trade_count_generation(self):
        """å¼·åˆ¶å›æ•°ç”ŸæˆãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª"""
        print("\nğŸš¨ å¼·åˆ¶å›æ•°ç”Ÿæˆæ¤œçŸ¥ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
        
        violations = []
        
        # scalable_analysis_system.pyã®å¼·åˆ¶å›æ•°ç”Ÿæˆãƒã‚§ãƒƒã‚¯
        try:
            from scalable_analysis_system import ScalableAnalysisSystem
            system = ScalableAnalysisSystem()
            
            # _generate_real_analysis ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚·ã‚°ãƒãƒãƒ£ã‚’ãƒã‚§ãƒƒã‚¯
            import inspect
            sig = inspect.signature(system._generate_real_analysis)
            params = list(sig.parameters.keys())
            
            # num_trades ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã¯é•å
            if 'num_trades' in params:
                violations.append({
                    'file': 'scalable_analysis_system.py',
                    'method': '_generate_real_analysis',
                    'issue': 'num_trades parameter detected (forced count generation)',
                    'parameter': 'num_trades'
                })
            
            print(f"   âœ… scalable_analysis_system.py: {len([v for v in violations if 'scalable_analysis' in v['file']])} violations")
            
        except Exception as e:
            print(f"   âš ï¸ scalable_analysis_system.py check failed: {e}")
            violations.append({
                'file': 'scalable_analysis_system.py',
                'method': '__init__',
                'issue': f'Critical error during initialization: {str(e)}',
                'parameter': 'system_error'
            })
        
        # improved_scalable_analysis_system.pyã® trades_per_day ãƒã‚§ãƒƒã‚¯
        try:
            if os.path.exists('improved_scalable_analysis_system.py'):
                with open('improved_scalable_analysis_system.py', 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # trades_per_day ã®ä½¿ç”¨ã‚’ãƒã‚§ãƒƒã‚¯
                if 'trades_per_day' in content and 'num_trades = int(trades_per_day' in content:
                    violations.append({
                        'file': 'improved_scalable_analysis_system.py',
                        'method': 'TIMEFRAME_CONFIGS',
                        'issue': 'trades_per_day forced count generation detected',
                        'parameter': 'trades_per_day'
                    })
                
                print(f"   âœ… improved_scalable_analysis_system.py: {len([v for v in violations if 'improved' in v['file']])} violations")
                
        except Exception as e:
            print(f"   âš ï¸ improved_scalable_analysis_system.py check failed: {e}")
        
        # çµæœå ±å‘Š
        if violations:
            print(f"\nğŸš¨ å¼·åˆ¶å›æ•°ç”Ÿæˆã‚’æ¤œå‡º:")
            for violation in violations:
                print(f"   - {violation['file']}.{violation['method']}: {violation['issue']}")
        else:
            print(f"\nâœ… å¼·åˆ¶å›æ•°ç”Ÿæˆã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
        
        self.assertEqual(len(violations), 0, 
                        f"å¼·åˆ¶å›æ•°ç”Ÿæˆã‚’æ¤œå‡º: {violations}")

    def test_condition_based_signal_generation(self):
        """æ¡ä»¶ãƒ™ãƒ¼ã‚¹ã‚·ã‚°ãƒŠãƒ«ç”ŸæˆãŒå®Ÿè£…ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        print("\nğŸ¯ æ¡ä»¶ãƒ™ãƒ¼ã‚¹ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆç¢ºèªãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
        
        try:
            from scalable_analysis_system import ScalableAnalysisSystem
            system = ScalableAnalysisSystem()
            
            # _evaluate_entry_conditions ãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            has_condition_evaluation = hasattr(system, '_evaluate_entry_conditions')
            
            if has_condition_evaluation:
                print("   âœ… _evaluate_entry_conditions ãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨")
                
                # ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚·ã‚°ãƒãƒãƒ£ã‚’ãƒã‚§ãƒƒã‚¯
                import inspect
                argspec = inspect.getfullargspec(system._evaluate_entry_conditions)
                expected_params = ['self', 'analysis_result', 'timeframe']
                actual_params = argspec.args
                
                if actual_params == expected_params:
                    print("   âœ… æ¡ä»¶è©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚·ã‚°ãƒãƒãƒ£ãŒæ­£ã—ã„")
                else:
                    print(f"   âš ï¸ æ¡ä»¶è©•ä¾¡ãƒ¡ã‚½ãƒƒãƒ‰ã®ã‚·ã‚°ãƒãƒãƒ£ãŒä¸æ­£: {actual_params} != {expected_params}")
            else:
                print("   âŒ _evaluate_entry_conditions ãƒ¡ã‚½ãƒƒãƒ‰ãŒå­˜åœ¨ã—ãªã„")
            
            # å®Ÿéš›ã«æ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æã‚’è©¦è¡Œã—ã¦NameErrorã‚’æ¤œå‡º
            print("   ğŸ§ª æ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æã®å®Ÿè¡Œãƒ†ã‚¹ãƒˆ...")
            try:
                # è»½é‡ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
                test_result = system._generate_real_analysis('BTC', '1h', 'Conservative_ML')
                print("   âœ… æ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æå®Ÿè¡ŒæˆåŠŸ")
            except NameError as ne:
                print(f"   âŒ NameErroræ¤œå‡º: {ne}")
                self.fail(f"æ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æã§NameError: {ne}")
            except Exception as te:
                print(f"   âš ï¸ ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼: {te}")
                # NameErrorä»¥å¤–ã®ã‚¨ãƒ©ãƒ¼ã¯è¨±å®¹ï¼ˆãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼ç­‰ï¼‰
            
            self.assertTrue(has_condition_evaluation, "æ¡ä»¶ãƒ™ãƒ¼ã‚¹ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆãƒ¡ã‚½ãƒƒãƒ‰ãŒå®Ÿè£…ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            
        except Exception as e:
            self.fail(f"æ¡ä»¶ãƒ™ãƒ¼ã‚¹ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆç¢ºèªä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
    
    def test_no_infinite_loop_in_analysis(self):
        """æ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æã§ç„¡é™ãƒ«ãƒ¼ãƒ—ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª"""
        print("\nâ° ç„¡é™ãƒ«ãƒ¼ãƒ—æ¤œçŸ¥ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œä¸­...")
        
        import threading
        import time
        
        try:
            from scalable_analysis_system import ScalableAnalysisSystem
            system = ScalableAnalysisSystem()
            
            # åˆ†æå®Ÿè¡Œãƒ•ãƒ©ã‚°
            analysis_completed = threading.Event()
            analysis_result = {'result': None, 'error': None}
            
            def run_analysis():
                try:
                    # è»½é‡ãªãƒ†ã‚¹ãƒˆåˆ†æï¼ˆçŸ­æœŸé–“ã€å°ã•ãªãƒ‡ãƒ¼ã‚¿ï¼‰
                    result = system._generate_real_analysis('BTC', '1h', 'Conservative_ML', evaluation_period_days=1)
                    analysis_result['result'] = result
                    analysis_completed.set()
                except Exception as e:
                    analysis_result['error'] = e
                    analysis_completed.set()
            
            # åˆ†æã‚’ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§é–‹å§‹
            analysis_thread = threading.Thread(target=run_analysis)
            analysis_thread.daemon = True
            analysis_thread.start()
            
            # 30ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            timeout_seconds = 30
            completed = analysis_completed.wait(timeout=timeout_seconds)
            
            if not completed:
                print(f"   âŒ ç„¡é™ãƒ«ãƒ¼ãƒ—ã¾ãŸã¯é•·æ™‚é–“å‡¦ç†ã‚’æ¤œå‡º: {timeout_seconds}ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                self.fail(f"æ¡ä»¶ãƒ™ãƒ¼ã‚¹åˆ†æãŒ{timeout_seconds}ç§’ä»¥å†…ã«å®Œäº†ã—ã¾ã›ã‚“ã§ã—ãŸï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—ã®å¯èƒ½æ€§ï¼‰")
            
            # ã‚¨ãƒ©ãƒ¼ãƒã‚§ãƒƒã‚¯
            if analysis_result['error']:
                if isinstance(analysis_result['error'], NameError):
                    print(f"   âŒ NameErroræ¤œå‡º: {analysis_result['error']}")
                    self.fail(f"NameError: {analysis_result['error']}")
                else:
                    print(f"   âš ï¸ ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ï¼ˆè¨±å®¹ï¼‰: {type(analysis_result['error']).__name__}")
            else:
                result = analysis_result['result']
                print(f"   âœ… åˆ†ææ­£å¸¸å®Œäº†: {len(result) if result else 0}ä»¶ã®ã‚·ã‚°ãƒŠãƒ«ç”Ÿæˆ")
                
        except Exception as e:
            self.fail(f"ç„¡é™ãƒ«ãƒ¼ãƒ—æ¤œçŸ¥ãƒ†ã‚¹ãƒˆä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        
    def test_no_hardcoded_entry_prices(self):
        """ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª"""
        violations = self._scan_for_hardcoded_values(['entry_price'])
        
        self.assertEqual(len(violations), 0, 
                        f"ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º: {violations}")
    
    def test_no_hardcoded_tp_sl_prices(self):
        """TP/SLä¾¡æ ¼ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª"""
        violations = self._scan_for_hardcoded_values(['take_profit_price', 'stop_loss_price'])
        
        self.assertEqual(len(violations), 0, 
                        f"TP/SLä¾¡æ ¼ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º: {violations}")
    
    def test_price_variation_exists(self):
        """ä¾¡æ ¼ã«é©åˆ‡ãªå¤‰å‹•ãŒã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        low_variation_cases = self._check_price_variation()
        
        self.assertEqual(len(low_variation_cases), 0,
                        f"ä¾¡æ ¼å¤‰å‹•ãŒä¸è¶³ã—ã¦ã„ã‚‹æˆ¦ç•¥: {low_variation_cases}")
    
    def test_prices_near_current_market(self):
        """ä¾¡æ ¼ãŒç¾åœ¨å¸‚å ´ä¾¡æ ¼ã«è¿‘ã„ã“ã¨ã‚’ç¢ºèª"""
        price_deviation_cases = []
        
        # å„éŠ˜æŸ„ã®ç¾åœ¨ä¾¡æ ¼ã‚’å–å¾—ã—ã¦ãƒã‚§ãƒƒã‚¯
        symbols = self._get_available_symbols()
        
        for symbol in symbols:
            current_price = self._get_current_market_price(symbol)
            if current_price:
                deviations = self._check_price_deviation_from_market(symbol, current_price)
                price_deviation_cases.extend(deviations)
        
        self.assertEqual(len(price_deviation_cases), 0,
                        f"å¸‚å ´ä¾¡æ ¼ã‹ã‚‰å¤§ããä¹–é›¢ã—ãŸä¾¡æ ¼: {price_deviation_cases}")
    
    def test_no_identical_price_patterns(self):
        """åŒä¸€ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå­˜åœ¨ã—ãªã„ã“ã¨ã‚’ç¢ºèª"""
        identical_patterns = self._detect_identical_patterns()
        
        self.assertEqual(len(identical_patterns), 0,
                        f"åŒä¸€ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º: {identical_patterns}")
    
    def test_no_identical_prices_within_file(self):
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§åŒä¸€ä¾¡æ ¼ãŒå¤§é‡ä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèªï¼ˆXLMãƒã‚°å¯¾ç­–ï¼‰"""
        identical_price_files = self._detect_identical_prices_within_files()
        
        self.assertEqual(len(identical_price_files), 0,
                        f"ãƒ•ã‚¡ã‚¤ãƒ«å†…åŒä¸€ä¾¡æ ¼ã‚’æ¤œå‡º: {identical_price_files}")
    
    def test_price_diversity_per_strategy(self):
        """æˆ¦ç•¥ã”ã¨ã®ä¾¡æ ¼å¤šæ§˜æ€§ã‚’ç¢ºèªï¼ˆåŒä¸€ä¾¡æ ¼ãƒã‚°å¯¾ç­–ï¼‰"""
        low_diversity_strategies = self._check_price_diversity_per_strategy()
        
        self.assertEqual(len(low_diversity_strategies), 0,
                        f"ä¾¡æ ¼å¤šæ§˜æ€§ä¸è¶³ã®æˆ¦ç•¥: {low_diversity_strategies}")
    
    def test_realistic_win_rates(self):
        """ç¾å®Ÿçš„ãªå‹ç‡ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆäººå·¥çš„é«˜å‹ç‡å¯¾ç­–ï¼‰"""
        unrealistic_win_rates = self._check_realistic_win_rates()
        
        self.assertEqual(len(unrealistic_win_rates), 0,
                        f"éç¾å®Ÿçš„ãªå‹ç‡ã‚’æ¤œå‡º: {unrealistic_win_rates}")
    
    def _scan_for_hardcoded_values(self, target_columns: List[str]) -> List[Dict]:
        """ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’ã‚¹ã‚­ãƒ£ãƒ³"""
        violations = []
        
        if not self.compressed_dir.exists():
            return violations
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # å¯¾è±¡ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
                for col in target_columns:
                    if col in df.columns:
                        violations.extend(
                            self._check_column_for_hardcoded_values(
                                df, col, symbol, timeframe, strategy
                            )
                        )
            
            except Exception as e:
                print(f"ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ {file_path}: {e}")
                continue
        
        return violations
    
    def _check_column_for_hardcoded_values(self, df: pd.DataFrame, column: str, 
                                         symbol: str, timeframe: str, strategy: str) -> List[Dict]:
        """ã‚«ãƒ©ãƒ å†…ã®ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’ãƒã‚§ãƒƒã‚¯"""
        violations = []
        
        values = pd.to_numeric(df[column], errors='coerce').dropna()
        if len(values) == 0:
            return violations
        
        for hardcoded_val in self.known_hardcoded_values:
            matching_count = sum(abs(val - hardcoded_val) < self.tolerance for val in values)
            
            if matching_count > 0:
                violation_percentage = matching_count / len(values) * 100
                
                violations.append({
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'strategy': strategy,
                    'column': column,
                    'hardcoded_value': hardcoded_val,
                    'matching_count': matching_count,
                    'total_count': len(values),
                    'percentage': violation_percentage,
                    'severity': 'HIGH' if violation_percentage > 50 else 'MEDIUM'
                })
        
        return violations
    
    def _check_price_variation(self) -> List[Dict]:
        """ä¾¡æ ¼å¤‰å‹•ã®ä¸è¶³ã‚’ãƒã‚§ãƒƒã‚¯"""
        low_variation_cases = []
        
        if not self.compressed_dir.exists():
            return low_variation_cases
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ä¾¡æ ¼å¤‰å‹•ã‚’ãƒã‚§ãƒƒã‚¯
                price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price']
                
                for col in price_columns:
                    if col in df.columns:
                        values = pd.to_numeric(df[col], errors='coerce').dropna()
                        
                        if len(values) > 1:
                            # æ¨™æº–åå·®ãƒã‚§ãƒƒã‚¯
                            std_dev = values.std()
                            mean_val = values.mean()
                            cv = std_dev / mean_val if mean_val > 0 else 0  # å¤‰å‹•ä¿‚æ•°
                            
                            # å›ºæœ‰å€¤æ•°ãƒã‚§ãƒƒã‚¯
                            unique_count = len(values.unique())
                            unique_ratio = unique_count / len(values)
                            
                            # ç•°å¸¸åˆ¤å®šï¼ˆXLMãƒã‚°å¯¾ç­–ã§é–¾å€¤ã‚’å³æ ¼åŒ–ï¼‰
                            if cv < 0.0001 or unique_ratio < 0.05 or unique_count <= 1:
                                low_variation_cases.append({
                                    'symbol': symbol,
                                    'timeframe': timeframe,
                                    'strategy': strategy,
                                    'column': col,
                                    'coefficient_of_variation': cv,
                                    'unique_ratio': unique_ratio,
                                    'unique_count': unique_count,
                                    'total_count': len(values),
                                    'std_dev': std_dev,
                                    'mean': mean_val,
                                    'severity': 'CRITICAL' if unique_count <= 1 else 'HIGH'
                                })
            
            except Exception as e:
                continue
        
        return low_variation_cases
    
    def _get_current_market_price(self, symbol: str) -> Optional[float]:
        """ç¾åœ¨ã®å¸‚å ´ä¾¡æ ¼ã‚’å–å¾—"""
        try:
            from hyperliquid_api_client import MultiExchangeAPIClient
            
            async def fetch_price():
                client = MultiExchangeAPIClient()
                end_time = datetime.now(timezone.utc)
                start_time = end_time - timedelta(hours=1)
                
                data = await client.get_ohlcv_data(symbol, '1h', start_time, end_time)
                if not data.empty:
                    return float(data['close'].iloc[-1])
                return None
            
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                return loop.run_until_complete(fetch_price())
            finally:
                loop.close()
                
        except Exception as e:
            print(f"å¸‚å ´ä¾¡æ ¼å–å¾—ã‚¨ãƒ©ãƒ¼ ({symbol}): {e}")
            return None
    
    def _check_price_deviation_from_market(self, symbol: str, current_price: float) -> List[Dict]:
        """å¸‚å ´ä¾¡æ ¼ã‹ã‚‰ã®ä¹–é›¢ã‚’ãƒã‚§ãƒƒã‚¯"""
        deviations = []
        
        if not self.compressed_dir.exists():
            return deviations
        
        for file_path in self.compressed_dir.glob(f"{symbol}_*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼ã®ä¹–é›¢ã‚’ãƒã‚§ãƒƒã‚¯
                if 'entry_price' in df.columns:
                    entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                    
                    if len(entry_prices) > 0:
                        mean_entry = entry_prices.mean()
                        deviation_pct = abs(mean_entry - current_price) / current_price * 100
                        
                        # 30%ä»¥ä¸Šã®ä¹–é›¢ã¯ç•°å¸¸
                        if deviation_pct > 30:
                            deviations.append({
                                'symbol': symbol,
                                'timeframe': timeframe,
                                'strategy': strategy,
                                'current_market_price': current_price,
                                'mean_entry_price': mean_entry,
                                'deviation_percentage': deviation_pct,
                                'severity': 'HIGH' if deviation_pct > 50 else 'MEDIUM'
                            })
            
            except Exception as e:
                continue
        
        return deviations
    
    def _detect_identical_patterns(self) -> List[Dict]:
        """åŒä¸€ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º"""
        identical_patterns = []
        
        if not self.compressed_dir.exists():
            return identical_patterns
        
        # éŠ˜æŸ„ã”ã¨ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’åé›†
        symbol_patterns = {}
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ä¾¡æ ¼ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆ
                if all(col in df.columns for col in ['entry_price', 'take_profit_price', 'stop_loss_price']):
                    entry = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                    tp = pd.to_numeric(df['take_profit_price'], errors='coerce').dropna()
                    sl = pd.to_numeric(df['stop_loss_price'], errors='coerce').dropna()
                    
                    if len(entry) > 0 and len(tp) > 0 and len(sl) > 0:
                        # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½œæˆï¼ˆå¹³å‡å€¤ã®çµ„ã¿åˆã‚ã›ï¼‰
                        pattern = (
                            round(entry.mean(), 6),
                            round(tp.mean(), 6),
                            round(sl.mean(), 6)
                        )
                        
                        if symbol not in symbol_patterns:
                            symbol_patterns[symbol] = []
                        
                        symbol_patterns[symbol].append({
                            'pattern': pattern,
                            'timeframe': timeframe,
                            'strategy': strategy,
                            'file_path': str(file_path)
                        })
            
            except Exception as e:
                continue
        
        # åŒä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
        for symbol, patterns in symbol_patterns.items():
            pattern_groups = {}
            
            for item in patterns:
                pattern = item['pattern']
                if pattern not in pattern_groups:
                    pattern_groups[pattern] = []
                pattern_groups[pattern].append(item)
            
            # åŒä¸€ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¤‡æ•°æˆ¦ç•¥ã§ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹å ´åˆ
            for pattern, items in pattern_groups.items():
                if len(items) > 1:
                    identical_patterns.append({
                        'symbol': symbol,
                        'pattern': pattern,
                        'strategies': [f"{item['timeframe']}_{item['strategy']}" for item in items],
                        'count': len(items),
                        'severity': 'HIGH' if len(items) > 3 else 'MEDIUM'
                    })
        
        return identical_patterns
    
    def _get_available_symbols(self) -> List[str]:
        """åˆ©ç”¨å¯èƒ½ãªéŠ˜æŸ„ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        symbols = set()
        
        if self.compressed_dir.exists():
            for file_path in self.compressed_dir.glob("*.pkl.gz"):
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 1:
                    symbols.add(parts[0])
        
        return list(symbols)
    
    def _detect_identical_prices_within_files(self) -> List[Dict]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å†…ã§åŒä¸€ä¾¡æ ¼ãŒå¤§é‡ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹ã‚±ãƒ¼ã‚¹ã‚’æ¤œå‡ºï¼ˆXLMãƒã‚°å¯¾ç­–ï¼‰"""
        identical_price_files = []
        
        if not self.compressed_dir.exists():
            return identical_price_files
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
                price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price']
                
                for col in price_columns:
                    if col in df.columns:
                        values = pd.to_numeric(df[col], errors='coerce').dropna()
                        
                        if len(values) > 10:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«
                            unique_count = len(values.unique())
                            
                            # ãƒ•ã‚¡ã‚¤ãƒ«å†…åŒä¸€ä¾¡æ ¼ãƒã‚§ãƒƒã‚¯ï¼ˆXLMãƒã‚°å¯¾ç­–ï¼‰
                            if unique_count == 1:  # å…¨ã¦åŒä¸€ä¾¡æ ¼
                                identical_price_files.append({
                                    'file_path': str(file_path),
                                    'symbol': symbol,
                                    'timeframe': timeframe,
                                    'strategy': strategy,
                                    'column': col,
                                    'unique_count': unique_count,
                                    'total_count': len(values),
                                    'identical_value': float(values.iloc[0]),
                                    'severity': 'CRITICAL'
                                })
            
            except Exception as e:
                continue
        
        return identical_price_files
    
    def _check_price_diversity_per_strategy(self) -> List[Dict]:
        """æˆ¦ç•¥ã”ã¨ã®ä¾¡æ ¼å¤šæ§˜æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆåŒä¸€ä¾¡æ ¼ãƒã‚°å¯¾ç­–ï¼‰"""
        low_diversity_strategies = []
        
        if not self.compressed_dir.exists():
            return low_diversity_strategies
        
        # æˆ¦ç•¥ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        strategy_groups = {}
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                    
                    key = f"{symbol}_{strategy}"
                    if key not in strategy_groups:
                        strategy_groups[key] = []
                    
                    if 'entry_price' in df.columns:
                        entry_prices = pd.to_numeric(df['entry_price'], errors='coerce').dropna()
                        if len(entry_prices) > 0:
                            strategy_groups[key].extend(entry_prices.tolist())
            
            except Exception:
                continue
        
        # å„æˆ¦ç•¥ã‚°ãƒ«ãƒ¼ãƒ—ã®å¤šæ§˜æ€§ã‚’ãƒã‚§ãƒƒã‚¯
        for key, prices in strategy_groups.items():
            if len(prices) > 20:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«
                symbol, strategy = key.split('_', 1)
                unique_count = len(set(prices))
                total_count = len(prices)
                diversity_ratio = unique_count / total_count
                
                # å¤šæ§˜æ€§ä¸è¶³ã®åˆ¤å®šï¼ˆXLMãƒã‚°ãƒ¬ãƒ™ãƒ«å¯¾ç­–ï¼‰
                if diversity_ratio < 0.1 or unique_count < 5:
                    low_diversity_strategies.append({
                        'symbol': symbol,
                        'strategy': strategy,
                        'unique_count': unique_count,
                        'total_count': total_count,
                        'diversity_ratio': diversity_ratio,
                        'severity': 'CRITICAL' if unique_count < 5 else 'HIGH'
                    })
        
        return low_diversity_strategies
    
    def _check_realistic_win_rates(self) -> List[Dict]:
        """ç¾å®Ÿçš„ãªå‹ç‡ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆäººå·¥çš„é«˜å‹ç‡å¯¾ç­–ï¼‰"""
        unrealistic_win_rates = []
        
        if not self.compressed_dir.exists():
            return unrealistic_win_rates
        
        for file_path in self.compressed_dir.glob("*.pkl.gz"):
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # æˆ¦ç•¥æƒ…å ±ã‚’æŠ½å‡º
                parts = file_path.stem.replace('.pkl', '').split('_')
                if len(parts) >= 3:
                    symbol = parts[0]
                    timeframe = parts[1]
                    strategy = '_'.join(parts[2:])
                else:
                    continue
                
                # å‹ç‡è¨ˆç®—ï¼ˆPnLã‹ã‚‰ï¼‰
                if 'pnl' in df.columns:
                    pnl_values = pd.to_numeric(df['pnl'], errors='coerce').dropna()
                    
                    if len(pnl_values) > 10:  # ååˆ†ãªã‚µãƒ³ãƒ—ãƒ«
                        win_rate = (pnl_values > 0).mean() * 100
                        
                        # éç¾å®Ÿçš„ãªå‹ç‡ãƒã‚§ãƒƒã‚¯ï¼ˆXLMã®96%å¯¾ç­–ï¼‰
                        if win_rate > 85:  # 85%ä»¥ä¸Šã¯éç¾å®Ÿçš„
                            unrealistic_win_rates.append({
                                'file_path': str(file_path),
                                'symbol': symbol,
                                'timeframe': timeframe,
                                'strategy': strategy,
                                'win_rate': win_rate,
                                'total_trades': len(pnl_values),
                                'severity': 'CRITICAL' if win_rate > 95 else 'HIGH'
                            })
            
            except Exception:
                continue
        
        return unrealistic_win_rates

class ContinuousMonitoringTest(unittest.TestCase):
    """ç¶™ç¶šç›£è¦–ç”¨ãƒ†ã‚¹ãƒˆ"""
    
    def test_latest_symbol_additions(self):
        """æœ€æ–°ã®éŠ˜æŸ„è¿½åŠ ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒä½¿ç”¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª"""
        # éå»24æ™‚é–“ä»¥å†…ã«ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
        recent_files = self._get_recent_files(hours=24)
        
        if not recent_files:
            self.skipTest("24æ™‚é–“ä»¥å†…ã«æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ãŒä½œæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        
        detector = HardcodedValueDetector()
        detector.setUp()
        
        violations = []
        for file_path in recent_files:
            # å€‹åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
            try:
                with gzip.open(file_path, 'rb') as f:
                    trades_data = pickle.load(f)
                
                if isinstance(trades_data, list):
                    df = pd.DataFrame(trades_data)
                elif isinstance(trades_data, dict):
                    df = pd.DataFrame(trades_data)
                else:
                    df = trades_data
                
                if df.empty:
                    continue
                
                # ä¾¡æ ¼ã‚«ãƒ©ãƒ ã‚’ãƒã‚§ãƒƒã‚¯
                price_columns = ['entry_price', 'take_profit_price', 'stop_loss_price']
                for col in price_columns:
                    if col in df.columns:
                        violations.extend(
                            detector._check_column_for_hardcoded_values(
                                df, col, "RECENT", "RECENT", str(file_path.name)
                            )
                        )
            
            except Exception as e:
                continue
        
        self.assertEqual(len(violations), 0,
                        f"æœ€æ–°ãƒ•ã‚¡ã‚¤ãƒ«ã§ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º: {violations}")
    
    def _get_recent_files(self, hours: int = 24) -> List[Path]:
        """æŒ‡å®šæ™‚é–“ä»¥å†…ã«ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—"""
        recent_files = []
        compressed_dir = Path("large_scale_analysis/compressed")
        
        if not compressed_dir.exists():
            return recent_files
        
        cutoff_time = datetime.now() - timedelta(hours=hours)
        
        for file_path in compressed_dir.glob("*.pkl.gz"):
            try:
                mtime = datetime.fromtimestamp(file_path.stat().st_mtime)
                if mtime > cutoff_time:
                    recent_files.append(file_path)
            except Exception:
                continue
        
        return recent_files

def create_monitoring_suite():
    """ç›£è¦–ç”¨ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã‚’ä½œæˆ"""
    suite = unittest.TestSuite()
    
    # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥ãƒ†ã‚¹ãƒˆ
    suite.addTest(unittest.makeSuite(HardcodedValueDetector))
    
    # ç¶™ç¶šç›£è¦–ãƒ†ã‚¹ãƒˆ
    suite.addTest(unittest.makeSuite(ContinuousMonitoringTest))
    
    return suite

if __name__ == '__main__':
    print("ğŸ” ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 60)
    
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
    runner = unittest.TextTestRunner(verbosity=2)
    suite = create_monitoring_suite()
    result = runner.run(suite)
    
    # çµæœãƒ¬ãƒãƒ¼ãƒˆ
    print("\n" + "=" * 60)
    print("ğŸ“Š ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤æ¤œçŸ¥çµæœ")
    print("=" * 60)
    print(f"å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {result.testsRun}")
    print(f"å¤±æ•—: {len(result.failures)}")
    print(f"ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")
    
    if result.failures:
        print("\nâŒ æ¤œå‡ºã•ã‚ŒãŸå•é¡Œ:")
        for test, traceback in result.failures:
            print(f"  - {test}")
    
    if result.errors:
        print("\nğŸ’¥ ãƒ†ã‚¹ãƒˆå®Ÿè¡Œã‚¨ãƒ©ãƒ¼:")
        for test, traceback in result.errors:
            print(f"  - {test}")
    
    if not result.failures and not result.errors:
        print("\nâœ… ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã¯æ¤œå‡ºã•ã‚Œã¾ã›ã‚“ã§ã—ãŸï¼")
    
    # çµ‚äº†ã‚³ãƒ¼ãƒ‰
    exit_code = 1 if (result.failures or result.errors) else 0
    exit(exit_code)