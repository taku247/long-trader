#!/usr/bin/env python3
"""
çµ±ä¸€ãƒ†ã‚¹ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹
- æœ¬ç•ªDBã¸ã®å½±éŸ¿ã‚’å®Œå…¨ã«é˜²ã
- ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®è‡ªå‹•ç®¡ç†
- å…±é€šã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
- æ¨™æº–çš„ãªãƒ†ã‚¹ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®æä¾›
"""
import os
import sqlite3
import tempfile
import shutil
import unittest
from pathlib import Path
from datetime import datetime, timezone
from typing import Dict, List, Optional, Tuple
import json

class BaseTest(unittest.TestCase):
    """
    ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã®åŸºåº•ã‚¯ãƒ©ã‚¹
    
    æ©Ÿèƒ½:
    - ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è‡ªå‹•ä½œæˆãƒ»å‰Šé™¤
    - ãƒ†ã‚¹ãƒˆç”¨DBã®æ¨™æº–ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
    - æœ¬ç•ªDBã¨ã®åˆ†é›¢ä¿è¨¼
    - å…±é€šã®ã‚¢ã‚µãƒ¼ãƒˆãƒ¡ã‚½ãƒƒãƒ‰æä¾›
    """
    
    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å‡¦ç†"""
        # ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.test_dir = tempfile.mkdtemp(prefix=f"test_{self.__class__.__name__}_")
        self.test_start_time = datetime.now(timezone.utc)
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°
        print(f"\nğŸ§ª {self.__class__.__name__} ãƒ†ã‚¹ãƒˆé–‹å§‹")
        print(f"   ğŸ“ ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {self.test_dir}")
        print(f"   â° é–‹å§‹æ™‚åˆ»: {self.test_start_time.strftime('%H:%M:%S')}")
        
        # æ¨™æº–çš„ãªãƒ†ã‚¹ãƒˆç”¨DBãƒ‘ã‚¹ã‚’è¨­å®š
        self.setup_test_databases()
        
        # ãƒ†ã‚¹ãƒˆå›ºæœ‰ã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        self.custom_setup()
    
    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆå¾Œã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        try:
            # ãƒ†ã‚¹ãƒˆå›ºæœ‰ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            self.custom_teardown()
            
            # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å‰Šé™¤
            if hasattr(self, 'test_dir') and os.path.exists(self.test_dir):
                shutil.rmtree(self.test_dir)
                
            # ãƒ†ã‚¹ãƒˆå®Œäº†ãƒ­ã‚°
            test_duration = (datetime.now(timezone.utc) - self.test_start_time).total_seconds()
            print(f"   âœ… ãƒ†ã‚¹ãƒˆå®Œäº† (å®Ÿè¡Œæ™‚é–“: {test_duration:.2f}ç§’)")
            print(f"   ğŸ§¹ ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤: {self.test_dir}")
            
        except Exception as e:
            print(f"   âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def setup_test_databases(self):
        """æ¨™æº–çš„ãªãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ"""
        # execution_logs.db
        self.execution_logs_db = os.path.join(self.test_dir, "execution_logs.db")
        
        # analysis.db
        analysis_dir = os.path.join(self.test_dir, "large_scale_analysis")
        os.makedirs(analysis_dir)
        self.analysis_db = os.path.join(analysis_dir, "analysis.db")
        
        # åŸºæœ¬ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        self.create_execution_logs_table()
        self.create_analyses_table()
        
        print(f"   ğŸ“Š execution_logs DB: {self.execution_logs_db}")
        print(f"   ğŸ“Š analysis DB: {self.analysis_db}")
    
    def create_execution_logs_table(self):
        """execution_logsãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ"""
        with sqlite3.connect(self.execution_logs_db) as conn:
            conn.execute("""
                CREATE TABLE execution_logs (
                    execution_id TEXT PRIMARY KEY,
                    symbol TEXT NOT NULL,
                    status TEXT NOT NULL,
                    start_time TEXT NOT NULL,
                    end_time TEXT,
                    error_message TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            conn.execute("CREATE INDEX idx_execution_logs_symbol ON execution_logs(symbol)")
            conn.execute("CREATE INDEX idx_execution_logs_status ON execution_logs(status)")
    
    def create_analyses_table(self):
        """analysesãƒ†ãƒ¼ãƒ–ãƒ«ã®ä½œæˆ"""
        with sqlite3.connect(self.analysis_db) as conn:
            conn.execute("""
                CREATE TABLE analyses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    execution_id TEXT NOT NULL,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    config TEXT NOT NULL,
                    sharpe_ratio REAL,
                    max_drawdown REAL,
                    total_return REAL,
                    win_rate REAL,
                    total_trades INTEGER,
                    compressed_path TEXT,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    FOREIGN KEY (execution_id) REFERENCES execution_logs(execution_id)
                )
            """)
            
            # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
            conn.execute("CREATE INDEX idx_analyses_symbol ON analyses(symbol)")
            conn.execute("CREATE INDEX idx_analyses_execution_id ON analyses(execution_id)")
            conn.execute("CREATE INDEX idx_analyses_config ON analyses(config)")
    
    def insert_test_execution_log(self, execution_id: str, symbol: str, 
                                  status: str = "SUCCESS") -> str:
        """ãƒ†ã‚¹ãƒˆç”¨execution_logãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥"""
        with sqlite3.connect(self.execution_logs_db) as conn:
            conn.execute("""
                INSERT INTO execution_logs 
                (execution_id, symbol, status, start_time, end_time)
                VALUES (?, ?, ?, ?, ?)
            """, (
                execution_id, symbol, status,
                self.test_start_time.isoformat(),
                datetime.now(timezone.utc).isoformat()
            ))
        return execution_id
    
    def insert_test_analysis(self, execution_id: str, symbol: str, 
                           timeframe: str, config: str,
                           sharpe_ratio: float = 1.0,
                           max_drawdown: float = -0.1,
                           total_return: float = 0.15) -> int:
        """ãƒ†ã‚¹ãƒˆç”¨analysisãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æŒ¿å…¥"""
        with sqlite3.connect(self.analysis_db) as conn:
            cursor = conn.execute("""
                INSERT INTO analyses 
                (execution_id, symbol, timeframe, config, sharpe_ratio, max_drawdown, total_return)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            """, (execution_id, symbol, timeframe, config, sharpe_ratio, max_drawdown, total_return))
            return cursor.lastrowid
    
    def create_test_symbol_data(self, symbol: str, num_patterns: int = 5) -> List[str]:
        """æŒ‡å®šéŠ˜æŸ„ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½œæˆ"""
        execution_ids = []
        strategies = ['Conservative_ML', 'Aggressive_Traditional', 'Full_ML']
        timeframes = ['30m', '1h']
        
        pattern_count = 0
        for strategy in strategies:
            for timeframe in timeframes:
                if pattern_count >= num_patterns:
                    break
                
                execution_id = f"test_{symbol}_{strategy}_{timeframe}_{pattern_count}"
                
                # execution_logä½œæˆ
                self.insert_test_execution_log(execution_id, symbol)
                
                # analysisä½œæˆ
                self.insert_test_analysis(
                    execution_id, symbol, timeframe, strategy,
                    sharpe_ratio=1.0 + (pattern_count * 0.1),
                    max_drawdown=-0.1 - (pattern_count * 0.01),
                    total_return=0.15 + (pattern_count * 0.02)
                )
                
                execution_ids.append(execution_id)
                pattern_count += 1
                
            if pattern_count >= num_patterns:
                break
        
        print(f"   ğŸ“ˆ {symbol}ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ: {len(execution_ids)}ãƒ‘ã‚¿ãƒ¼ãƒ³")
        return execution_ids
    
    def assert_db_isolated(self):
        """æœ¬ç•ªDBã¨ã®åˆ†é›¢ã‚’ç¢ºèª"""
        # æœ¬ç•ªDBãƒ‘ã‚¹ã«è§¦ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
        production_paths = [
            'execution_logs.db',
            'large_scale_analysis/analysis.db',
            os.path.expanduser('~/execution_logs.db')
        ]
        
        for path in production_paths:
            abs_path = os.path.abspath(path)
            test_path = os.path.abspath(self.test_dir)
            
            # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå¤–ã®DBãƒ•ã‚¡ã‚¤ãƒ«ã«è§¦ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¢ºèª
            self.assertFalse(
                abs_path.startswith(test_path.rstrip('/test_')),
                f"æœ¬ç•ªDB({abs_path})ã«è§¦ã‚Œã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
            )
    
    def assert_test_data_exists(self, symbol: str, min_records: int = 1):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å­˜åœ¨ç¢ºèª"""
        with sqlite3.connect(self.analysis_db) as conn:
            cursor = conn.execute(
                "SELECT COUNT(*) FROM analyses WHERE symbol = ?", (symbol,)
            )
            count = cursor.fetchone()[0]
            self.assertGreaterEqual(
                count, min_records,
                f"{symbol}ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒä¸è¶³: {count} < {min_records}"
            )
    
    def get_analysis_count(self, symbol: str = None) -> int:
        """åˆ†æãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—"""
        with sqlite3.connect(self.analysis_db) as conn:
            if symbol:
                cursor = conn.execute(
                    "SELECT COUNT(*) FROM analyses WHERE symbol = ?", (symbol,)
                )
            else:
                cursor = conn.execute("SELECT COUNT(*) FROM analyses")
            return cursor.fetchone()[0]
    
    def get_execution_logs_count(self, symbol: str = None, status: str = None) -> int:
        """å®Ÿè¡Œãƒ­ã‚°ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’å–å¾—"""
        with sqlite3.connect(self.execution_logs_db) as conn:
            query = "SELECT COUNT(*) FROM execution_logs WHERE 1=1"
            params = []
            
            if symbol:
                query += " AND symbol = ?"
                params.append(symbol)
            
            if status:
                query += " AND status = ?"
                params.append(status)
            
            cursor = conn.execute(query, params)
            return cursor.fetchone()[0]
    
    # ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºç”¨ã®ãƒ•ãƒƒã‚¯
    def custom_setup(self):
        """å„ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½ãªã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—å‡¦ç†"""
        pass
    
    def custom_teardown(self):
        """å„ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹ã§ã‚ªãƒ¼ãƒãƒ¼ãƒ©ã‚¤ãƒ‰å¯èƒ½ãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†"""
        pass


class DatabaseTest(BaseTest):
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ“ä½œå°‚ç”¨ã®ãƒ†ã‚¹ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def custom_setup(self):
        """DBæ“ä½œãƒ†ã‚¹ãƒˆç”¨ã®è¿½åŠ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’æœ‰åŠ¹åŒ–
        with sqlite3.connect(self.analysis_db) as conn:
            conn.execute("PRAGMA foreign_keys = ON")
        
        with sqlite3.connect(self.execution_logs_db) as conn:
            conn.execute("PRAGMA foreign_keys = ON")
    
    def test_foreign_key_constraints(self):
        """å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®ãƒ†ã‚¹ãƒˆ"""
        # å­˜åœ¨ã—ãªã„execution_idã§analysisã‚’ä½œæˆã—ã‚ˆã†ã¨ã—ã¦ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        with self.assertRaises(sqlite3.IntegrityError):
            self.insert_test_analysis(
                "nonexistent_id", "TEST", "1h", "Conservative_ML"
            )


class APITest(BaseTest):
    """APIæ“ä½œå°‚ç”¨ã®ãƒ†ã‚¹ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹"""
    
    def custom_setup(self):
        """API ãƒ†ã‚¹ãƒˆç”¨ã®è¿½åŠ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        # è¤‡æ•°éŠ˜æŸ„ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        self.test_symbols = ['BTC', 'ETH', 'SOL']
        self.test_execution_ids = {}
        
        for symbol in self.test_symbols:
            execution_ids = self.create_test_symbol_data(symbol, num_patterns=6)
            self.test_execution_ids[symbol] = execution_ids
    
    def simulate_api_query(self, symbol: str = None, 
                          join_execution_logs: bool = True) -> List[Dict]:
        """API ã‚¯ã‚¨ãƒªã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""
        with sqlite3.connect(self.analysis_db) as conn:
            if join_execution_logs:
                # execution_logs.db ã‚’ã‚¢ã‚¿ãƒƒãƒ
                conn.execute(f"ATTACH DATABASE '{self.execution_logs_db}' AS exec_db")
                
                query = """
                    SELECT a.symbol, a.timeframe, a.config, a.sharpe_ratio, a.total_return
                    FROM analyses a
                    INNER JOIN exec_db.execution_logs e ON a.execution_id = e.execution_id
                    WHERE e.status = 'SUCCESS'
                """
                params = []
                
                if symbol:
                    query += " AND a.symbol = ?"
                    params.append(symbol)
                
                query += " ORDER BY a.sharpe_ratio DESC"
                
            else:
                query = """
                    SELECT symbol, timeframe, config, sharpe_ratio, total_return
                    FROM analyses WHERE 1=1
                """
                params = []
                
                if symbol:
                    query += " AND symbol = ?"
                    params.append(symbol)
                
                query += " ORDER BY sharpe_ratio DESC"
            
            cursor = conn.execute(query, params)
            columns = [description[0] for description in cursor.description]
            rows = cursor.fetchall()
            
            # è¾æ›¸å½¢å¼ã§è¿”å´
            results = []
            for row in rows:
                results.append(dict(zip(columns, row)))
            
            return results


if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆåŸºåº•ã‚¯ãƒ©ã‚¹ã®å‹•ä½œç¢ºèª
    class SampleTest(BaseTest):
        def test_basic_functionality(self):
            """åŸºæœ¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""
            # DBåˆ†é›¢ã®ç¢ºèª
            self.assert_db_isolated()
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
            execution_ids = self.create_test_symbol_data("TEST", 3)
            self.assertEqual(len(execution_ids), 3)
            
            # ãƒ‡ãƒ¼ã‚¿å­˜åœ¨ç¢ºèª
            self.assert_test_data_exists("TEST", 3)
            self.assertEqual(self.get_analysis_count("TEST"), 3)
            self.assertEqual(self.get_execution_logs_count("TEST"), 3)
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ
    unittest.main(argv=[''], exit=False, verbosity=2)