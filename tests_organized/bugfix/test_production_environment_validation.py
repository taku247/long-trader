#!/usr/bin/env python3
"""
æœ¬ç•ªç’°å¢ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ

ãƒ†ã‚¹ãƒˆã§ã¯æ¤œçŸ¥ã§ããªã‹ã£ãŸæœ¬ç•ªç’°å¢ƒç‰¹æœ‰ã®å•é¡Œã‚’æ¤œè¨¼:
1. è¤‡æ•°execution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«å•é¡Œ
2. å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã‚‹DBãƒ•ã‚¡ã‚¤ãƒ«ã®ç‰¹å®š
3. æœ¬ç•ªç’°å¢ƒã§ã®ã‚¹ã‚­ãƒ¼ãƒæ•´åˆæ€§
4. ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ•£çŠ¶æ³ã®æ¤œè¨¼
"""

import unittest
import os
import sqlite3
import subprocess
from pathlib import Path


class TestProductionEnvironmentValidation(unittest.TestCase):
    """æœ¬ç•ªç’°å¢ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        """ãƒ†ã‚¹ãƒˆå‰æº–å‚™"""
        self.project_root = Path(__file__).parent.parent.parent
        self.original_cwd = os.getcwd()
        os.chdir(self.project_root)

    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆå¾Œæ¸…æƒ"""
        os.chdir(self.original_cwd)

    def test_execution_logs_db_file_discovery(self):
        """execution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«ç™ºè¦‹ãƒ†ã‚¹ãƒˆ"""
        # å…¨execution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢ï¼ˆ.worktreesé™¤å¤–ï¼‰
        result = subprocess.run([
            'find', '.', '-name', '*execution_logs.db', '-type', 'f', 
            '-not', '-path', '*/.worktrees/*'
        ], capture_output=True, text=True)
        
        execution_logs_files = result.stdout.strip().split('\n')
        execution_logs_files = [f for f in execution_logs_files if f]  # ç©ºè¡Œé™¤å»
        
        # è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ã®æ¤œè¨¼
        self.assertGreater(len(execution_logs_files), 0, 
                          "execution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«ãŒå°‘ãªãã¨ã‚‚1ã¤ã¯å­˜åœ¨ã™ã‚‹ã¹ã")
        
        print(f"ğŸ“‹ ç™ºè¦‹ã•ã‚ŒãŸexecution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«: {len(execution_logs_files)}å€‹")
        for file_path in execution_logs_files:
            print(f"  - {file_path}")

    def test_execution_logs_schema_consistency(self):
        """execution_logs.dbã‚¹ã‚­ãƒ¼ãƒä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        # å…¨execution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¹ã‚­ãƒ¼ãƒã‚’ç¢ºèªï¼ˆ.worktreesé™¤å¤–ï¼‰
        result = subprocess.run([
            'find', '.', '-name', '*execution_logs.db', '-type', 'f',
            '-not', '-path', '*/.worktrees/*'
        ], capture_output=True, text=True)
        
        execution_logs_files = result.stdout.strip().split('\n')
        execution_logs_files = [f for f in execution_logs_files if f and os.path.exists(f)]
        
        required_columns = ['execution_id', 'selected_strategy_ids']
        inconsistent_files = []
        
        for db_file in execution_logs_files:
            try:
                with sqlite3.connect(db_file) as conn:
                    cursor = conn.cursor()
                    cursor.execute("PRAGMA table_info(execution_logs)")
                    columns = [row[1] for row in cursor.fetchall()]
                    
                    missing_columns = [col for col in required_columns if col not in columns]
                    if missing_columns:
                        inconsistent_files.append({
                            'file': db_file,
                            'missing_columns': missing_columns,
                            'existing_columns': columns
                        })
                        
            except sqlite3.Error as e:
                inconsistent_files.append({
                    'file': db_file,
                    'error': str(e)
                })
        
        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        if inconsistent_files:
            error_msg = "ã‚¹ã‚­ãƒ¼ãƒä¸æ•´åˆãªexecution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«:\n"
            for item in inconsistent_files:
                if 'error' in item:
                    error_msg += f"  âŒ {item['file']}: {item['error']}\n"
                else:
                    error_msg += f"  âš ï¸ {item['file']}: ä¸è¶³ã‚«ãƒ©ãƒ  {item['missing_columns']}\n"
            
            self.fail(error_msg)
        
        print(f"âœ… å…¨{len(execution_logs_files)}å€‹ã®execution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«ã§ã‚¹ã‚­ãƒ¼ãƒä¸€è²«æ€§ç¢ºèª")

    def test_database_path_resolution(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹è§£æ±ºãƒ†ã‚¹ãƒˆ"""
        # ä¸»è¦ã‚·ã‚¹ãƒ†ãƒ ã‚¯ãƒ©ã‚¹ãŒå®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹DBãƒ‘ã‚¹ã‚’ç¢ºèª
        import sys
        sys.path.insert(0, str(self.project_root))
        
        from scalable_analysis_system import ScalableAnalysisSystem
        from new_symbol_addition_system import NewSymbolAdditionSystem
        
        # ScalableAnalysisSystemã®DBãƒ‘ã‚¹
        system = ScalableAnalysisSystem()
        analysis_db_path = system.db_path
        
        # NewSymbolAdditionSystemã®DBãƒ‘ã‚¹
        addition_system = NewSymbolAdditionSystem()
        addition_analysis_db = addition_system.analysis_db
        addition_execution_logs_db = addition_system.execution_logs_db
        
        # ãƒ‘ã‚¹ä¸€è‡´ç¢ºèª
        self.assertEqual(analysis_db_path, addition_analysis_db,
                        "ScalableAnalysisSystemã¨NewSymbolAdditionSystemã®analysis.dbãƒ‘ã‚¹ãŒä¸€è‡´ã™ã‚‹ã¹ã")
        
        # å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
        self.assertTrue(analysis_db_path.exists(),
                       f"analysis.dbãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¹ã: {analysis_db_path}")
        self.assertTrue(addition_execution_logs_db.exists(),
                       f"execution_logs.dbãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã¹ã: {addition_execution_logs_db}")
        
        print(f"ğŸ“Š ä½¿ç”¨ä¸­ã®DBãƒ‘ã‚¹:")
        print(f"  analysis.db: {analysis_db_path}")
        print(f"  execution_logs.db: {addition_execution_logs_db}")

    def test_web_dashboard_database_isolation(self):
        """web_dashboardãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹éš”é›¢ãƒ†ã‚¹ãƒˆ"""
        web_dashboard_dir = self.project_root / "web_dashboard"
        
        # web_dashboardå†…ã®æ½œåœ¨çš„DBåˆ†æ•£ç®‡æ‰€ã‚’ç¢ºèª
        potential_db_locations = [
            web_dashboard_dir / "large_scale_analysis",
            web_dashboard_dir / "execution_logs.db",
            web_dashboard_dir / "large_scale_analysis_disabled"
        ]
        
        active_db_locations = []
        for location in potential_db_locations:
            if location.exists():
                if location.is_dir():
                    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®DBãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª
                    db_files = list(location.glob("*.db"))
                    if db_files:
                        active_db_locations.append({
                            'location': str(location),
                            'type': 'directory',
                            'db_files': [str(f) for f in db_files]
                        })
                else:
                    # ç›´æ¥DBãƒ•ã‚¡ã‚¤ãƒ«
                    active_db_locations.append({
                        'location': str(location),
                        'type': 'file'
                    })
        
        # web_dashboardå†…ã®æƒ³å®šå¤–DBç™ºè¦‹æ™‚ã¯è­¦å‘Š
        unexpected_locations = [
            loc for loc in active_db_locations 
            if 'large_scale_analysis_disabled' not in loc['location']
        ]
        
        if unexpected_locations:
            warning_msg = "web_dashboardå†…ã«äºˆæœŸã—ãªã„DBãƒ•ã‚¡ã‚¤ãƒ«:\n"
            for loc in unexpected_locations:
                if loc['type'] == 'directory':
                    warning_msg += f"  ğŸ“ {loc['location']}: {loc['db_files']}\n"
                else:
                    warning_msg += f"  ğŸ“„ {loc['location']}\n"
            
            print(f"âš ï¸ {warning_msg}")
            
            # é‡è¦: ã“ã‚Œã¯å¿…ãšã—ã‚‚ã‚¨ãƒ©ãƒ¼ã§ã¯ãªã„ãŒã€ç›£è¦–ãŒå¿…è¦
            # ãƒ†ã‚¹ãƒˆå¤±æ•—ã•ã›ã‚‹ã‹ã¯è¨­å®šå¯èƒ½
            # self.fail(warning_msg)

    def test_actual_database_usage_tracking(self):
        """å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä½¿ç”¨è¿½è·¡ãƒ†ã‚¹ãƒˆ"""
        # ç’°å¢ƒå¤‰æ•°ã‚„ãƒ­ã‚°å‡ºåŠ›ã‹ã‚‰å®Ÿéš›ã«ä½¿ç”¨ã•ã‚Œã¦ã„ã‚‹DBã‚’ç‰¹å®š
        import sys
        sys.path.insert(0, str(self.project_root))
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­ã®DBä½¿ç”¨ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£
        from scalable_analysis_system import ScalableAnalysisSystem
        
        # ãƒ­ã‚°å‡ºåŠ›ã‚’ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ã¦å®Ÿéš›ã®DBä½¿ç”¨ã‚’ç¢ºèª
        import logging
        import io
        
        log_capture = io.StringIO()
        handler = logging.StreamHandler(log_capture)
        logger = logging.getLogger('scalable_analysis_system')
        logger.addHandler(handler)
        logger.setLevel(logging.INFO)
        
        try:
            # ScalableAnalysisSystemã‚’åˆæœŸåŒ–ã—ã¦ãƒ­ã‚°ã‚­ãƒ£ãƒ—ãƒãƒ£
            system = ScalableAnalysisSystem()
            
            # ã‚­ãƒ£ãƒ—ãƒãƒ£ã—ãŸãƒ­ã‚°ã‹ã‚‰å®Ÿéš›ã®DBãƒ‘ã‚¹æŠ½å‡º
            log_output = log_capture.getvalue()
            db_path_lines = [line for line in log_output.split('\n') if 'DB path:' in line]
            
            self.assertGreater(len(db_path_lines), 0, 
                             "DBä½¿ç”¨ãƒ­ã‚°ãŒå‡ºåŠ›ã•ã‚Œã‚‹ã¹ã")
            
            # æœ€æ–°ã®DBãƒ‘ã‚¹æƒ…å ±ã‚’è¡¨ç¤º
            if db_path_lines:
                latest_db_path = db_path_lines[-1]
                print(f"ğŸ“Š å®Ÿéš›ã«ä½¿ç”¨ã•ã‚ŒãŸDBãƒ‘ã‚¹: {latest_db_path}")
                
        finally:
            logger.removeHandler(handler)

    def test_migration_completeness(self):
        """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Œå…¨æ€§ãƒ†ã‚¹ãƒˆ"""
        # æœ¬ç•ªç’°å¢ƒã§å¿…è¦ãªã‚¹ã‚­ãƒ¼ãƒå¤‰æ›´ãŒå…¨ã¦é©ç”¨ã•ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        
        # analysis.dbã®å¿…é ˆã‚«ãƒ©ãƒ ç¢ºèª
        analysis_db_path = self.project_root / "large_scale_analysis" / "analysis.db"
        if analysis_db_path.exists():
            with sqlite3.connect(analysis_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("PRAGMA table_info(analyses)")
                analysis_columns = [row[1] for row in cursor.fetchall()]
                
                required_analysis_columns = [
                    'execution_id', 'task_status', 'task_started_at', 
                    'task_completed_at', 'error_message'
                ]
                
                missing_analysis_columns = [
                    col for col in required_analysis_columns 
                    if col not in analysis_columns
                ]
                
                self.assertEqual(len(missing_analysis_columns), 0,
                               f"analysis.dbã«ä¸è¶³ã‚«ãƒ©ãƒ : {missing_analysis_columns}")
        
        # execution_logs.dbã®å¿…é ˆã‚«ãƒ©ãƒ ç¢ºèª
        execution_logs_db_path = self.project_root / "execution_logs.db"
        if execution_logs_db_path.exists():
            with sqlite3.connect(execution_logs_db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("PRAGMA table_info(execution_logs)")
                execution_columns = [row[1] for row in cursor.fetchall()]
                
                required_execution_columns = ['execution_id', 'selected_strategy_ids']
                
                missing_execution_columns = [
                    col for col in required_execution_columns 
                    if col not in execution_columns
                ]
                
                self.assertEqual(len(missing_execution_columns), 0,
                               f"execution_logs.dbã«ä¸è¶³ã‚«ãƒ©ãƒ : {missing_execution_columns}")
        
        print("âœ… å…¨å¿…é ˆã‚¹ã‚­ãƒ¼ãƒå¤‰æ›´ãŒæœ¬ç•ªç’°å¢ƒã«é©ç”¨æ¸ˆã¿")


if __name__ == '__main__':
    # æœ¬ç•ªç’°å¢ƒæ¤œè¨¼ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    unittest.main(verbosity=2)