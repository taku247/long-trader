#!/usr/bin/env python3
"""
DBçµ±ä¸€ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ - ãƒ†ã‚¹ãƒˆé§†å‹•ã§DBãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§å…ˆçµ±ä¸€ã‚’æ¤œè¨¼
"""

import os
import sys
import sqlite3
import tempfile
import shutil
from pathlib import Path
from unittest.mock import patch, MagicMock
import json

class DbUnificationTest:
    """DBçµ±ä¸€ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.test_results = []
        self.temp_dirs = []
        
    def setup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ğŸ”§ DBçµ±ä¸€ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
        
        # ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.temp_dir = Path(tempfile.mkdtemp(prefix="db_unification_test_"))
        self.temp_dirs.append(self.temp_dir)
        
        # ãƒ†ã‚¹ãƒˆç”¨DBä½œæˆ
        self.test_root_db = self.temp_dir / "execution_logs.db"
        self.test_web_db = self.temp_dir / "web_dashboard" / "execution_logs.db"
        
        # web_dashboardãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        (self.temp_dir / "web_dashboard").mkdir()
        
        # å®Ÿéš›ã®DBã‚¹ã‚­ãƒ¼ãƒã‚’ã‚³ãƒ”ãƒ¼
        self._create_test_databases()
        
        print(f"âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒ: {self.temp_dir}")
        
    def _create_test_databases(self):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ"""
        # ãƒ«ãƒ¼ãƒˆDBã®ä½œæˆï¼ˆå®Ÿéš›ã®ã‚¹ã‚­ãƒ¼ãƒã«åˆã‚ã›ã‚‹ï¼‰
        with sqlite3.connect(self.test_root_db) as conn:
            conn.execute("""
                CREATE TABLE execution_logs (
                    execution_id TEXT PRIMARY KEY,
                    execution_type TEXT NOT NULL,
                    symbol TEXT,
                    symbols TEXT,  -- JSON array
                    timestamp_start TEXT NOT NULL,
                    timestamp_end TEXT,
                    status TEXT NOT NULL,
                    duration_seconds REAL,
                    triggered_by TEXT,
                    server_id TEXT,
                    version TEXT,
                    
                    -- é€²æ—æƒ…å ±
                    current_operation TEXT,
                    progress_percentage REAL DEFAULT 0,
                    completed_tasks TEXT,  -- JSON array
                    total_tasks INTEGER DEFAULT 0,
                    
                    -- ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
                    cpu_usage_avg REAL,
                    memory_peak_mb INTEGER,
                    disk_io_mb INTEGER,
                    
                    -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                    metadata TEXT,  -- JSON
                    
                    -- ã‚¨ãƒ©ãƒ¼æƒ…å ±
                    errors TEXT,  -- JSON array
                    
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ï¼ˆã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªRUNNINGãƒ—ãƒ­ã‚»ã‚¹å«ã‚€ï¼‰
            test_data = [
                ("root_exec_001", "SYMBOL_ADDITION", "BTC", None, "2025-06-21T10:00:00", None, "RUNNING", None, "TEST", None, None, None, 0, "[]", 0, None, None, None, None, "[]"),
                ("root_exec_002", "SYMBOL_ADDITION", "ETH", None, "2025-06-21T09:00:00", None, "SUCCESS", None, "TEST", None, None, None, 0, "[]", 0, None, None, None, None, "[]"),
                ("root_exec_003", "SYMBOL_ADDITION", "SOL", None, "2025-06-21T08:00:00", None, "SUCCESS", None, "TEST", None, None, None, 0, "[]", 0, None, None, None, None, "[]"),
            ]
            
            for data in test_data:
                conn.execute("""
                    INSERT INTO execution_logs 
                    (execution_id, execution_type, symbol, symbols, timestamp_start, timestamp_end, status, 
                     duration_seconds, triggered_by, server_id, version, current_operation, progress_percentage, 
                     completed_tasks, total_tasks, cpu_usage_avg, memory_peak_mb, disk_io_mb, metadata, errors)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, data)
            conn.commit()
        
        # Webãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰DBã®ä½œæˆï¼ˆåŒã˜ã‚¹ã‚­ãƒ¼ãƒï¼‰
        with sqlite3.connect(self.test_web_db) as conn:
            conn.execute("""
                CREATE TABLE execution_logs (
                    execution_id TEXT PRIMARY KEY,
                    execution_type TEXT NOT NULL,
                    symbol TEXT,
                    symbols TEXT,  -- JSON array
                    timestamp_start TEXT NOT NULL,
                    timestamp_end TEXT,
                    status TEXT NOT NULL,
                    duration_seconds REAL,
                    triggered_by TEXT,
                    server_id TEXT,
                    version TEXT,
                    
                    -- é€²æ—æƒ…å ±
                    current_operation TEXT,
                    progress_percentage REAL DEFAULT 0,
                    completed_tasks TEXT,  -- JSON array
                    total_tasks INTEGER DEFAULT 0,
                    
                    -- ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³
                    cpu_usage_avg REAL,
                    memory_peak_mb INTEGER,
                    disk_io_mb INTEGER,
                    
                    -- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                    metadata TEXT,  -- JSON
                    
                    -- ã‚¨ãƒ©ãƒ¼æƒ…å ±
                    errors TEXT,  -- JSON array
                    
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ï¼ˆå¤ã„ãƒ‡ãƒ¼ã‚¿ã€éã‚¢ã‚¯ãƒ†ã‚£ãƒ–ï¼‰
            test_data = [
                ("web_exec_001", "SYMBOL_ADDITION", "DOGE", None, "2025-06-20T15:00:00", None, "SUCCESS", None, "TEST", None, None, None, 0, "[]", 0, None, None, None, None, "[]"),
                ("web_exec_002", "SYMBOL_ADDITION", "ADA", None, "2025-06-20T14:00:00", None, "FAILED", None, "TEST", None, None, None, 0, "[]", 0, None, None, None, None, "[]"),
            ]
            
            for data in test_data:
                conn.execute("""
                    INSERT INTO execution_logs 
                    (execution_id, execution_type, symbol, symbols, timestamp_start, timestamp_end, status, 
                     duration_seconds, triggered_by, server_id, version, current_operation, progress_percentage, 
                     completed_tasks, total_tasks, cpu_usage_avg, memory_peak_mb, disk_io_mb, metadata, errors)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, data)
            conn.commit()
    
    def test_current_db_references(self):
        """ç¾åœ¨ã®DBãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§çŠ¶æ³ã‚’ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª ç¾åœ¨ã®DBãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§çŠ¶æ³ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        try:
            # execution_log_database.pyã®å‚ç…§å…ˆç¢ºèª
            exec_db_path = Path("execution_log_database.py")
            if exec_db_path.exists():
                with open(exec_db_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®DBã‚’å‚ç…§ã—ã¦ã„ã‚‹ã‹
                if 'project_root = Path(__file__).parent' in content and 'execution_logs.db' in content:
                    print("âœ… execution_log_database.py: ãƒ«ãƒ¼ãƒˆDBå‚ç…§")
                else:
                    print("âŒ execution_log_database.py: DBå‚ç…§å…ˆä¸æ˜")
                    self.test_results.append(("execution_log_database_ref", False))
                    return False
            
            # web_dashboard/app.pyã®å‚ç…§å…ˆç¢ºèª
            app_py_path = Path("web_dashboard/app.py")
            if app_py_path.exists():
                with open(app_py_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # ç¾åœ¨ã®å‚ç…§å…ˆã‚’ç¢ºèª
                if "exec_db_path = 'execution_logs.db'" in content:
                    print("âŒ web_dashboard/app.py: ãƒ­ãƒ¼ã‚«ãƒ«DBå‚ç…§ï¼ˆçµ±ä¸€ãŒå¿…è¦ï¼‰")
                    self.test_results.append(("web_dashboard_app_ref", False))
                    return False
                elif "exec_db_path = '../execution_logs.db'" in content:
                    print("âœ… web_dashboard/app.py: ãƒ«ãƒ¼ãƒˆDBå‚ç…§")
                else:
                    print("âš ï¸ web_dashboard/app.py: DBå‚ç…§å…ˆä¸æ˜")
            
            self.test_results.append(("current_db_references", True))
            return True
            
        except Exception as e:
            print(f"âŒ DBå‚ç…§å…ˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("current_db_references", False))
            return False
    
    def test_migration_script_functionality(self):
        """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆæ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        try:
            # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å­˜åœ¨ç¢ºèª
            migration_script = Path("db_unification_migration.py")
            if not migration_script.exists():
                print("âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                self.test_results.append(("migration_script_exists", False))
                return False
            
            print("âœ… ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå­˜åœ¨ã—ã¾ã™")
            
            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ä¸»è¦é–¢æ•°ã‚’ãƒ†ã‚¹ãƒˆ
            sys.path.insert(0, str(Path.cwd()))
            
            # ãƒ†ã‚¹ãƒˆç’°å¢ƒã«ç§»å‹•ã—ã¦ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
            original_cwd = os.getcwd()
            os.chdir(self.temp_dir)
            
            try:
                from db_unification_migration import analyze_databases, migrate_data
                
                # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æãƒ†ã‚¹ãƒˆ
                analysis = analyze_databases()
                
                expected_root_count = 3  # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°
                expected_web_count = 2   # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æ•°
                
                if (analysis['root_db']['count'] == expected_root_count and 
                    analysis['web_db']['count'] == expected_web_count):
                    print(f"âœ… ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æ: Root({expected_root_count}) Web({expected_web_count})")
                else:
                    print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆ†æ: äºˆæœŸã—ãªã„ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°")
                    self.test_results.append(("migration_analysis", False))
                    return False
                
                # ãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ãƒ†ã‚¹ãƒˆ
                migrate_success = migrate_data(dry_run=True)
                if migrate_success:
                    print("âœ… ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰æˆåŠŸ")
                else:
                    print("âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆãƒ‰ãƒ©ã‚¤ãƒ©ãƒ³ï¼‰å¤±æ•—")
                    self.test_results.append(("migration_dry_run", False))
                    return False
                
            finally:
                os.chdir(original_cwd)
            
            self.test_results.append(("migration_script_functionality", True))
            return True
            
        except Exception as e:
            print(f"âŒ ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("migration_script_functionality", False))
            return False
    
    def test_unified_db_access(self):
        """çµ±ä¸€å¾Œã®DBå‚ç…§ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª çµ±ä¸€å¾Œã®DBå‚ç…§å‹•ä½œãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        try:
            # ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®DBçµ±ä¸€ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
            original_cwd = os.getcwd()
            os.chdir(self.temp_dir)
            
            try:
                # çµ±ä¸€DBä½œæˆï¼ˆãƒ«ãƒ¼ãƒˆDBã«WebDBã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆï¼‰
                with sqlite3.connect("execution_logs.db") as root_conn:
                    root_conn.execute("ATTACH DATABASE 'web_dashboard/execution_logs.db' AS web_db")
                    
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    cursor = root_conn.execute("""
                        SELECT COUNT(*) FROM web_db.execution_logs w
                        WHERE w.execution_id NOT IN (
                            SELECT execution_id FROM execution_logs
                        )
                    """)
                    new_records = cursor.fetchone()[0]
                    
                    # æ–°ã—ã„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’çµ±åˆ
                    root_conn.execute("""
                        INSERT OR IGNORE INTO execution_logs 
                        SELECT * FROM web_db.execution_logs 
                        WHERE execution_id NOT IN (
                            SELECT execution_id FROM execution_logs
                        )
                    """)
                    root_conn.commit()
                    
                    # çµ±åˆå¾Œã®ç¢ºèª
                    cursor = root_conn.execute("SELECT COUNT(*) FROM execution_logs")
                    total_count = cursor.fetchone()[0]
                    
                    expected_total = 5  # 3 + 2 = 5ãƒ¬ã‚³ãƒ¼ãƒ‰
                    if total_count == expected_total:
                        print(f"âœ… DBçµ±åˆæˆåŠŸ: {total_count}ãƒ¬ã‚³ãƒ¼ãƒ‰")
                    else:
                        print(f"âŒ DBçµ±åˆå¤±æ•—: äºˆæœŸã—ãªã„ãƒ¬ã‚³ãƒ¼ãƒ‰æ•° {total_count}")
                        self.test_results.append(("unified_db_access", False))
                        return False
                
                # çµ±ä¸€å¾Œã®ã‚¢ã‚¯ã‚»ã‚¹ãƒ†ã‚¹ãƒˆï¼ˆExecutionLogDatabaseã‚¯ãƒ©ã‚¹ï¼‰
                sys.path.insert(0, str(Path(original_cwd)))
                from execution_log_database import ExecutionLogDatabase
                
                # çµ±ä¸€DBã‚’å‚ç…§
                db = ExecutionLogDatabase(db_path="execution_logs.db")
                executions = db.list_executions(limit=10)
                
                if len(executions) == expected_total:
                    print(f"âœ… çµ±ä¸€DBçµŒç”±ã®ã‚¢ã‚¯ã‚»ã‚¹æˆåŠŸ: {len(executions)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
                else:
                    print(f"âŒ çµ±ä¸€DBçµŒç”±ã®ã‚¢ã‚¯ã‚»ã‚¹å¤±æ•—: {len(executions)}ãƒ¬ã‚³ãƒ¼ãƒ‰")
                    self.test_results.append(("unified_db_access", False))
                    return False
                
            finally:
                os.chdir(original_cwd)
            
            self.test_results.append(("unified_db_access", True))
            return True
            
        except Exception as e:
            print(f"âŒ çµ±ä¸€DBå‚ç…§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("unified_db_access", False))
            return False
    
    def test_deletion_function_fix(self):
        """å‰Šé™¤æ©Ÿèƒ½ã®ä¿®æ­£ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª å‰Šé™¤æ©Ÿèƒ½ä¿®æ­£ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        try:
            # app.pyã®å‰Šé™¤æ©Ÿèƒ½ã‚’ãƒ†ã‚¹ãƒˆ
            app_py_path = Path("web_dashboard/app.py")
            if not app_py_path.exists():
                print("âŒ web_dashboard/app.py ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                self.test_results.append(("deletion_function_fix", False))
                return False
            
            with open(app_py_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ä¿®æ­£å¾Œã®DBå‚ç…§ãƒ‘ã‚¹ã‚’ãƒã‚§ãƒƒã‚¯
            if "exec_db_path = '../execution_logs.db'" in content:
                print("âœ… å‰Šé™¤æ©Ÿèƒ½ã®DBå‚ç…§å…ˆãŒä¿®æ­£ã•ã‚Œã¦ã„ã¾ã™")
            elif "exec_db_path = 'execution_logs.db'" in content:
                print("âŒ å‰Šé™¤æ©Ÿèƒ½ã®DBå‚ç…§å…ˆãŒæœªä¿®æ­£ï¼ˆãƒ­ãƒ¼ã‚«ãƒ«DBå‚ç…§ï¼‰")
                self.test_results.append(("deletion_function_fix", False))
                return False
            else:
                print("âš ï¸ å‰Šé™¤æ©Ÿèƒ½ã®DBå‚ç…§å…ˆãŒä¸æ˜")
                self.test_results.append(("deletion_function_fix", False))
                return False
            
            # æ‰‹å‹•ãƒªã‚»ãƒƒãƒˆæ©Ÿèƒ½ã®analysiså‰Šé™¤å‡¦ç†ç¢ºèª
            if "DELETE FROM analyses WHERE execution_id = ?" in content:
                print("âœ… åˆ†æçµæœå‰Šé™¤å‡¦ç†ãŒå«ã¾ã‚Œã¦ã„ã¾ã™")
            else:
                print("âŒ åˆ†æçµæœå‰Šé™¤å‡¦ç†ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“")
                self.test_results.append(("deletion_function_fix", False))
                return False
            
            self.test_results.append(("deletion_function_fix", True))
            return True
            
        except Exception as e:
            print(f"âŒ å‰Šé™¤æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("deletion_function_fix", False))
            return False
    
    def test_data_consistency_after_unification(self):
        """çµ±ä¸€å¾Œã®ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª çµ±ä¸€å¾Œã®ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        try:
            # ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
            original_cwd = os.getcwd()
            os.chdir(self.temp_dir)
            
            try:
                # çµ±ä¸€DBã®æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                with sqlite3.connect("execution_logs.db") as conn:
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    cursor = conn.execute("""
                        SELECT execution_id, COUNT(*) as count 
                        FROM execution_logs 
                        GROUP BY execution_id 
                        HAVING count > 1
                    """)
                    duplicates = cursor.fetchall()
                    
                    if len(duplicates) == 0:
                        print("âœ… é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰ãªã—")
                    else:
                        print(f"âŒ é‡è¤‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ¤œå‡º: {len(duplicates)}ä»¶")
                        self.test_results.append(("data_consistency", False))
                        return False
                    
                    # ãƒ‡ãƒ¼ã‚¿å‹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                    cursor = conn.execute("""
                        SELECT COUNT(*) FROM execution_logs 
                        WHERE execution_id IS NULL OR execution_type IS NULL
                    """)
                    null_count = cursor.fetchone()[0]
                    
                    if null_count == 0:
                        print("âœ… å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã« NULL ãªã—")
                    else:
                        print(f"âŒ å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã« NULL: {null_count}ä»¶")
                        self.test_results.append(("data_consistency", False))
                        return False
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
                    cursor = conn.execute("""
                        SELECT DISTINCT status FROM execution_logs
                    """)
                    statuses = [row[0] for row in cursor.fetchall()]
                    valid_statuses = ['PENDING', 'RUNNING', 'SUCCESS', 'FAILED', 'CANCELLED']
                    
                    invalid_statuses = set(statuses) - set(valid_statuses)
                    if len(invalid_statuses) == 0:
                        print("âœ… ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å€¤ãŒæœ‰åŠ¹")
                    else:
                        print(f"âŒ ç„¡åŠ¹ãªã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å€¤: {invalid_statuses}")
                        self.test_results.append(("data_consistency", False))
                        return False
                
            finally:
                os.chdir(original_cwd)
            
            self.test_results.append(("data_consistency_after_unification", True))
            return True
            
        except Exception as e:
            print(f"âŒ ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("data_consistency_after_unification", False))
            return False
    
    def cleanup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("\nğŸ§¹ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        for temp_dir in self.temp_dirs:
            try:
                shutil.rmtree(temp_dir)
                print(f"âœ… å‰Šé™¤: {temp_dir}")
            except Exception as e:
                print(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def print_test_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼"""
        print("\n" + "=" * 60)
        print("ğŸ“Š DBçµ±ä¸€ãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 60)
        
        passed = sum(1 for _, result in self.test_results if result)
        total = len(self.test_results)
        
        for test_name, result in self.test_results:
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"{status} {test_name}")
        
        print(f"\nğŸ“ˆ ç·åˆçµæœ: {passed}/{total} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({passed/total*100:.1f}%)")
        
        if passed == total:
            print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒåˆæ ¼ã—ã¾ã—ãŸï¼")
            print("âœ… DBçµ±ä¸€æ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã™ã‚‹æº–å‚™ãŒã§ãã¦ã„ã¾ã™")
        else:
            print(f"\nâš ï¸ {total - passed}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
            print("âŒ DBçµ±ä¸€å®Ÿè£…å‰ã«è¿½åŠ ä¿®æ­£ãŒå¿…è¦ã§ã™")
        
        return passed == total

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ DBçµ±ä¸€ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 80)
    
    test = DbUnificationTest()
    
    try:
        # ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        test.setup_test_environment()
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test.test_current_db_references()
        test.test_migration_script_functionality()
        test.test_unified_db_access()
        test.test_deletion_function_fix()
        test.test_data_consistency_after_unification()
        
        # çµæœè¡¨ç¤º
        success = test.print_test_summary()
        
        return success
        
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        test.cleanup_test_environment()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)