#!/usr/bin/env python3
"""
å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
"""

import os
import sys
import sqlite3
import tempfile
import shutil
from pathlib import Path
from datetime import datetime, timedelta

class OrphanedCleanupTest:
    """å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.test_results = []
        self.temp_dirs = []
        
    def setup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        print("ğŸ”§ å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä¸­...")
        
        # ãƒ†ã‚¹ãƒˆç”¨ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.temp_dir = Path(tempfile.mkdtemp(prefix="orphaned_cleanup_test_"))
        self.temp_dirs.append(self.temp_dir)
        
        # ãƒ†ã‚¹ãƒˆç”¨DBä½œæˆ
        self.test_execution_db = self.temp_dir / "execution_logs.db"
        self.test_analysis_db = self.temp_dir / "analysis.db"
        
        # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚µãƒ–ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ä½œæˆ
        (self.temp_dir / "web_dashboard" / "large_scale_analysis").mkdir(parents=True)
        self.test_analysis_db = self.temp_dir / "web_dashboard" / "large_scale_analysis" / "analysis.db"
        
        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’ä½œæˆ
        self._create_test_databases()
        
        print(f"âœ… ãƒ†ã‚¹ãƒˆç’°å¢ƒ: {self.temp_dir}")
        
    def _create_test_databases(self):
        """ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        # execution_logs.db ä½œæˆ
        with sqlite3.connect(self.test_execution_db) as conn:
            conn.execute("""
                CREATE TABLE execution_logs (
                    execution_id TEXT PRIMARY KEY,
                    execution_type TEXT NOT NULL,
                    symbol TEXT,
                    status TEXT NOT NULL,
                    timestamp_start TEXT NOT NULL,
                    created_at TEXT DEFAULT CURRENT_TIMESTAMP
                )
            """)
            
            # æœ‰åŠ¹ãªexecution_idã‚’ä½œæˆ
            valid_executions = [
                ("valid_exec_001", "SYMBOL_ADDITION", "BTC", "SUCCESS", "2025-06-21T10:00:00"),
                ("valid_exec_002", "SYMBOL_ADDITION", "ETH", "SUCCESS", "2025-06-21T09:00:00"),
                ("valid_exec_003", "SYMBOL_ADDITION", "SOL", "FAILED", "2025-06-21T08:00:00"),
            ]
            
            for data in valid_executions:
                conn.execute("""
                    INSERT INTO execution_logs 
                    (execution_id, execution_type, symbol, status, timestamp_start)
                    VALUES (?, ?, ?, ?, ?)
                """, data)
            conn.commit()
        
        # analysis.db ä½œæˆï¼ˆå­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰
        with sqlite3.connect(self.test_analysis_db) as conn:
            conn.execute("""
                CREATE TABLE analyses (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    timeframe TEXT NOT NULL,
                    config TEXT NOT NULL,
                    total_trades INTEGER,
                    win_rate REAL,
                    total_return REAL,
                    sharpe_ratio REAL,
                    max_drawdown REAL,
                    avg_leverage REAL,
                    chart_path TEXT,
                    compressed_path TEXT,
                    generated_at TEXT DEFAULT CURRENT_TIMESTAMP,
                    execution_id TEXT
                )
            """)
            
            # å¤ã„æ—¥ä»˜ã‚’è¨ˆç®—
            old_date = (datetime.now() - timedelta(days=35)).isoformat()
            
            # æ§˜ã€…ãªçŠ¶æ…‹ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            test_analyses = [
                # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿
                ("BTC", "1h", "Conservative_ML", 10, 0.6, 0.15, 1.5, -0.08, 5.2, None, None, datetime.now().isoformat(), "valid_exec_001"),
                ("ETH", "4h", "Aggressive_ML", 8, 0.75, 0.22, 1.8, -0.12, 6.1, None, None, datetime.now().isoformat(), "valid_exec_002"),
                
                # å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ï¼ˆç„¡åŠ¹execution_idï¼‰
                ("DOGE", "1h", "Conservative_ML", 12, 0.5, 0.08, 1.2, -0.15, 3.8, None, None, datetime.now().isoformat(), "invalid_exec_001"),
                ("ADA", "4h", "Balanced", 7, 0.57, 0.12, 1.1, -0.18, 4.2, None, None, datetime.now().isoformat(), "invalid_exec_002"),
                
                # NULL execution_id
                ("LTC", "1d", "Full_ML", 5, 0.4, -0.05, 0.8, -0.25, 4.5, None, None, datetime.now().isoformat(), None),
                ("XRP", "1h", "Conservative_ML", 15, 0.67, 0.18, 1.6, -0.10, 4.8, None, None, datetime.now().isoformat(), None),
                
                # ç©ºæ–‡å­— execution_id
                ("DOT", "4h", "Aggressive_ML", 9, 0.44, 0.02, 0.9, -0.20, 5.5, None, None, datetime.now().isoformat(), ""),
                
                # å¤ã„NULLãƒ‡ãƒ¼ã‚¿ï¼ˆ30æ—¥ä»¥ä¸Šå‰ï¼‰
                ("OLD1", "1h", "Legacy", 20, 0.3, -0.15, 0.5, -0.30, 3.0, None, None, old_date, None),
                ("OLD2", "4h", "Legacy", 18, 0.35, -0.10, 0.6, -0.28, 3.2, None, None, old_date, None),
            ]
            
            for data in test_analyses:
                conn.execute("""
                    INSERT INTO analyses 
                    (symbol, timeframe, config, total_trades, win_rate, total_return, 
                     sharpe_ratio, max_drawdown, avg_leverage, chart_path, compressed_path, 
                     generated_at, execution_id)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, data)
            conn.commit()
    
    def test_orphaned_data_detection(self):
        """å­¤ç«‹ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª å­¤ç«‹ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        try:
            # ãƒ†ã‚¹ãƒˆç’°å¢ƒã§ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            sys.path.insert(0, str(Path.cwd()))
            from orphaned_data_cleanup import OrphanedDataCleanup
            
            # ãƒ†ã‚¹ãƒˆç”¨ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ä½œæˆ
            original_cwd = os.getcwd()
            os.chdir(self.temp_dir)
            
            try:
                cleanup = OrphanedDataCleanup()
                analysis_result = cleanup.analyze_orphaned_data()
                
                # æ¤œå‡ºçµæœã®æ¤œè¨¼
                expected_total = 9  # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç·æ•°
                expected_valid = 2  # æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿æ•°
                expected_null = 3   # NULL execution_id (LTC, XRP, OLD1, OLD2 = 4ã ãŒã€OLD1,OLD2ã¯åˆ¥ã‚«ã‚¦ãƒ³ãƒˆ)
                expected_empty = 1  # ç©ºæ–‡å­— execution_id (DOT)
                expected_invalid = 2 # ç„¡åŠ¹ execution_id (DOGE, ADA)
                
                print(f"ğŸ“Š æ¤œå‡ºçµæœ:")
                print(f"   ç·æ•°: {analysis_result['total_analyses']} (æœŸå¾…å€¤: {expected_total})")
                print(f"   æœ‰åŠ¹: {analysis_result['valid_execution_id']} (æœŸå¾…å€¤: {expected_valid})")
                print(f"   NULL: {analysis_result['null_execution_id']} (æœŸå¾…å€¤: 3)")
                print(f"   ç©ºæ–‡å­—: {analysis_result['empty_execution_id']} (æœŸå¾…å€¤: {expected_empty})")
                print(f"   ç„¡åŠ¹: {analysis_result['invalid_execution_id']} (æœŸå¾…å€¤: {expected_invalid})")
                print(f"   å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰: {len(analysis_result['old_records'])} (æœŸå¾…å€¤: 2)")
                
                # æ¤œè¨¼
                success = True
                if analysis_result['total_analyses'] != expected_total:
                    print(f"âŒ ç·æ•°ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™")
                    success = False
                
                if analysis_result['valid_execution_id'] != expected_valid:
                    print(f"âŒ æœ‰åŠ¹ãƒ‡ãƒ¼ã‚¿æ•°ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™")
                    success = False
                
                if analysis_result['empty_execution_id'] != expected_empty:
                    print(f"âŒ ç©ºæ–‡å­—ãƒ‡ãƒ¼ã‚¿æ•°ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™")
                    success = False
                
                if analysis_result['invalid_execution_id'] != expected_invalid:
                    print(f"âŒ ç„¡åŠ¹ãƒ‡ãƒ¼ã‚¿æ•°ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™")
                    success = False
                
                if len(analysis_result['old_records']) != 2:
                    print(f"âŒ å¤ã„ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãŒæœŸå¾…å€¤ã¨ç•°ãªã‚Šã¾ã™")
                    success = False
                
                if success:
                    print("âœ… å­¤ç«‹ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
                
                self.test_results.append(("orphaned_data_detection", success))
                return analysis_result
                
            finally:
                os.chdir(original_cwd)
            
        except Exception as e:
            print(f"âŒ å­¤ç«‹ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("orphaned_data_detection", False))
            return None
    
    def test_cleanup_execution(self, analysis_result):
        """ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        if not analysis_result:
            print("âŒ åˆ†æçµæœãŒãªã„ãŸã‚ãƒ†ã‚¹ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
            self.test_results.append(("cleanup_execution", False))
            return None
        
        try:
            from orphaned_data_cleanup import OrphanedDataCleanup
            
            original_cwd = os.getcwd()
            os.chdir(self.temp_dir)
            
            try:
                cleanup = OrphanedDataCleanup()
                
                # å®Ÿè¡Œå‰ã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’ç¢ºèª
                with sqlite3.connect(self.test_analysis_db) as conn:
                    cursor = conn.execute("SELECT COUNT(*) FROM analyses")
                    before_count = cursor.fetchone()[0]
                
                # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œï¼ˆå®Ÿéš›ã®å‰Šé™¤ï¼‰
                cleanup_summary = cleanup.execute_cleanup(analysis_result, dry_run=False)
                
                # å®Ÿè¡Œå¾Œã®ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ã‚’ç¢ºèª
                with sqlite3.connect(self.test_analysis_db) as conn:
                    cursor = conn.execute("SELECT COUNT(*) FROM analyses")
                    after_count = cursor.fetchone()[0]
                    
                    # æ®‹ã£ãŸãƒ¬ã‚³ãƒ¼ãƒ‰ãŒæœ‰åŠ¹ãªã‚‚ã®ã®ã¿ã‹ãƒã‚§ãƒƒã‚¯
                    cursor = conn.execute("""
                        SELECT symbol, execution_id FROM analyses 
                        WHERE execution_id IS NOT NULL AND execution_id != ''
                    """)
                    remaining_records = cursor.fetchall()
                
                print(f"ğŸ“Š ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—çµæœ:")
                print(f"   å®Ÿè¡Œå‰ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {before_count}")
                print(f"   å®Ÿè¡Œå¾Œãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {after_count}")
                print(f"   å‰Šé™¤ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {cleanup_summary['total_deleted']}")
                print(f"   æ®‹å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰: {len(remaining_records)}ä»¶")
                
                # æ¤œè¨¼
                expected_deleted = analysis_result['null_execution_id'] + analysis_result['empty_execution_id'] + analysis_result['invalid_execution_id']
                expected_remaining = analysis_result['valid_execution_id']
                
                success = True
                if cleanup_summary['total_deleted'] != expected_deleted:
                    print(f"âŒ å‰Šé™¤æ•°ãŒæœŸå¾…å€¤({expected_deleted})ã¨ç•°ãªã‚Šã¾ã™")
                    success = False
                
                if after_count != expected_remaining:
                    print(f"âŒ æ®‹å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãŒæœŸå¾…å€¤({expected_remaining})ã¨ç•°ãªã‚Šã¾ã™")
                    success = False
                
                # æ®‹å­˜ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã™ã¹ã¦æœ‰åŠ¹ãªexecution_idã‚’æŒã¤ã‹ãƒã‚§ãƒƒã‚¯
                valid_execution_ids = {"valid_exec_001", "valid_exec_002", "valid_exec_003"}
                for symbol, execution_id in remaining_records:
                    if execution_id not in valid_execution_ids:
                        print(f"âŒ ç„¡åŠ¹ãªexecution_idãŒæ®‹å­˜ã—ã¦ã„ã¾ã™: {symbol} -> {execution_id}")
                        success = False
                
                if success:
                    print("âœ… ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãŒæ­£å¸¸ã«å®Ÿè¡Œã•ã‚Œã¾ã—ãŸ")
                
                self.test_results.append(("cleanup_execution", success))
                return cleanup_summary
                
            finally:
                os.chdir(original_cwd)
            
        except Exception as e:
            print(f"âŒ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å®Ÿè¡Œãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("cleanup_execution", False))
            return None
    
    def test_backup_functionality(self):
        """ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ"""
        print("\nğŸ§ª ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆ")
        print("-" * 40)
        
        try:
            from orphaned_data_cleanup import OrphanedDataCleanup
            
            original_cwd = os.getcwd()
            os.chdir(self.temp_dir)
            
            try:
                cleanup = OrphanedDataCleanup()
                
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å®Ÿè¡Œ
                backup_info = cleanup.backup_databases()
                
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
                backup_dir = Path(backup_info['backup_dir'])
                analysis_backup = Path(backup_info['backups']['analysis'])
                info_file = backup_dir / "backup_info.json"
                
                success = True
                
                if not backup_dir.exists():
                    print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ã¾ã›ã‚“: {backup_dir}")
                    success = False
                
                if not analysis_backup.exists():
                    print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {analysis_backup}")
                    success = False
                
                if not info_file.exists():
                    print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {info_file}")
                    success = False
                
                # ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ç¢ºèª
                if analysis_backup.exists():
                    with sqlite3.connect(analysis_backup) as conn:
                        cursor = conn.execute("SELECT COUNT(*) FROM analyses")
                        backup_count = cursor.fetchone()[0]
                        print(f"ğŸ“ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {backup_count}")
                        
                        if backup_count != 9:  # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç·æ•°
                            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°ãŒæœŸå¾…å€¤(9)ã¨ç•°ãªã‚Šã¾ã™")
                            success = False
                
                if success:
                    print("âœ… ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
                    print(f"   ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å ´æ‰€: {backup_dir}")
                
                self.test_results.append(("backup_functionality", success))
                return True
                
            finally:
                os.chdir(original_cwd)
            
        except Exception as e:
            print(f"âŒ ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ãƒ†ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            self.test_results.append(("backup_functionality", False))
            return False
    
    def cleanup_test_environment(self):
        """ãƒ†ã‚¹ãƒˆç’°å¢ƒã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        print("\nğŸ§¹ ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—")
        for temp_dir in self.temp_dirs:
            try:
                shutil.rmtree(temp_dir)
                print(f"âœ… å‰Šé™¤: {temp_dir}")
            except Exception as e:
                print(f"âš ï¸ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã‚¨ãƒ©ãƒ¼: {e}")
    
    def print_test_summary(self):
        """ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼"""
        print("\n" + "=" * 60)
        print("ğŸ“Š å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆçµæœ")
        print("=" * 60)
        
        passed = sum(1 for _, result in self.test_results if result)
        total = len(self.test_results)
        
        for test_name, result in self.test_results:
            status = "âœ… PASS" if result else "âŒ FAIL"
            print(f"{status} {test_name}")
        
        print(f"\nğŸ“ˆ ç·åˆçµæœ: {passed}/{total} ãƒ†ã‚¹ãƒˆåˆæ ¼ ({passed/total*100:.1f}%)")
        
        if passed == total:
            print("\nğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒåˆæ ¼ã—ã¾ã—ãŸï¼")
            print("âœ… å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—æ©Ÿèƒ½ã¯æ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã¾ã™")
        else:
            print(f"\nâš ï¸ {total - passed}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
            print("âŒ è¿½åŠ ä¿®æ­£ãŒå¿…è¦ã§ã™")
        
        return passed == total

def main():
    """ãƒ¡ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("ğŸš€ å­¤ç«‹ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ")
    print("=" * 80)
    
    test = OrphanedCleanupTest()
    
    try:
        # ãƒ†ã‚¹ãƒˆç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        test.setup_test_environment()
        
        # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
        test.test_backup_functionality()
        analysis_result = test.test_orphaned_data_detection()
        test.test_cleanup_execution(analysis_result)
        
        # çµæœè¡¨ç¤º
        success = test.print_test_summary()
        
        return success
        
    finally:
        # ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        test.cleanup_test_environment()

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)