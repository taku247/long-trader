#!/usr/bin/env python3
"""
å®Ÿåœ¨ã®ã‚·ãƒ³ãƒœãƒ«ã§ã®åˆ†æãƒ†ã‚¹ãƒˆ

ä¿®æ­£ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ã§å®Ÿåœ¨ã®ã‚·ãƒ³ãƒœãƒ«ï¼ˆHYPEï¼‰ã‚’åˆ†æã—ã€
ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª
"""

import sys
import os
import pandas as pd
from datetime import datetime, timezone, timedelta

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ 
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

def test_real_symbol_analysis():
    """å®Ÿåœ¨ã®ã‚·ãƒ³ãƒœãƒ«ï¼ˆHYPEï¼‰ã§åˆ†æã‚’ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ” å®Ÿåœ¨ã‚·ãƒ³ãƒœãƒ«ï¼ˆHYPEï¼‰ã§ã®åˆ†æãƒ†ã‚¹ãƒˆ")
    print("=" * 50)
    
    try:
        from scalable_analysis_system import ScalableAnalysisSystem
        
        system = ScalableAnalysisSystem()
        
        # HYPEã®åˆ†æã‚’1ä»¶ã ã‘å®Ÿè¡Œ
        print("\nğŸ“Š HYPE_1h_Conservative_ML ã®åˆ†æã‚’å®Ÿè¡Œ...")
        
        try:
            # æ­£ã—ã„ãƒ¡ã‚½ãƒƒãƒ‰å‘¼ã³å‡ºã—ï¼ˆstrategyã¯å¼•æ•°ã«ãªã„ï¼‰
            result = system._generate_single_analysis(
                symbol="HYPE",
                timeframe="1h", 
                config="Conservative_ML"
            )
            
            print("âœ… åˆ†æçµæœ:")
            print(f"   çµæœã®å‹: {type(result)}")
            
            if isinstance(result, list):
                print(f"   ä»¶æ•°: {len(result)}")
                if result:
                    first_trade = result[0]
                    print(f"   æœ€åˆã®ãƒˆãƒ¬ãƒ¼ãƒ‰ keys: {list(first_trade.keys())}")
                    
                    if 'entry_price' in first_trade:
                        entry_price = first_trade['entry_price']
                        print(f"   ğŸ¯ entry_price: {entry_price}")
                        
                        # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚§ãƒƒã‚¯
                        hardcoded_values = [100.0, 1000.0, 105.0, 97.62]
                        is_hardcoded = any(abs(entry_price - hv) < 0.001 for hv in hardcoded_values)
                        
                        if is_hardcoded:
                            print(f"   âŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ã‚’æ¤œå‡º: {entry_price}")
                        else:
                            print(f"   âœ… å‹•çš„ä¾¡æ ¼ã‚’ç¢ºèª: {entry_price}")
                    
                    if 'take_profit_price' in first_trade:
                        tp_price = first_trade.get('take_profit_price', 'N/A')
                        print(f"   ğŸ¯ take_profit_price: {tp_price}")
                    
                    if 'stop_loss_price' in first_trade:
                        sl_price = first_trade.get('stop_loss_price', 'N/A')
                        print(f"   ğŸ¯ stop_loss_price: {sl_price}")
                    
                    # ä¾¡æ ¼ã®å¤šæ§˜æ€§ã‚’ãƒã‚§ãƒƒã‚¯
                    entry_prices = [trade.get('entry_price') for trade in result[:10]]
                    unique_prices = len(set(entry_prices))
                    print(f"   ğŸ“Š æœ€åˆã®10ä»¶ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯ä¾¡æ ¼æ•°: {unique_prices}")
                    
                    if unique_prices > 1:
                        print("   âœ… ä¾¡æ ¼å¤‰å‹•ã‚’ç¢ºèª")
                    else:
                        print("   âŒ ä¾¡æ ¼ãŒå›ºå®šã•ã‚Œã¦ã„ã¾ã™")
            
        except Exception as e:
            print(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            print(f"   ã‚¨ãƒ©ãƒ¼ã‚¿ã‚¤ãƒ—: {type(e)}")
            import traceback
            traceback.print_exc()
            
    except Exception as e:
        print(f"âŒ ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")

def check_existing_hype_data():
    """æ—¢å­˜ã®HYPEãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ” æ—¢å­˜ã®HYPEãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯")
    print("=" * 50)
    
    import glob
    import pickle
    import gzip
    
    hype_files = glob.glob("large_scale_analysis/compressed/HYPE_*.pkl.gz")
    
    if not hype_files:
        print("â“ HYPEã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"ğŸ“ HYPEãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(hype_files)}")
    
    # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è©³ç´°ãƒã‚§ãƒƒã‚¯
    first_file = hype_files[0]
    print(f"\nğŸ“Š è©³ç´°ãƒã‚§ãƒƒã‚¯: {first_file}")
    
    try:
        with gzip.open(first_file, 'rb') as f:
            trades_data = pickle.load(f)
        
        if isinstance(trades_data, list):
            df = pd.DataFrame(trades_data)
        elif isinstance(trades_data, dict):
            df = pd.DataFrame(trades_data)
        else:
            df = trades_data
        
        print(f"   ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {len(df)}")
        print(f"   ã‚«ãƒ©ãƒ : {list(df.columns)}")
        
        if 'entry_price' in df.columns:
            entry_prices = df['entry_price']
            print(f"   ã‚¨ãƒ³ãƒˆãƒªãƒ¼ä¾¡æ ¼:")
            print(f"     ãƒ¦ãƒ‹ãƒ¼ã‚¯å€¤æ•°: {len(entry_prices.unique())}")
            print(f"     æœ€å°å€¤: {entry_prices.min():.4f}")
            print(f"     æœ€å¤§å€¤: {entry_prices.max():.4f}")
            print(f"     å¹³å‡å€¤: {entry_prices.mean():.4f}")
            print(f"     æ¨™æº–åå·®: {entry_prices.std():.4f}")
            
            # ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãƒã‚§ãƒƒã‚¯
            hardcoded_values = [100.0, 1000.0, 105.0, 97.62]
            hardcoded_count = 0
            
            for hv in hardcoded_values:
                matching = sum(abs(price - hv) < 0.001 for price in entry_prices)
                if matching > 0:
                    hardcoded_count += matching
                    print(f"     âŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ {hv}: {matching}ä»¶")
            
            if hardcoded_count == 0:
                print("     âœ… ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤ãªã—")
            else:
                print(f"     âŒ ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰å€¤åˆè¨ˆ: {hardcoded_count}ä»¶")
                
    except Exception as e:
        print(f"   âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

def check_recent_files():
    """æœ€è¿‘ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("\nğŸ” æœ€è¿‘ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯")
    print("=" * 50)
    
    import glob
    import os
    from datetime import datetime
    
    all_files = glob.glob("large_scale_analysis/compressed/*.pkl.gz")
    
    # ä½œæˆæ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
    files_with_time = []
    for file_path in all_files:
        try:
            mtime = os.path.getmtime(file_path)
            files_with_time.append((file_path, mtime))
        except:
            continue
    
    files_with_time.sort(key=lambda x: x[1], reverse=True)
    
    print(f"ğŸ“ ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(files_with_time)}")
    print("ğŸ“… æœ€æ–°ã®10ãƒ•ã‚¡ã‚¤ãƒ«:")
    
    for i, (file_path, mtime) in enumerate(files_with_time[:10]):
        dt = datetime.fromtimestamp(mtime)
        print(f"   {i+1}. {os.path.basename(file_path)} - {dt.strftime('%Y-%m-%d %H:%M:%S')}")

def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""
    print("ğŸ” å®Ÿåœ¨ã‚·ãƒ³ãƒœãƒ«ã§ã®åˆ†æãƒ†ã‚¹ãƒˆ")
    print("=" * 60)
    
    # 1. å®Ÿåœ¨ã‚·ãƒ³ãƒœãƒ«ï¼ˆHYPEï¼‰ã§ã®æ–°è¦åˆ†æãƒ†ã‚¹ãƒˆ
    test_real_symbol_analysis()
    
    # 2. æ—¢å­˜ã®HYPEãƒ‡ãƒ¼ã‚¿ã‚’ãƒã‚§ãƒƒã‚¯
    check_existing_hype_data()
    
    # 3. æœ€è¿‘ä½œæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚§ãƒƒã‚¯
    check_recent_files()
    
    print("\n" + "=" * 60)
    print("âœ… ãƒ†ã‚¹ãƒˆå®Œäº†")
    print("=" * 60)

if __name__ == '__main__':
    main()